{"meta":{"title":"秋早亦朝","subtitle":"Kurosak1","description":"纯个人记录","author":"KebabShell","url":"https://kebabshellgithub.github.io","root":"/"},"pages":[{"title":"categories","date":"2020-04-26T23:34:35.000Z","updated":"2023-04-06T11:06:55.042Z","comments":false,"path":"categories/index.html","permalink":"https://kebabshellgithub.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-12-28T13:37:43.000Z","updated":"2023-04-06T11:06:55.046Z","comments":false,"path":"tags/index.html","permalink":"https://kebabshellgithub.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"人生放映机之 2022 下","slug":"2022下半年总结","date":"2023-01-19T18:27:56.000Z","updated":"2023-04-06T11:06:55.018Z","comments":true,"path":"2023/01/19/2022下半年总结/","link":"","permalink":"https://kebabshellgithub.github.io/2023/01/19/2022%E4%B8%8B%E5%8D%8A%E5%B9%B4%E6%80%BB%E7%BB%93/","excerpt":"","text":"片名：《人生放映机》 片长：2022.5.31 ~ 2023.1.19 制片人 &amp; 导演 &amp; 主演：KebabShell（Morgan） 年底巨忙，到现在才开贴~~O(∩_∩)O 时间真挺快，2022下半年的主要内容还是工作吧。规律就是这样，时间长了就能适应，经历了前面的迷茫，然后知道自己该做什么，扮演什么角色。。。 都说体制内是枯燥无味的，但我比较庆幸我们这边的氛围好年轻好活泼，工作的时候就得嘻嘻哈哈嘛，大家都知道彼此的能力，不会因为嘻嘻哈哈懈怠工作。 其实到现在我还是没想清楚要做什么，即使今年才过了两个月，不过用两个月想清楚后面的人生，确实有点短哈。 本来想着就这样吧，混在体制内，不当官不做要职，找份副业，从此财富自由，也有一定的社会地位。可是想的太简单了，不当官不做要职还好说，就是摆烂的话会臭了名声。。但是副业的门路也太难想了吧，可能是认识的人太少了，也可能是我太 low 了，想的东西太浅显，所以现在也只能爱迈爱迈地（想去又不想去，不是很努力）考公务员。 好消息是我又重新捡起吉他，希望能一直学下去。 年尾看了几部好剧，《狂飙》（烂尾）、《三体》（剧版！！） 写到这里，突然觉得记忆力不行了，只记得年尾这些事情，感觉2023上半年的总结是不是得列个提纲了，没事上去补补当下的想法和经历 补上了大迷惑剧《进击的巨人》，只是新开的几部美剧我都没有续上，没啥动力看，审美疲劳了。 就这样— 2023，希望大家都好好的吧！！希望谈一场不用考虑结婚的甜甜的恋爱~ ：） PS：确实应该列个提纲了…","categories":[{"name":"总结","slug":"总结","permalink":"https://kebabshellgithub.github.io/categories/%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"半年","slug":"半年","permalink":"https://kebabshellgithub.github.io/tags/%E5%8D%8A%E5%B9%B4/"}]},{"title":"10月组图《绿色春天》","slug":"十月组图","date":"2022-10-29T22:53:07.000Z","updated":"2023-04-06T11:06:55.038Z","comments":true,"path":"2022/10/29/十月组图/","link":"","permalink":"https://kebabshellgithub.github.io/2022/10/29/%E5%8D%81%E6%9C%88%E7%BB%84%E5%9B%BE/","excerpt":"","text":"”绿色春天“，稳中向好。 参加工作快半年，听到的、遇到的人和事，都有点超出想象，虽然早有准备。 稳中向好，真是个贬义词啊~","categories":[{"name":"摄影","slug":"摄影","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%84%E5%BD%B1/"}],"tags":[{"name":"画册","slug":"画册","permalink":"https://kebabshellgithub.github.io/tags/%E7%94%BB%E5%86%8C/"},{"name":"原创","slug":"原创","permalink":"https://kebabshellgithub.github.io/tags/%E5%8E%9F%E5%88%9B/"},{"name":"组图","slug":"组图","permalink":"https://kebabshellgithub.github.io/tags/%E7%BB%84%E5%9B%BE/"}]},{"title":"摄影-新彩色摄影","slug":"摄影-新彩色摄影","date":"2022-08-20T22:08:00.000Z","updated":"2023-04-06T11:06:55.042Z","comments":true,"path":"2022/08/20/摄影-新彩色摄影/","link":"","permalink":"https://kebabshellgithub.github.io/2022/08/20/%E6%91%84%E5%BD%B1-%E6%96%B0%E5%BD%A9%E8%89%B2%E6%91%84%E5%BD%B1/","excerpt":"","text":"新彩色摄影 读 吴晓隆《黄金时代的摄影50讲》的笔记 “三新”中除了”新彩色摄影“，还有“新纪实”和“新地形”，但三者没有必然的联系。 ”新彩色“是一种艺术运动，而其他两个“新”只不过是两次摄影展览，不是艺术运动。 （“艺术运动“也叫”艺术流派“，是指一种在艺术上具有共同宗旨和目标，被一群艺术家在一段时间内（从几个月到数十年不等）所遵循的潮流或风格。比如：印象派、点彩派、立体主义、未来主义、超现实主义等）。 新地形和新纪实未能单独成为运动或潮流，而是和新彩色一起作为一个整体，在新彩色的大背景下，成为六十年代以来的摄影潮流和趋势，直到九十年代末。 “新彩色摄影”（大概从1976年威廉·艾格斯顿的摄影个展开始，到九十年代末数码摄影出来之前） → 1976年，纽约现代艺术博物馆（MoMA），馆长：约翰·萨考夫斯基（John Szarkowski，美国摄影理论家、策展人、评论家，时任MoMA摄影部主任），出了《Guide》（威廉·艾格斯顿导读）。 快照美学：不再强调作品的唯一性和神秘感，而是除掉艺术中的英雄感，去除精心的雕琢和设计印刷，而去强调原真的直接交流的图像（拍的快，出来的快，平俗，日常，没有公共的意识形态的教育和灌输），寻求表面的偶然性。 以前的摄影主要服务于新闻，承担了教化的作用。 艺术的走向：从确定性到不确定性，从唯一的答案走向多元的解读 从1976年后，摄影说教的成分越来越少，给人留出越来越多的再阅读的空间， 但是，新彩色摄影 !&#x3D; 快照美学，早期的新彩色摄影有快照风格，但后面大师们（迈耶罗维茨、斯坦菲尔德、肖尔）都开始尝试大画幅相机进行严谨的拍摄，即刻意的拍出不那么刻意的照片。 👉总结 新彩色摄影的特点： 摒弃了传统摄影对公共的意识形态的教化倾向，不追求宏大的叙事，转而从自身经验出发，以质疑和反省的态度，借助极具表现力的色彩对日常社会景观进行摄影式的审视，揭示了潜伏在美国平常普通的社会表面下所普遍存在的暗藏的危机，一种寻常之下的不寻常，一种时代造就的焦虑和疏离。 在表现形式上，新彩色摄影让色彩成为视觉语言的重要组成部分，色彩并非是简单的依附在事物上的属性，而是让色彩成为画面的重要维度，甚至让色彩支配画面的整体走向。 新彩色摄影开启了一个摄影的新的篇章，无论从表现手法还是拍摄题材或是摄影态度，都对摄影有着举足轻重的影响。 摄影师们：","categories":[{"name":"摄影","slug":"摄影","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%84%E5%BD%B1/"}],"tags":[{"name":"历史","slug":"历史","permalink":"https://kebabshellgithub.github.io/tags/%E5%8E%86%E5%8F%B2/"}]},{"title":"摄影-黑白与彩色","slug":"摄影-黑白与彩色","date":"2022-08-14T10:43:14.000Z","updated":"2023-04-06T11:06:55.042Z","comments":true,"path":"2022/08/14/摄影-黑白与彩色/","link":"","permalink":"https://kebabshellgithub.github.io/2022/08/14/%E6%91%84%E5%BD%B1-%E9%BB%91%E7%99%BD%E4%B8%8E%E5%BD%A9%E8%89%B2/","excerpt":"","text":"黑白与彩色一些大师的看法 1、亨利·卡蒂埃-布列松（Henri Cartier-Bresson），人文，决定性瞬间理论实践者，曾经说过彩色摄影是 bullshit 2、保罗·斯特兰德（Paul Strand），美国“直接摄影”代表人物，曾经说过彩色摄影无法表达更深的情感 3、沃克·埃文斯（Walker Evans），纪实摄影（完全客观的），极具洞察力，曾经说过：彩色很容易使摄影堕落，特别是强烈的色彩更会使照片变得一败涂地（即 Low） 4、安塞尔·亚当斯（Ansel Adams），美国风光摄影家、摄影教育家、“区域曝光法”创始人，曾经说蛋爷的红色天花板是拍不好才弄成红色 5、罗伯特·弗兰克（Robert Frank），20th最有影响力的摄影师之一，黑白就是摄影的色彩 6、… 客观原因： 1、彩色暗房技术太复杂 2、没钱 3、传播因素（彩色太麻烦，贵，慢） 4、表现层面，色彩干扰太多，不如黑白单纯 5、认知层面，用黑白是希望和绘画划清界限 6、人性层面，怕尝试新事物 彩色摄影是必然的趋势，在周围环绕人造色彩的环境下，不和世界接轨，就会被淘汰 为什么先拍黑白？ 初学者要抛弃事物本身的属性，进而去发现它作为一个物体抽象出来的点线面和设计元素","categories":[{"name":"摄影","slug":"摄影","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%84%E5%BD%B1/"}],"tags":[{"name":"历史","slug":"历史","permalink":"https://kebabshellgithub.github.io/tags/%E5%8E%86%E5%8F%B2/"}]},{"title":"中级软考要点汇总","slug":"中级软考-软件设计师","date":"2022-05-21T17:16:50.000Z","updated":"2023-04-06T11:06:55.034Z","comments":true,"path":"2022/05/21/中级软考-软件设计师/","link":"","permalink":"https://kebabshellgithub.github.io/2022/05/21/%E4%B8%AD%E7%BA%A7%E8%BD%AF%E8%80%83-%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1%E5%B8%88/","excerpt":"","text":"乱七八糟 页内存储 CPU DMA 海明码 Cache 加密 PV 操作 不死锁所需要的资源计算 位示图 词法、语法、语义分析 数据流图 确定 接口 功能内聚＞信息内聚＞通信内聚＞过程内聚＞时间内聚＞逻辑内聚＞巧合内聚 程序流程图 语句覆盖&#x2F;代码行覆盖 &lt; 判定覆盖&#x2F;分支覆盖 &amp; 条件覆盖（每个条件） &lt; 路径覆盖 &lt; 条件组合覆盖（所有可能组合） Mcache 环路复杂度：边数 - 结点数 + 2（结点数包括开始结束） 面向对象开发 分析阶段，架构师关注系统的行为，即系统应该做什么 关系代数 R 中间代码 常见：四元式、符号表 二级索引需要的文件最大长度 软件配置管理：标识变更、控制变更、确保变更更正确的实现、报告有关变更 没有风险管理 极限编程：快速","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"软考","slug":"软考","permalink":"https://kebabshellgithub.github.io/tags/%E8%BD%AF%E8%80%83/"}]},{"title":"人生放映机之 2022 上","slug":"2022上半年总结","date":"2022-05-16T22:53:28.000Z","updated":"2023-04-06T11:06:55.018Z","comments":true,"path":"2022/05/16/2022上半年总结/","link":"","permalink":"https://kebabshellgithub.github.io/2022/05/16/2022%E4%B8%8A%E5%8D%8A%E5%B9%B4%E6%80%BB%E7%BB%93/","excerpt":"","text":"第一次开总结帖~ 片名：《人生放映机》 片长：2021 ~ 2022.5.31 制片人 &amp; 导演 &amp; 主演：KebabShell（Morgan） 去年 4 月开始，这一年，算是体验到电视里的起起落落。 第一次省考垫底进面，又有得知巨大分差的，培训期间赶毕业设计的，无领导社死练习的等等的焦虑。五一收到第一名靓女的放弃体检的微信，隔天又知道揭阳无体检递补的小道消息。麻了，后面摆烂，也不想那么多，没想到打球还摔了，喜提软组织挫伤，祸不单行，终究还是戏剧性的俗了哈哈乐了尼玛的… 第二次省考，不出意外的倒数进面，这次倒是公安的。这体测，我尼玛，我大学 1000 米散步的 (lll￢ω￢)。没想到啊没想到，本市自招的事业编中了，我尼玛 300 取 2 尼玛让我中了，嗯，内心长着疤呢，有啥高兴，也就长舒了一口气，结束了，2022.5.16，我高兴了，也属于后知后觉了。 起码啊现在挺 happy，跳绳跑步，体重也慢慢下来，半路扔掉的吉他，也在捡了，从小时候有手机的那一刻，无时无刻都在拍，手机到微单，拍了这么多照片，突然也找到了想要的那种感觉，突然活明白了好像。去尼玛的器材党哈哈哈~ 我真是一个人类，有血有肉，挺精彩。 上半年度-最满意照片：","categories":[{"name":"总结","slug":"总结","permalink":"https://kebabshellgithub.github.io/categories/%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"半年","slug":"半年","permalink":"https://kebabshellgithub.github.io/tags/%E5%8D%8A%E5%B9%B4/"}]},{"title":"Jetpack","slug":"Jetpack","date":"2022-05-03T17:09:31.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2022/05/03/Jetpack/","link":"","permalink":"https://kebabshellgithub.github.io/2022/05/03/Jetpack/","excerpt":"","text":"写在前面 只是汇总和简述，详细的内容有对应的文章 ViewModelViewModel 主要用于数据处理，和 Activity 分离 Livecycles生命周期！！！！ LiveData顾名思义，数据变化，能响应式的显示，实时显示 另外，还有 map() 能提取关键信息、switchMap() 在 LiveData 是外部获取时能将其转化为可观察的 LiveData 对象！ Room数据库 WorkManager定时处理工具 Navigation用于单 Activity 多 Fragment，起到 路由 的作用 Navigation graph（导航图）、NavHost（导航容器）、NavController（导航控制器）","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Kotlin","slug":"Kotlin","permalink":"https://kebabshellgithub.github.io/tags/Kotlin/"},{"name":"Jetpack","slug":"Jetpack","permalink":"https://kebabshellgithub.github.io/tags/Jetpack/"},{"name":"Android","slug":"Android","permalink":"https://kebabshellgithub.github.io/tags/Android/"}]},{"title":"Kotlin初学须知","slug":"Kotlin初学须知","date":"2022-05-01T15:27:49.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2022/05/01/Kotlin初学须知/","link":"","permalink":"https://kebabshellgithub.github.io/2022/05/01/Kotlin%E5%88%9D%E5%AD%A6%E9%A1%BB%E7%9F%A5/","excerpt":"","text":"写在前面 根据 郭霖的《第一行代码》总结，主要用于 Java 转 Kotlin （幸运地拿到了第一批的签名版~ 麻了，有 Kotlin 中文站，此文仅做个人理解 变量与函数val（value）不可变、var（variable）可变，Kotlin 能类型推导，尽可能用 val 123fun methodName(p1: Int, p2: Int): Int &#123; return 0&#125; 函数语法糖： 123fun methodName(p1: Int, p2: Int): Int = max(p1, p2)// 类型推导fun methodName(p1: Int, p2: Int) = max(p1, p2) 逻辑控制when 类似 switch，还支持 类型匹配（is Int -&gt; println(&quot;...&quot;)） 12345678fun getScore(name: String) = when &#123; name.startsWith(&quot;Tom&quot;) -&gt; 86 name == &quot;Jim&quot; -&gt; 77 else -&gt; 0 // else 在后面能改&#125;// 字符串和对象比较一律用 == val range = 0..10 即 [0,10] val range = 0 until 10 即 [0,10) for-in 循环： 123456789for(i in 0..10) &#123; println(i)&#125;for(i in 0 until 10 step 2) &#123; // 每次 i+2，而不是 i++ println(i)&#125;for(i in 10 downTo 1) &#123; // [10,1] 降序 println(i)&#125; 类与对象默认都是 final，需要此类能被继承需要在类名前面添加 open 关键字： 1234567891011121314151617181920212223open class Person &#123; ... &#125;interface Study &#123; fun readBooks() fun doHomework() &#123; println(&quot;这里是接口方法默认实现&quot;) &#125;&#125;// 继承class Student : Person() &#123; ... &#125;// 实现接口，直接逗号后面加，也是 :class Student : Person(), Study &#123; ... &#125;// 主构造函数：直接类名后面加class Student(val sno: String, val grade: Int) : Person() &#123; ... &#125;// 主构可以在 init体 里面加逻辑class Student(val sno: String, val grade: Int) : Person() &#123; init &#123; // ... &#125;&#125; 只能有一个主构造函数，但可以有多个次构造函数，但次构造函数 constructor 必须 间接调用 主构造函数 this： 1234class Student(val sno: String, val grade: Int, name: String, age: Int) : Person(name, age) &#123; constructor(name: String, age: Int) : this(&quot;&quot;, 0, name, age)&#123;&#125; constructor() : this(&quot;&quot;, 0)&#123;&#125;&#125; 密封类sealed when 时可以用到，不用写 else 数据类与单例类data 关键字直接帮你把 equals()、hashCode()、toString() 等方法都自动生成： 12data class YourClass(val p1: String, val p2: Int)// 可省略&#123;&#125; object 替换 class： 12345678object MySingleton &#123; fun singletonFun() &#123; println(&quot;hhh&quot;) &#125;&#125;// 调用直接MySingleton.singletonFun() 泛型语法和 Java 一样 Kotlin 特性： 1234567891011// 类型推导val result = myClass.method&lt;Int&gt;(123)val result = myClass.method(123)// 类型限制class MyClass &#123; fun &lt;T : Number&gt; method(param: T): T &#123; return param &#125;&#125;// 默认情况下，所有的泛型都是可以指定成可空类型的// -&gt;&gt;&gt; 泛型上界默认是 Any?，如果想不为空，Any out 与 in：声明处型变 类型擦除 函数可见性修饰符 修饰符 Java（4种） Kotlin（4种） public 所有类可见 所有类可见（默认） private 当前类可见 当前类可见 protected 当前类、子类、同一包路径下的类可见 当前类、子类可见 default 同一包路径下的类可见（默认） 无 internal 无 同一模块中的类可见 Kotlin奇奇怪怪的函数listOf 初始化集合（不可变）： 1val list = listOf(&quot;A&quot;, &quot;B&quot;) mutableListOf 初始化集合（可变）： 12val list = mutableListOf(&quot;A&quot;, &quot;B&quot;)list.add(&quot;c&quot;) Set 和 List 一样 → setOf 和 mutableSetOf 对于 Map，Kotlin 不推荐用 put、get 来操作，而是用下标： 12345678910// to 不是关键字，而是 infix 函数val map = mapOf(&quot;A&quot; to 1, &quot;B&quot; to 2, &quot;C&quot; to 3)// 存map[&quot;A&quot;] = 2// 取val num = map[&quot;B&quot;]// 遍历for ((fruit, number) in map) &#123; println(&quot;fruit is &quot; + fruit + &quot;, number is &quot; + number)&#125; 高阶函数 参数或返回值类型是函数的函数就是高阶函数 例如： 123fun example(func: (String, Int) -&gt; Unit) &#123; // Unit是妹有返回值 func(&quot;hello&quot;, 123)&#125; 对高阶函数的调用： 1234567891011fun main() &#123; test1(&quot;abc&quot;, 123, ::test12)&#125;fun test1(p1: String, p2: Int, func: (String, Int) -&gt; Unit) &#123; func(p1, p2)&#125;fun test12(p1: String, p2: Int) &#123; println(&quot;p1: $p1; p2: $p2&quot;)&#125; 高阶的背后原理还是匿名类调用，即调用 Function 接口产生的匿名类实例的 invoke 方法。 内联函数而 内联函数 能够解决高阶函数产生的开销，能直接替换代码 123inline fun test1(p1: String, p2: Int, func: (String, Int) -&gt; Unit) &#123; func(p1, p2)&#125; 而 noinline 关键字这是让此参数不要内联： 123inline fun test1(noinline func1: (String, Int) -&gt; Unit, func2: (String, Int) -&gt; Unit) &#123;&#125; 内联函数的缺点是：无法将函数作为参数去传递，只允许传递给另一个内联函数 tips：内联函数能直接在 Lambda 中 return，且返回的是外层的函数： 12345678910111213141516171819202122232425262728293031323334353637383940// 内联fun main(args: Array&lt;String&gt;) &#123; println(&quot;main start&quot;) test1(&quot;abc&quot;) &#123; println(&quot;Lambda start&quot;) // 直接返回 return println(it) println(&quot;Lambda end&quot;) &#125; println(&quot;main end&quot;)&#125;inline fun test1(str: String, func1: (String) -&gt; Unit)&#123; func1(str)&#125;// 输出：// main start// Lambda start// 非内联fun main(args: Array&lt;String&gt;) &#123; println(&quot;main start&quot;) test1(&quot;abc&quot;) &#123; println(&quot;Lambda start&quot;) // 只能局部返回 return@test1 println(it) println(&quot;Lambda end&quot;) &#125; println(&quot;main end&quot;)&#125;fun test1(str: String, func1: (String) -&gt; Unit)&#123; func1(str)&#125;// 输出：// main start// Lambda start// main end 郭霖：“将高阶函数声明成内联函数是一种良好的编程习惯” tips：在内联函数中创建另外的 Lambda 或匿名类实现，并在其中调用函数参数，会报错 原因：在另外的 Lambda 或匿名类实现中无法 return 解决：用 crossinline 修饰函数参数，保证不会用 return … 标准函数with、run、apply 定义静态方法123class Util &#123; fun doAction1() &#123; println(&quot;do action1&quot;) &#125;companion object &#123; fun doAction2() &#123;println(&quot;do action2&quot;) &#125; &#125; &#125; 扩展函数类名.扩展函数 运算符重载 协程GlobalScope.launch 函数、delay() 函数、runBlocking 函数、launch 函数（子协程）、suspend 关键字、coroutineScope 函数（coroutine：协程）、 1234val job = Job()val scope = CoroutineScope(job) scope.launch &#123; // 处理具体的逻辑&#125;job.cancel() async 函数和 await withContext 函数 suspendCoroutine 函数 待更新… companion object、@JvmStatic、顶层方法、as、lateinit、sealed class、扩展函数、运算符重载、为什么取消 checked exception、泛型上界 Any?和Any、类委托（by）和委托属性（by）、懒加载 by lazy &#123;...&#125; 就是委托属性、A to B 即 A.to(B)、infix、泛型实化（reified）、 编译时判空、人为为空、判空辅助 ?.、?:、!! 标准函数 let、with、run、apply、repeat","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Kotlin","slug":"Kotlin","permalink":"https://kebabshellgithub.github.io/tags/Kotlin/"}]},{"title":"大三和弦和小三和弦","slug":"大三和弦和小三和弦","date":"2022-04-17T12:07:48.000Z","updated":"2023-04-06T11:06:55.038Z","comments":true,"path":"2022/04/17/大三和弦和小三和弦/","link":"","permalink":"https://kebabshellgithub.github.io/2022/04/17/%E5%A4%A7%E4%B8%89%E5%92%8C%E5%BC%A6%E5%92%8C%E5%B0%8F%E4%B8%89%E5%92%8C%E5%BC%A6/","excerpt":"","text":"写在前面开始练吉他了嗷 音程以 C 大调 为例，其音名为 C D E F G A B C 对应的唱名就是 Do Re Mi Fa Sol La Si Do（1 2 3 4 5 6 7 8 升1） 音程有全音和半音之分（这里用 = 代表全音，- 代表半音） 而在八度内，每两个音的音程关系就是： Do &#x3D; Re &#x3D; Mi - Fa &#x3D; Sol &#x3D; La &#x3D; Si - Do 即常说的：全全半全全全半 大三和弦与小三和弦首先，理解 三和弦 三和弦就是由三个音组成和弦，例如 C 和弦，就是 1 3 5，即 Do Mi Sol 大三和弦 指的是： 前两个音的关系是 两个全音，后两个音的关系是 一个全音一个半音 还是以 C 和弦 为例，Do 到 Mi 就是有两个 =，也就是两个全音，Mi 到 Sol 是一个 = 和一个 -，即 一个全音一个半音 这样的和弦有个特点，就是听起来 积极又和谐。 而 小三和弦 则相反： 前两个音的关系是 一个全音一个半音，后两个音的关系是 两个全音 小三和弦的标志是和弦后面带一个小写的 m 以 Am 和弦 为例子，Am 和弦 就是 6 1 3，即 La Do Mi La 到 Do 就是一个 = 和一个 -，Do 到 Mi 这是两个 = 小三和弦的特点是 低沉且消极。","categories":[{"name":"音乐","slug":"音乐","permalink":"https://kebabshellgithub.github.io/categories/%E9%9F%B3%E4%B9%90/"}],"tags":[{"name":"乐理","slug":"乐理","permalink":"https://kebabshellgithub.github.io/tags/%E4%B9%90%E7%90%86/"},{"name":"和弦","slug":"和弦","permalink":"https://kebabshellgithub.github.io/tags/%E5%92%8C%E5%BC%A6/"}]},{"title":"使用 GitHub Actions 自动部署 hexo","slug":"GitHub-Action-hexo","date":"2022-04-13T13:27:54.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2022/04/13/GitHub-Action-hexo/","link":"","permalink":"https://kebabshellgithub.github.io/2022/04/13/GitHub-Action-hexo/","excerpt":"","text":"写在前面好朋友林桑推荐（不是鬼子），他说使用 GitHub Actions 可以白嫖 GitHub 的服务器资源来给 hexo 生成静态文件，然后我就开始研究咋整… 林桑的文章：使用 Github Actions 来自动化部署 hexo 博客 GitHub Actions个人感觉，GitHub Actions 就是一个自动化的工具，设置脚本，它帮你一步一步执行，脚本的具体实现，具体在 .github\\workflows\\whatever-name.yml 文件。（whatever-name：随便啥名…） 具体去看官方文档：GitHub Actions 理解而用 Actions 来自动部署 hexo，就需要理解整个过程… 我们在本地给 hexo 生成静态文件并 deploy 的命令是： 123hexo clean# hexo generatehexo deploy 而我们要自动部署，就需要新建私有库（最好），把源码推到远程库，GitHub Actions 感应到 push，就会帮我们执行这些命令，生成静态文件，deploy 到 github.io 库中。 这些命令又需要相对应的环境，所以要在之前先安装相关运行环境，如 nodejs、hexo-cli 等。 让 GitHub 明白我们的指令，就需要上面提到的“脚本文件”： 123456789101112131415161718192021222324252627282930313233343536373839# name 随便起name: deploy# 在 master 分支 push 的时候激活 Actionson: push: branches: - masterjobs: # 可以有多个 job # deploy 为一个 job 的名字，可以随意的取 deploy: # 运行在最新的 ubuntu 容器中 runs-on: ubuntu-latest steps: # 定义这个任务的步骤 - name: checkout repo # 使用封装好的一些 actions # 这里的 actions/checkout@v3 的作用为拉取代码到工作区 uses: actions/checkout@v3 - name: Setup Node.js uses: actions/setup-node@v1 with: node-version: &#x27;14.15.0&#x27; - name: Setup Hexo env: HEXO_DEPLOY_KEY: $&#123;&#123; secrets.HEXO_DEPLOY_KEY &#125;&#125; run: | mkdir -p ~/.ssh/ echo &quot;$HEXO_DEPLOY_KEY&quot; &gt; ~/.ssh/id_rsa chmod 600 ~/.ssh/id_rsa ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts git config --global user.email &quot;kebabshell@163.com&quot; git config --global user.name &quot;KebabShell&quot; npm install hexo-cli -g npm install - name: Deploy run: | hexo clean hexo deploy 密钥理解了上面的整个过程，那么就会想到，在 GitHub 自己的环境下，怎么有权限推内容到我们的库呢？ 在本地，我们推内容到远程仓库是需要 ssh 验证的，所以要在 GitHub 的环境下 push 内容，GitHub 环境就需要我们自己的密钥！ 而密钥又不能直接写在 yml 中，这时候就需要 GitHub 仓库中的 Actions secrets 了！ 就像 yml 提到的： 1234567891011- name: Setup Hexo env: # HEXO_DEPLOY_KEY 就是自定义的 key，把密钥写入 id_rsa 与远程库进行 ssh 验证 HEXO_DEPLOY_KEY: $&#123;&#123; secrets.HEXO_DEPLOY_KEY &#125;&#125; run: | mkdir -p ~/.ssh/ echo &quot;$HEXO_DEPLOY_KEY&quot; &gt; ~/.ssh/id_rsa chmod 600 ~/.ssh/id_rsa ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts git config --global user.email &quot;kebabshell@163.com&quot; git config --global user.name &quot;KebabShell&quot; 效果当你把更改 push 到私有库 master 分支，就会触发 Actions，你可以在 Actions 页看到： 你还能点进去看具体的执行过程： 最后完成上述工作，以后写博文就只需要提交更改，生成静态文件和发布的任务就交给 GitHub ！ 白嫖党永不为奴","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://kebabshellgithub.github.io/tags/Hexo/"},{"name":"博客","slug":"博客","permalink":"https://kebabshellgithub.github.io/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"GitHub","slug":"GitHub","permalink":"https://kebabshellgithub.github.io/tags/GitHub/"}]},{"title":"摄影史01 | 摄影术的发明","slug":"摄影史01摄影术的发明","date":"2022-04-06T22:11:00.000Z","updated":"2023-04-06T11:06:55.042Z","comments":true,"path":"2022/04/06/摄影史01摄影术的发明/","link":"","permalink":"https://kebabshellgithub.github.io/2022/04/06/%E6%91%84%E5%BD%B1%E5%8F%B201%E6%91%84%E5%BD%B1%E6%9C%AF%E7%9A%84%E5%8F%91%E6%98%8E/","excerpt":"","text":"… 测试 test","categories":[{"name":"摄影","slug":"摄影","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%84%E5%BD%B1/"}],"tags":[{"name":"历史","slug":"历史","permalink":"https://kebabshellgithub.github.io/tags/%E5%8E%86%E5%8F%B2/"}]},{"title":"摄影史-总括（目录）","slug":"摄影史-总括","date":"2022-04-06T22:05:43.000Z","updated":"2023-04-06T11:06:55.042Z","comments":true,"path":"2022/04/06/摄影史-总括/","link":"","permalink":"https://kebabshellgithub.github.io/2022/04/06/%E6%91%84%E5%BD%B1%E5%8F%B2-%E6%80%BB%E6%8B%AC/","excerpt":"","text":"摄影史01 | 摄影术的发明 Post not found: # 摄影史02 Post not found: # 摄影史03 Post not found: # 摄影史04","categories":[{"name":"摄影","slug":"摄影","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%84%E5%BD%B1/"}],"tags":[{"name":"历史","slug":"历史","permalink":"https://kebabshellgithub.github.io/tags/%E5%8E%86%E5%8F%B2/"}]},{"title":"面试复盘","slug":"复盘","date":"2021-06-22T14:17:21.000Z","updated":"2023-04-06T11:06:55.038Z","comments":true,"path":"2021/06/22/复盘/","link":"","permalink":"https://kebabshellgithub.github.io/2021/06/22/%E5%A4%8D%E7%9B%98/","excerpt":"","text":"可酷啥来着 Java跨平台体现在哪 一次编译，到处运行。不同平台有对应的虚拟机 Java文件在每个平台上编译完都是class文件吗 对 Java与C++的区别 都是面向对象的语言，都支持封装、继承和多态 Java不提供指针来直接访问内存，程序内存更加安全 Java的类是单继承的，C++支持多重继承；虽然Java的类不可以多继承，但是接口可以多继承。 Java有自动内存管理机制，不需要程序员手动释放无用内存 Java的面向对象体现在哪里 封装 封装可以被认为是一个保护屏障，防止该类的代码和数据被外部类定义的代码随机访问 继承 继承就是子类继承父类的特征和行为，使得子类对象（实例）具有父类的实例域和方法，或子类从父类继承方法，使得子类具有父类相同的行为 多态 多态就是同一个接口，使用不同的实例而执行不同操作 Java为什么使用引用替代指针 Java怎么解决多继承的问题 可以通过内部类继承其他类来实现多继承 重写和重载 抽象类、接口 final、static的使用，包括可变，初始化等 死锁，举例 破死锁，具体一点 设计模式，举例 单例模式怎么解决并发 讲讲计网五层 讲讲HTTP、HTTPS TCP可靠在哪 TCP和UDP哪个传输效率更高 二叉树、完全二叉树、平衡二叉树 排序算法 JVM的内存结构 集合 HashMap链表超过8就要扩容或者红黑树，为什么是8 ArrayList、LinkedList 数组的内存分布、一定是连续分布的吗、定义多大就多大吗 其他忘了 我日，提的问题好离谱。。。 网上查了才发现，都是套路题啊，没看面经，淦。。。。","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://kebabshellgithub.github.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"回调","slug":"回调","date":"2021-06-20T16:48:29.000Z","updated":"2023-04-06T11:06:55.038Z","comments":true,"path":"2021/06/20/回调/","link":"","permalink":"https://kebabshellgithub.github.io/2021/06/20/%E5%9B%9E%E8%B0%83/","excerpt":"","text":"回调balabala 参考 Future、Callable ExecutorService FutureTask 1ExecutorService service = Executors.newCachedThreadPool();","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"摆烂了","slug":"摆烂了","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%86%E7%83%82%E4%BA%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"ThreadPoolTaskExecutor","slug":"ThreadPoolTaskExecutor","date":"2021-06-20T15:24:22.000Z","updated":"2023-04-06T11:06:55.030Z","comments":true,"path":"2021/06/20/ThreadPoolTaskExecutor/","link":"","permalink":"https://kebabshellgithub.github.io/2021/06/20/ThreadPoolTaskExecutor/","excerpt":"","text":"balabala ListenableFutureTask 参考","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"摆烂了","slug":"摆烂了","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%86%E7%83%82%E4%BA%86/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://kebabshellgithub.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"ThreadPoolExecutor","slug":"ThreadPoolExecutor","date":"2021-06-20T15:23:56.000Z","updated":"2023-04-06T11:06:55.030Z","comments":true,"path":"2021/06/20/ThreadPoolExecutor/","link":"","permalink":"https://kebabshellgithub.github.io/2021/06/20/ThreadPoolExecutor/","excerpt":"","text":"balabala~","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"摆烂了","slug":"摆烂了","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%86%E7%83%82%E4%BA%86/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://kebabshellgithub.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"MySQL45讲学习笔记","slug":"MySQL45讲学习笔记","date":"2021-06-11T11:29:35.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2021/06/11/MySQL45讲学习笔记/","link":"","permalink":"https://kebabshellgithub.github.io/2021/06/11/MySQL45%E8%AE%B2%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"redo logInnoDB特有的，在引擎层 掌柜、粉板、账本、赊账 checkpoint、write pos binlog归档日志 在Server层 redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。 redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID&#x3D;2这一行的c字段加1 ”。 redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 update语句的执行流程图，浅色框表示是在InnoDB内部执行的，深色框表示是在执行器中执行的 prepare和commit，即”两阶段提交” 事务一致性视图（可重复读级别） 锁全局锁、表级锁、行锁 全局锁MySQL提供一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL) 全局锁的典型使用场景是，做全库逻辑备份 缺点是备份期间所有东西都动不了，包括binlog 而一致性视图（read-view）可以解决： 官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的 但是single-transaction方法只适用于所有的表使用事务引擎的库 既然要全库只读，为什么不使用set global readonly&#x3D;true的方式呢 readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。修改global变量的方式影响面更大 在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高 表级锁MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL) InnoDB这种支持行锁的引擎，一般不使用lock tables命令来控制并发，毕竟锁住整个表的影响面还是太大 MDL不需要显式使用，在访问一个表的时候会被自动加上 坑：给一个小表加个字段，导致整个库挂了 如何安全地给小表加字段？ 解决长事务，事务不提交，就会一直占着MDL锁 在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。 12ALTER TABLE tbl_name NOWAIT add column ...ALTER TABLE tbl_name WAIT N add column ... 行锁行锁就是针对数据表中行记录的锁。这很好理解，比如事务A更新了一行，而这时候事务B也要更新同一行，则必须等事务A的操作完成后才能进行更新。 在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议 即：update结束后，commit了才算释放行锁 所以： 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放 死锁及检测 策略： 直接进入等待，直到超时（InnoDB默认50s） 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。 意味着每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。 如果所有事务都要更新同一行的场景呢？那么每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作 解决： 如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉 控制并发度 可见性关于一致性视图关键词：MVCC、快照、数组… InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。“活跃”指的就是，启动了但还没提交。 数组里面事务ID的最小值记为低水位，当前系统里面已经创建过的事务ID的最大值加1记为高水位。 这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。 而数据版本的可见性规则，就是基于数据的row trx_id和这个一致性视图的对比结果得到的 注意：更新操作！ 更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read） 可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。 读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是： 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图； 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。 InnoDB的行数据有多个版本，每个数据版本有自己的row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据row trx_id和一致性视图确定数据版本的可见性。 对于可重复读，查询只承认在事务启动前就已经提交完成的数据； 对于读提交，查询只承认在语句启动前就已经提交完成的数据； 而当前读，总是读取已经提交完成的最新版本。 唯一索引和普通索引的选择关键词：change buffer 这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响 如果要在这张表中插入一个新记录(4,400)的话，InnoDB的处理流程是怎样的。 第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB的处理流程如下： 对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。 这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的CPU时间。 但，这不是我们关注的重点。 第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB的处理流程如下： 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了。 将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一。change buffer因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。 merge的时候是真正进行数据更新的时刻 在一个数据页做merge之前，change buffer记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。 假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://kebabshellgithub.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"https://kebabshellgithub.github.io/tags/MySQL/"}]},{"title":"设计模式","slug":"设计模式","date":"2021-06-03T21:31:35.000Z","updated":"2023-04-06T11:06:55.042Z","comments":true,"path":"2021/06/03/设计模式/","link":"","permalink":"https://kebabshellgithub.github.io/2021/06/03/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"各大设计模式单例模式 参考 只有一个实例 构造器私有，外部类无法通过调用构造器方法创建该实例 没有公开的 set 方法 提供一个公开的 get 方法获取唯一的这个实例 a、饿汉式提前把对象 new 出来了，即第一次获取之前就已经存在这个实例了（static） 即提前加载 b、懒汉式第一次获取的时候发现空，就创建实例，再赋值（static） （线程不安全） 写法：（加锁、双检锁、volatile、静态内部类、枚举） 工厂模式 参考 简单工厂模式 工厂方法模式 抽象工程模式 a、简单工厂模式使用静态工厂，但使用反射会影响性能，为了避免反射，可以用 Map 存每种类的实例 b、工厂方法模式工厂类直接被抽象化，需要具体特定化的逻辑代码转移到实现抽象方法的子类中 c、抽象工程模式工厂方法类中只有一个抽象方法，要想实现多种不同的类对象，只能去创建不同的具体工厂方法的子类来实列化，而抽象工厂则是让一个工厂负责创建多个不同类型的对象 建造者模式 参考 抽象建造者类、具体建造者类继承抽象类、director 指导类 原型模式 参考 克隆对象（Cloneable） 比起new的好处是保留对象的信息 注意：浅拷贝和深拷贝 浅拷贝就是基本的数据类型直接复制，而成员变量里引用的其他对象，还是那个 深拷贝就是所有都会复制一遍（可以通过递归实现，或者通过序列化把对象写入流中再从流中取出来） 或者使用工具类： 深拷贝（deep copy）：SerializationUtils 浅拷贝（shallow copy）：BeanUtils 责任链模式 参考 将请求的发送和接收解耦，让多个接收对象都有机会处理这个请求。将这些接收对象串成一条链，并沿着这条链传递这个请求，直到链上的某个接收对象能够处理它为止。 关键词：handler 抽象类、handler 实现类、handleRequest 方法 就是 handler 里面有 handler 成员变量，存着下一个 handler（实现也可以不是传递的方式，看参考文章） 应用： SpringMVC 中的 ServletFilter Spring 中的 SpringInterceptor dubbo 观察者模式 参考 如 RocketMQ 的发布&#x2F;订阅模式 当一个对象的状态发生改变时，已经登记的其他对象能够观察到这一改变从而作出自己相对应的改变。通过这种方式来达到减少依赖关系，解耦合的作用。 关键词：主题（Subject）、主题实现类、观察者 应用： Observable 类 Spring 的 ApplicationListener ApplicationEventMulticaster 作为主题，里面有添加，删除，通知等 策略模式 参考 关键词：Strategy（抽象策略）、ConcreteStrategy 策略实现、Context 可以搞一个抽象类（游泳）和实现类，然后 Context 里面维护一个 Map，Context get 了一个游泳（自由泳，其他也可以），get 里面发现 Map 没有，就 new 存入 Map，有就直接返回 也可以直接 new 一个返回 应用： ThreadPoolExecutor（HashSet）","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://kebabshellgithub.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Java 日志","slug":"日志","date":"2021-06-02T19:55:20.000Z","updated":"2023-04-06T11:06:55.042Z","comments":true,"path":"2021/06/02/日志/","link":"","permalink":"https://kebabshellgithub.github.io/2021/06/02/%E6%97%A5%E5%BF%97/","excerpt":"","text":"Java 日志 参考 待定。。。","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"摆烂了","slug":"摆烂了","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%86%E7%83%82%E4%BA%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"Spring中的多线程","slug":"Spring中的多线程","date":"2021-06-02T19:36:22.000Z","updated":"2023-04-06T11:06:55.030Z","comments":true,"path":"2021/06/02/Spring中的多线程/","link":"","permalink":"https://kebabshellgithub.github.io/2021/06/02/Spring%E4%B8%AD%E7%9A%84%E5%A4%9A%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"Spring 中的多线程@EnableAsync 开启 Spring Boot 对于异步任务的支持 配置类实现接口 AsyncConfigurator，返回一个 ThreadPoolTaskExecutor 线程池对象 @Async 注解表明该方法是异步方法，如果注解在类上，那表明这个类里面的所有方法都是异步的 通过 Future 来接受异步方法的处理结果","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"摆烂了","slug":"摆烂了","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%86%E7%83%82%E4%BA%86/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://kebabshellgithub.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://kebabshellgithub.github.io/tags/Spring/"}]},{"title":"Servlet","slug":"Servlet","date":"2021-06-02T18:53:17.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2021/06/02/Servlet/","link":"","permalink":"https://kebabshellgithub.github.io/2021/06/02/Servlet/","excerpt":"","text":"ServletHttpServlet、doGet、doPost等、service()等balabala 非线程安全 可以说单例 Servlet容器（Tomcat） … Spring MVC 的 DispatcherServlet 关键词： DispatcherServlet、Handler（Controller）、HandlerMethod（@RequestMapping） RequestMappingInfo、map&lt;RequestMappingInfo, HandlerMethod&gt;、urlMap&lt;url, RequestMappingInfo&gt; 在urlMap 中查询对应的url，获取RequestMappingInfo 在map中查询对应RequestMappingInfo，获取对应的HandlerMethod。该方法则是请求所对应的处理方法 https://juejin.cn/post/6844903735303503880 还有 RequestMapping：https://www.cnblogs.com/grasp/p/11100124.html","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"摆烂了","slug":"摆烂了","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%86%E7%83%82%E4%BA%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"Properties","slug":"Properties","date":"2021-06-02T17:12:45.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2021/06/02/Properties/","link":"","permalink":"https://kebabshellgithub.github.io/2021/06/02/Properties/","excerpt":"","text":"123456789101112Properties 属性集对象 属于Map集合 作用：可以把键值对数据存入到一个属性文件apisetProperty(_, _) 也就是put(_, _)getProperty(_)stringPropertyNames() 所有键的名称的集合store(OutputStream out, String comments) 保存数据到属性文件store(Writer fw, String comments) 保存数据到属性文件synchronized void load(InputStream is)synchronized void load(Reader fr) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * Created by KebabShell * on 2020/4/11 下午 04:22 */public class PropertiesTest &#123; /** * 存 * @throws Exception */ @Test public void test0() throws Exception&#123; Properties properties = new Properties(); properties.setProperty(&quot;name&quot;, &quot;kb&quot;); System.out.println(properties); FileOutputStream fos = new FileOutputStream(&quot;src/cn/kebabshell/test/util/properties/test.properties&quot;); properties.store(fos, &quot;this is comment&quot;); // fos.close(); // store会自动关闭fos &#125; /** * 取 * @throws Exception */ @Test public void test1() throws Exception&#123; Properties properties = new Properties(); FileInputStream fis = new FileInputStream(&quot;src/cn/kebabshell/test/util/properties/test.properties&quot;); properties.load(fis); System.out.println(properties); // System.out.println(properties.get(&quot;name&quot;)); System.out.println(properties.getProperty(&quot;name&quot;)); &#125; @Test public void test2() throws Exception&#123; Properties properties = new Properties(); FileReader fr = new FileReader(&quot;src/cn/kebabshell/test/util/properties/test.properties&quot;); properties.load(fr); System.out.println(properties); // System.out.println(properties.get(&quot;name&quot;)); System.out.println(properties.getProperty(&quot;name&quot;)); &#125;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"Java stream","slug":"stream","date":"2021-06-02T17:05:15.000Z","updated":"2023-04-06T11:06:55.034Z","comments":true,"path":"2021/06/02/stream/","link":"","permalink":"https://kebabshellgithub.github.io/2021/06/02/stream/","excerpt":"","text":"stream老是打成 steam 哈哈哈（不是 主要针对集合或数组 https://www.runoob.com/java/java8-streams.html 简化集合或数组api的弊端 整成链式编程 常用api forEach：逐一遍历 count：统计个数 filter：过滤元素 就是匿名内部类Predicate，符合返回true limit：取前几个元素 skip：跳过前几个 map：加工方法 concat：合并流 终结方法： forEach count 非终结方法： 每次调用返回 Stream 对象 收集 Stream 流： 把流的数据转成集合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138/** * Created by KebabShell * on 2020/4/8 下午 04:03 */public class StreamTest &#123; @Test public void test0()&#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(&quot;dd&quot;); list.add(&quot;dwe&quot;); list.add(&quot;dwq&quot;); list.add(&quot;qd&quot;); list.add(&quot;rd&quot;); //找出开头为d的 List&lt;String&gt; list_d = new ArrayList&lt;&gt;(); for (String s : list) &#123; if (s.startsWith(&quot;d&quot;))&#123; list_d.add(s); &#125; &#125; System.out.println(list_d); //找出开头为d的，长度为3的 List&lt;String&gt; list_d_3 = new ArrayList&lt;&gt;(); for (String s : list_d) &#123; if (s.length() == 3)&#123; list_d_3.add(s); &#125; &#125; System.out.println(list_d_3); /** * stream * * 淦，牛逼 */ list.stream() .filter(s -&gt; s.startsWith(&quot;d&quot;)) .filter(s -&gt; s.length() == 3) .forEach(System.out::println); /** * count */ long count = list.stream().count(); System.out.println(count); /** * limit 拿前两个 */ list.stream() .filter(s -&gt; s.length() == 3) .limit(2) .forEach(System.out::println); /** * skip 不要前两个 */ list.stream() .filter(s -&gt; s.length() == 3) .skip(2) .forEach(System.out::println); /** * 在后面加上123 */ list.stream().map(s -&gt; s + &quot;123&quot;).forEach(System.out::println); /** * 转成其他对象 */ list.stream().map(s -&gt; new StreamPerson(s)).forEach(System.out::println); //----&gt; list.stream().map(StreamPerson::new).forEach(System.out::println); /** * 合并流 */ Stream&lt;Integer&gt; s1 = Stream.of(1, 4, 3); Stream&lt;String&gt; s2 = list.stream(); Stream&lt;Object&gt; s1s2 = Stream.concat(s1, s2); s1s2.forEach(System.out::println); /** * 把流转为集合 */ Stream&lt;String&gt; stream = list.stream() .filter(s -&gt; s.startsWith(&quot;d&quot;)) .filter(s -&gt; s.length() == 3); Set&lt;String&gt; collect = stream.collect(Collectors.toSet()); /** * 转List */ Stream&lt;String&gt; stream1 = list.stream() .filter(s -&gt; s.startsWith(&quot;d&quot;)) .filter(s -&gt; s.length() == 3);//不加这句的话会报错，现在需要重新创建流 List&lt;String&gt; collect1 = stream1.collect(Collectors.toList()); /** * 转数组 */ Stream&lt;String&gt; stream2 = list.stream() .filter(s -&gt; s.startsWith(&quot;d&quot;)) .filter(s -&gt; s.length() == 3); Object[] objects = stream2.toArray(); //构造器引用 String[] strings = stream2.toArray(String[]::new); &#125; public static void main(String[] args) &#123; /** * Collection获取流 */ Collection&lt;String&gt; c = new ArrayList&lt;&gt;(); Stream&lt;String&gt; c_s = c.stream(); /** * Map集合获取流 */ Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); Stream&lt;String&gt; k_s = map.keySet().stream(); Stream&lt;Integer&gt; v_s = map.values().stream(); Stream&lt;Map.Entry&lt;String, Integer&gt;&gt; m_s = map.entrySet().stream(); /** * 数组获取流 */ String[] strings = &#123;&quot;ad&quot;, &quot;dag&quot;, &quot;dageae&quot;, &quot;vcz&quot;&#125;; Stream&lt;String&gt; s_s = Arrays.stream(strings); Stream&lt;String&gt; s_s2 = Stream.of(strings); &#125;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"String","slug":"String","date":"2021-06-02T17:00:48.000Z","updated":"2023-04-06T11:06:55.030Z","comments":true,"path":"2021/06/02/String/","link":"","permalink":"https://kebabshellgithub.github.io/2021/06/02/String/","excerpt":"","text":"String、StringBuilder、StringBuffer诶，可以，写了，没完全写，诶，就是玩儿~ 小TipsString 有长度限制，不管是编译期还是运行期，都不能超过 65535 编译期：JVM 限制，Class 常量池等 运行期：如高清图片转 BASE64，超过会抛异常","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"摆烂了","slug":"摆烂了","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%86%E7%83%82%E4%BA%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"Math","slug":"Math","date":"2021-06-02T16:56:18.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2021/06/02/Math/","link":"","permalink":"https://kebabshellgithub.github.io/2021/06/02/Math/","excerpt":"","text":"运算123456789101112131415161718192021222324252627282930/** * Created by KebabShell * on 2020/3/28 上午 10:41 */public class MathTest &#123; @Test public void test()&#123; double result = Math.sqrt(4); System.out.println(&quot;sqrt result:&quot; + result);//开方 result = Math.pow(4, 2); System.out.println(&quot;pow result:&quot; + result);//4的2次方 int i = Math.floorMod(5, 2);//5 % 2 System.out.println(&quot;i:&quot; + i); long round = Math.round(1.5); System.out.println(&quot;round:&quot; + round);//四舍五入 System.out.println(&quot;up:&quot; + Math.ceil(4.000000001));//向上取整 System.out.println(&quot;floor:&quot; + Math.floor(4.99999));//向下取整 &#125; @Test public void leftMove()&#123; int result = 3 &lt;&lt; 2; System.out.println(&quot;&lt;&lt;:&quot; + result);//左移一位都相当于乘以2的1次方，左移n位就相当于乘以2的n次方 &#125; @Test public void rightMove()&#123; int result = 12 &gt;&gt; 2; System.out.println(&quot;&gt;&gt;:&quot; + result);//右移n位相当于除以2的n次方 &#125;&#125; 大数： 12345678910111213141516171819202122232425262728293031/** * Created by KebabShell * on 2020/3/29 下午 04:50 */public class BigDecimalTest &#123; @Test public void test()&#123; //浮点型直接运算会失真 System.out.println(1.1 + 2.2); double a = 1.1; double b = 2.2; //不要new BigDecimal bigDecimal = BigDecimal.valueOf(a); BigDecimal bigDecimal1 = BigDecimal.valueOf(b); BigDecimal add = bigDecimal.add(bigDecimal1); System.out.println(add); // bigDecimal.divide() 除法 // bigDecimal.subtract() 减法 // bigDecimal.multiply() 乘法 //最终拿到double的数据 double value = bigDecimal.doubleValue(); int compare = Double.compare(1.1, 6.3);//比较 &#125;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"文件/IO流","slug":"文件","date":"2021-06-02T16:46:41.000Z","updated":"2023-04-06T11:06:55.042Z","comments":true,"path":"2021/06/02/文件/","link":"","permalink":"https://kebabshellgithub.github.io/2021/06/02/%E6%96%87%E4%BB%B6/","excerpt":"","text":"Java文件、IO流字符集12345678910111213141516171819202122232425字符集各个国家为自己的语言创造的一套编号规则计算机底层不能直接存储字符，只能存储二进制1B=8bit计算机最小单位B(字节)英文8bit为一组，1个字节2^8=256 1个字节可以表示256种情况a 97A 650 48ASCII中文一般16bit 2个字节表示一个中文字符GBK编码兼容ASCIIUnicode编码（万国码）变种 -&gt; UTF-8 一个中文一般占3个字节 流123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172ioFile类只能操作文件本身，不能读写按方向分类 输出流：把程序（内存）中的内容写出到磁盘 输入流：把磁盘/网络的内容读入程序（内存）按内容分类 字节流：流中的数据最小单位是字节 字符流：最小单位是字符（文本文件）按方向、内容分类： 字节输入流 字节输出流 字符输入流 字符输出流 InputStream | OutputStream | Reader | Writer | | | 上面是抽象类，下面是实现类 | | | | | FileInputStream | FileOutputStream | FileReader | FileWriter | | |BufferedInputStream | BufferedOutputStream| BufferedReader | BufferedWriter(提高性能) | | | | | InputStreamReader | OutputStreamWriter(解决乱码)构造可以传File或者路径字节流适合复制文件字符流适合中文字节缓冲输入流有一个默认的DEFAULT_BUFFER_SIZE = 8192 8KB的缓冲池从磁盘读文件，内容先到缓冲池（在内存），程序（内存）再从缓冲池读取字节缓冲输出流从程序（内存）向磁盘写数据，先写入内存中的缓冲池（也是8KB），再由操作系统写入磁盘字符缓冲输入流 √多了一个换行字符缓冲输出流输出流设置追加，要在原始的构造器添加true（FileInputStream(_, true)....）InputStreamReader字符输入转换流 可以把字节流按照默认或指定的编码转换成字符流 可以解决乱码 如果文件是GBK编码，程序代码是utf-8，需要InputStreamReader包装InputStream，设置编码OutputStreamReader字符输出转换流 能指定编码把字节输出流转换成字符输出流对象序列化ObjectOutputStream 把java对象实例直接存到文件对象反序列化ObjectInputStream 把文件存储的对象实例恢复为java对象实例目标对象 需要实现Serialize接口，如果成员变量加了transient修饰，这个变量不参与序列化（安全） private static final long serialVersionUID序列化版本号PrintStream打印流(字节)PrintWriter打印流(字符)极其强大 文件&#x3D;文件+文件夹 英文数字占一个字节中文占 文件路径 1正斜杠&#x2F; 2反斜杠\\（即需要转义） 3分隔符api File.separator .length()字节数 new file文件夹，得到的大小只是文件夹本身的大小，不包含里面的文件 不能删除非空文件夹 .lastModified()最后修改时间 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/** * Created by KebabShell * on 2020/4/9 下午 04:44 */public class FileTest &#123; @Test public void test0()&#123; File file = new File(&quot;E:\\\\影音\\\\me.jpg&quot;); System.out.println(file.length()); &#125; @Test public void test1()&#123; File file = new File(&quot;src/cn/kebabshell/test/file/字符集.txt&quot;); System.out.println(file.exists()); System.out.println(file.length()); &#125; @Test public void test2()&#123; File file = new File(&quot;src/cn/kebabshell/test/file&quot;); System.out.println(file.length()); System.out.println(file.exists()); &#125; @Test public void test3()&#123; File file = new File(&quot;src/cn/kebabshell/test/file/字符集.txt&quot;); File file1 = new File(&quot;E:\\\\影音\\\\me.jpg&quot;); File file2 = new File(&quot;src/cn/kebabshell/test/file&quot;); System.out.println(file.getAbsolutePath()); System.out.println(file.getPath()); System.out.println(file1.getPath()); // D:\\IDEA\\AllPojects\\JavaSourceLearn\\src\\cn\\kebabshell\\test\\file // src\\cn\\kebabshell\\test\\file获取文件定义时使用的路径 // E:\\影音\\me.jpg System.out.println(file.getName());//带后缀 System.out.println(file.length());//拿字节数 System.out.println(file.isFile()); System.out.println(file2.isDirectory()); &#125; @Test public void test4() throws IOException &#123; File file = new File(&quot;src/cn/kebabshell/test/file/test.txt&quot;); System.out.println(file.createNewFile()); &#125; @Test public void test5()&#123; File file = new File(&quot;src/cn/kebabshell/test/file/test&quot;); System.out.println(file.mkdirs()); &#125; @Test public void test6()&#123; //遍历 File dir = new File(&quot;src/cn/kebabshell/test/file&quot;); //取到的只是字符串 String[] list = dir.list(); for (String fileName : list) &#123; System.out.println(fileName); &#125;//只是一级目录 //取到的是File对象 File[] listFiles = dir.listFiles(); for (File f : listFiles) &#123; System.out.print(f.length() + &quot;----&quot;); SimpleDateFormat format = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); //最后修改时间 System.out.println(format.format(f.lastModified())); &#125; //递归搜索 File gotFile = searchFile(dir, &quot;test.txt&quot;); if (gotFile != null)&#123; System.out.println(gotFile.length()); &#125; &#125; File searchFile(File dir, String name)&#123; if (dir.exists() &amp;&amp; dir.isDirectory())&#123; File[] listFiles = dir.listFiles(); if (listFiles != null &amp;&amp; listFiles.length != 0)&#123; for (File file : listFiles) &#123; if (file.isFile())&#123; if (file.getName().equals(name))&#123; return file; &#125; &#125;else &#123; searchFile(file, name); &#125; &#125; &#125; &#125; return null; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * Created by KebabShell * on 2020/4/11 下午 09:31 */public class CopyDirTest &#123; @Test public void test0() &#123; copyDir(new File(&quot;src/cn/kebabshell/test/file/cptest&quot;), new File(&quot;src/cn/kebabshell/test/file/cptest_bak&quot;)); &#125; public void copyDir(File srcDir, File destDir) &#123; //判断是否合法 if (srcDir.exists() &amp;&amp; srcDir.isDirectory()) &#123; //创建目标文件夹 destDir.mkdirs(); //拿到一级文件 File[] files = srcDir.listFiles(); //判断合法性，有些操作系统用户没有权限，会返回null或者其他 if (files != null &amp;&amp; files.length &gt; 0) &#123; //遍历数组 for (File file : files) &#123; //如果是文件，复制 if (file.isFile()) &#123; copyFile(file, new File(destDir, file.getName())); &#125; else &#123; //如果是目录 copyDir(file, new File(destDir, file.getName())); &#125; &#125; &#125; &#125; &#125; public void copyFile(File srcFile, File destDir) &#123; //复制，使用缓冲流，用一个一个字节 try (InputStream fis = new FileInputStream(srcFile); BufferedInputStream bis = new BufferedInputStream(fis); OutputStream fos = new FileOutputStream(destDir); BufferedOutputStream bos = new BufferedOutputStream(fos)) &#123; byte[] bytes = new byte[1024]; int len; while ((len = bis.read(bytes)) != -1) &#123; bos.write(bytes, 0, len); &#125; System.out.println(&quot;success&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"Java 注解","slug":"注解","date":"2021-06-02T16:32:48.000Z","updated":"2023-04-06T11:06:55.042Z","comments":true,"path":"2021/06/02/注解/","link":"","permalink":"https://kebabshellgithub.github.io/2021/06/02/%E6%B3%A8%E8%A7%A3/","excerpt":"","text":"自定义注解 123456修饰符 @interface 注解名&#123; //注解属性 数据类型 属性名() 数据类型 属性名() default 默认值&#125; 12345678元注解@Target @Retention用来注解自定义注解 是用在自定义注解的注解@Target 约束自定义注解只能在哪些地方使用 TYPE...@Retention 申明注解的生命周期 SOURCE 只作用在源码阶段 CLASS(默认) 字节码文件，执行就没了 RUNTIME 一直存在 1234567891011121314151617181920@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@interface Book &#123; String name(); double price(); String madeBy() default &quot;paper&quot;;&#125;@Book(name = &quot;hhh&quot;, price = 123)class parseTest&#123; @Book(name = &quot;method&quot;, price = 334) private void test()&#123; System.out.println(&quot;test&quot;); &#125;&#125; 12345678910Annotation 是所有注解的父类AnnotatedElement 定义了与注解解析相关的方法 所有Class、Method、。。。都实现了AnnotatedElement接口 都拥有解析注解的能力 1、Annotation[] getDeclaredAnnotations() 获得当前对象上使用的所有注解 2、T getDeclaredAnnotation(Class&lt;T&gt; annotationClass) 根据注解类型获得对应的注解对象 3、boolean isAnnotationPresent(Class&lt;Annotation&gt; annotationClass) 判断当前对象是否使用了指定的注解，使用了返回true 123456789101112131415161718192021@Testpublic void test() throws NoSuchMethodException &#123; //通过反射拿 Class parseTestClass = parseTest.class; //判断这个类上是否使用了某个注解 if (parseTestClass.isAnnotationPresent(Book.class))&#123; //获取注解对象 Book book = (Book) parseTestClass.getDeclaredAnnotation(Book.class); //拿值 System.out.println(book.name()); &#125; //通过类拿到方法对象 Method test = parseTestClass.getDeclaredMethod(&quot;test&quot;); //判断 if (test.isAnnotationPresent(Book.class))&#123; Book b = test.getDeclaredAnnotation(Book.class); System.out.println(b.name()); &#125;&#125; https://juejin.cn/post/6844904167517995022 https://juejin.cn/post/6844904168491073543","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"正则表达式","slug":"Regex","date":"2021-06-02T16:18:02.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2021/06/02/Regex/","link":"","permalink":"https://kebabshellgithub.github.io/2021/06/02/Regex/","excerpt":"","text":"12345678910111213141516171819/** * . 任何字符 * \\d 数字[0-9] * \\D 非数字， [^0-9] * \\s 空白字符 * \\S 非空白字符 * \\w 单词字符 [a-z A-Z 0-9 _] 字母数字下划线 * \\W 非单词字符 * * 以上都只是判断一个字符 * * * X? X一次或一次也没有 * X* X零次或多次 * X+ X一次或多次 * X&#123;n&#125; X恰好n次 * X&#123;n,&#125; X至少n次 * X&#123;n,m&#125; X至少n次，不超过m次 */","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[]},{"title":"JVM 基础","slug":"JVM基础","date":"2021-03-17T10:21:25.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2021/03/17/JVM基础/","link":"","permalink":"https://kebabshellgithub.github.io/2021/03/17/JVM%E5%9F%BA%E7%A1%80/","excerpt":"","text":"JVM 基础中的基础一个进程对应一个JVM实例，对应一个堆栈+方法区 运行时数据区域 P43 程序计数器（PC寄存器 - Program Counter Register） 行号指示器、“线程私有”、本地方法计数器为空（undefined）、用来存储指向下一条指令的地址… 切换线程需要知道下一次执行之前线程的地址 虚拟机栈 每个线程创建时都会创建一个虚拟机栈，内部有一个个的栈帧，线程私有 每个方法 - 栈帧（局部变量表（主要）、操作数栈、动态链接、方法出口…）（入栈到出栈） 保存方法的局部变量、部分结果，参与方法的调用与返回 栈溢出（如递归，会StackOverflowError，而栈如果动态扩容超过内存物理大小，则会 OOM） 这里不存在gc 栈的存储单位 - 栈帧（P294）局部变量表（本地变量表） 方法参数和方法的局部变量 最小单位是变量槽（Variable Slot），就是个数组 对于64位数据类型，JVM会高位对齐，为其分配两个槽（long、double） this 有在里面，也是个变量 静态方法中，不能使用 this，因为 this 不会在这个方法的局部变量表，因为 this 代表对象实例，而静态是随类加载而加载，先于实例就有了，所以 this 放进去没卵用 变量表大小是编译时就确定了，运行时不能更改 JVM通过索引定位使用变量表 槽是可以重用的，即有些变量是很小的作用域，超过的话这个槽就会被重用 因为是线程独占私有的，所以不存在并发问题 局部变量不会有默认值&#x2F;初始值，在使用前必须要显式赋值 局部变量表存的对象引用和 GC 密切相关 操作数栈（操作栈） 用数组实现，LIFO push、store。。。（方法中） 保存计算过程的中间结果，同时作为计算过程中变量的临时存储空间 栈中的任何一个元素都可以是任意的Java类型 32位占用一个栈深度 64两个 栈的最大深度在编译期就定义好了 byte、short、char、boolean都以int来保存 ++i 和 i++ 的区别 栈顶缓存（HotSpot）：栈顶元素全部缓存在物理CPU的寄存器，提高执行引擎效率 动态链接 即指向运行时常量池中该栈帧所属方法的引用（如#6等），动态链接的作用是将这些方法引用转换为直接引用 （Class 常量池的内容会存放到运行时常量池（如：子类调用父类方法，调用其他类的方法）） 下面只是说明 Class 常量池 每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态连接(Dynamic Linking)。Class文件的常量池中存有大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符号引用作为参数。这些符号引用一部分会在类加载阶段或者第一次使用的时候就转化为直接引用，这种转化称为静态解析。另外一部分将在每一次运行期间转化为直接引用，这部分称为动态连接 math.compute()调用时compute()叫符号，需要通过compute()这个符号去到常量池中去找到对应方法的符号引用，运行时将通过符号引用找到方法的字节码指令的内存地址。 方法返回值&#x2F;返回地址（P300）栈顶方法返回该方法被调用的位置 正常调用返回 主调方法的PC计数器的值作为返回地址，保存在栈帧 异常返回 返回地址通过异常处理器表来确定，栈帧不会保存信息 附加消息 其他信息 动态链接+方法返回地址+附加消息 &#x3D; 帧数据区（或栈帧信息（深入了解JVM）） 代码跟踪 静态链接和动态链接 静态，编译期就确定的 动态：编译期无法确定，如多态的方法调用 方法的调用：解析+分派（P301） 方法调用 invokestatic：调静态方法 invokespecial：调构造器（&lt;init&gt;()）方法 invokevirtual：调虚方法 注意：final方法是非虚方法，但是是用invokevirtual调用（历史设计） invokeinterface：调接口方法，会在运行时再确定实现该接口的对象 invokedynamic：运行时动态解析出所引用的方法，再执行 invokestatic和invokespecial+final（invokevirtual）是都是静态的，编译期就把符号引用转为直接引用，即非虚，其他为虚方法 分派有静态也有动态 动态：如多态的重写 OutOfMemoryError StackOverflowError 设置 -Xsssize：-Xss1m、-Xss1024k、-Xss1048576 本地方法栈 与虚拟机栈作用相似 HotSpot直接把虚拟机栈和本地方法栈合二为一 OutOfMemoryError StackOverflowError 堆 内存最大的一块 物理内存不连续，逻辑是连续的（虚拟内存（见操作系统）） 被所有线程共享 但是：堆里可以划分线程私有的缓冲区 thread local allocation buffer 虚拟机启动时创建 这个区域的唯一目的就是存放对象实例 也称为 GC 堆 分代设计：新生代、老年代、永久代（JDK 8 没了，改用本地内存中实现的元空间）、Eden 空间、From&#x2F;To Survivor 空间… 细分的目的只是为了更好的回收内存，更好的分配内存 可扩展：-Xms、-Xmx、-XX OOM 年轻代 &amp; 老年代test 内存结构7及以前：新生代区域、老年代区域、永久代区域（PSPermGen） 8及以后：新生代区域、老年代区域、元空间（Metaspace） Young Gen 新生代区域 Eden 区 Survivor 0 Survivor 1 Old Gen 老年代区域 元空间 Metaspace（可通过 -XX:+PrintGCDetails 显示） 内存分配策略test 对象分配过程TLAB（堆里可以划分线程私有的缓冲区 thread local allocation buffer） test 逃逸分析 &amp; 栈上分配test Minor GC &amp; Major GC &amp; Full GCtest 方法区（元数据区&#x2F;堆外内存。1.8）（堆外内存也包括JIT编译产物） Method Area （只有 HotSpot 有 被所有线程共享 存储已经被虚拟机加载的类型信息、常量、静态变量… 是堆的一个逻辑部分，但叫做“非堆（Non-Heap）” OutOfMemoryError（如动态类，即 CGLib 那些，可能导致 OOM 运行时常量池 方法区的一部分 常量池表 Constant Pool Table，用于存放编译期生成的字面量和符号引用（字符串，能根据这个字符串定位到指定的数据，比如java&#x2F;lang&#x2F;StringBuilder），这部分内容将在类加载后存放到运行时常量池 具备动态性：运行期间也可以将新的常量放入池中（String#intern） OutOfMemoryError 直接内存 不是运行时数据区域的一部分 OutOfMemoryError JDK 1.4 有 NIO，基于通道与缓冲区，使用 Native 函数库直接分配堆外内存，然后通过一个存储在堆里的 DirectByteBuffer 对象作为这块内存的引用进行操作，避免了在堆与 Native 堆之间来回复制 本机直接内存的分配不会受到限制，但是会受到总内存的限制，也会OOM 执行引擎等 HotSpot 对象创建 简单版 P48 取决于 Java 堆是否规整 指针碰撞 空闲列表 并发下分配内存方式 CAS 每个线程在 Java 堆中预先分配一小块内存，称为本地线程分配缓冲（TLAB），哪个线程要分配内存，就在自己的本地缓冲区分配，只有缓冲区用完，分配新的缓冲区才需要同步锁定 是否使用 TLAB：-XX:+&#x2F;-UserTLAB 内存分配完成后，虚拟机把内存空间初始化为零值，保证实例字段能直接访问到 设置对象头信息，如这个对象是哪个类的实例、元数据信息、哈希码、GC 分代年龄、偏向锁… 这时候构造函数还没执行，都还是默认零值，如何初始化有程序员决定 HotSpot 对象内存布局 P51 对象头（Header） 存储对象自身运行时数据（32 位虚拟机为 32 个比特；64 为 64 个比特） （Mark Word） 类型指针，指向类型元数据，确定该对象是哪个类的实例（找元数据不一定要经过对象本身） 如果是数组，还有一块数据是记录数组长度 实例数据（Instance Data） 无论是从父类来的，还是定义的，都在这里记录 对齐填充（Padding） 仅仅起到占位符的作用 HotSpot 要求对象起始地址必须为 8 字节的整数倍，所以任何对象的大小都必须是 8 字节的整数倍 对象的定位通过栈上的 reference 引用来操作堆上的具体对象。 引用的定位实现是由虚拟机决定的，没有一定。 主流有两种 句柄 堆中可能要划分出一块内存来作为句柄池，reference 中存的就是对象的句柄地址 句柄包含了对象实例数据与类型数据各自具体的地址信息 直接指针 句柄最大的好处就是，对象被移动的时候只会改变句柄中实例数据指针，而 reference 本身不改变 直接指针最大的好处是快，开销少 HotSpot 主要使用直接指针 对于内存泄漏和溢出分析工具：Eclipse Memory Analyzer 作者：McAce链接：https://www.zhihu.com/question/40560123/answer/512873873来源：知乎 内存泄露本意是申请的内存空间没有被正确释放，导致后续程序里这块内存被永远占用（不可达），而且指向这块内存空间的指针不再存在时，这块内存也就永远不可达了，内存空间就这么一点点被蚕食，借用别人的比喻就是：比如有10张纸，本来一人一张，画完自己擦了还回去，别人可以继续画，现在有个坏蛋要了纸不擦不还，然后还跑了找不到人了，如此就只剩下9张纸给别人用了，这样的人多起来后，最后大家一张纸都没有了。 内存溢出是指存储的数据超出了指定空间的大小，这时数据就会越界，举例来说，常见的溢出，是指在栈空间里，分配了超过数组长度的数据，导致多出来的数据覆盖了栈空间其他位置的数据，这种情况发生时，可能会导致程序出现各种难排查的异常行为，或是被有心人利用，修改特定位置的变量数据达到溢出攻击的目的。而Java中的内存溢出，一般指【OOM：发生位置】这种Error，它更像是一种内存空间不足时发生的错误，并且也不会导致溢出攻击这种问题，举例来说，堆里能存10个数，分了11个数进去，堆就溢出了1个数，JVM会检测、避免、报告这种问题，所以虽然实际上JVM规避了内存溢出带来的问题，但在概念上来说，它确实是溢出才导致的，只是Java程序员在看到这个问题时，脑袋里的反应会是“内存不够了，咋回事，是不是又是哪个大对象没释放”之类，而不是像C程序员“我X被攻击了&#x2F;程序咋写的搞溢出了”（这段是我臆想的）。同时对于Java来说，传统意义的溢出攻击也无法奏效，因为Java的数组会检查下标，对超出数组下标的赋值会报ArrayOutOfIndex错误。 而内存泄露的话，个人意见在Java里是不存在的，gc采用根搜索算法时，不可达的对象会被回收，gc是会搜索回收这些空间的，由于程序员个人问题，没用的对象不回收但可达，这种情况能不能界定为内存泄露，我觉得是个哲学问题（对象可达，但空间被占用了，对象也不再使用了），个人觉得是不能界定为内存泄露的。 底下评论： java 中也会存在内存泄露的，比如在使用 ThreadLocal 这个类时，就易发生内存泄露。 内存泄漏在早期 java 版本中比较多，主要是 hotspot 没对 method area 进行有效回收导致的 字符串常量池 P63 12345String str1 = new StringBuilder(&quot;计算机&quot;).append(&quot;软件&quot;).toString();System.out.println(str1.intern() == str1); // JDK 6: false; JDK 7: trueString str2 = new StringBuilder(&quot;ja&quot;).append(&quot;va&quot;).toString();System.out.println(str2.intern() == str2); // JDK 6: false; JDK 7: false JDK 6 中，intern 会把首次遇到的字符串实例复制到永久代的字符串常量池，返回的也是永久代里面这个字符串实例的引用，而 StringBuilder 创建的字符串对象实例是在 Java 堆上的，所以不可能是同一个引用 JDK 7 中 intern 不再需要拷贝字符串实例到永久代，字符串常量池已经移到了 Java 堆中。只需要在常量池中记录首次出现的实例引用即可，所以 intern 返回的引用和 StringBuilder 创建的字符串实例就是同一个 而“java”已经出现过，字符串常量池已经有他的引用，所以为 false（之前有进入常量池） 垃圾收集java的垃圾收集机制主要针对新生代和老年代的内存进行回收，不同的垃圾收集算法针对不同的区域。所以java的垃圾收集算法使用的是分代回收。一般java的对象首先进入新生代的Eden区域，当进行GC的时候会回收新生代的区域，新生代一般采用复制收集算法，将活着的对象复制到survivor区域中，如果survivor区域装在不下，就查看老年代是否有足够的空间装下新生代中的对象，如果能装下就装下，否则老年代就执行FULL GC回收自己，老年代还是装不下，就会抛出OUtOfMemory的异常 判断对象是否存活 引用计数 有一个地方引用对象，对象的计数器加一，引用失效，计数器减一，计数器为零就是不可能再被使用 简单，效率高 难以解决对象之间相互循环引用的问题 可达性分析 GC Roots。对象到 GC Roots 不可达时，就会被判定可回收 引用 强引用、软引用、弱引用、虚引用 对象死亡 一个对象的死亡，至少要经历两次标记（标记指的是到 GC Roots 不可达时标记这个对象） 第一次标记完，会有一次筛选，看看对象有没有必要执行 finalize 方法 对象没覆盖 finalize 方法&#x2F;finalize 方法已经被虚拟机调用，就没必要 如果有必要，对象放入 F-Queue，虚拟机会去触发对象的 finalize 方法（不会等他） 收集器会继续对 F-Queue 中的对象进行第二次标记，如果对象重新与引用链上的对象建立关联，就能活下来 不建议使用 finalize 方法，用 try-finally 分代收集 收集器应该将 Java 堆分为不同区域，将回收对象依据年龄（对象逃过垃圾收集的次数）扔到不同的区域存储 Minor GC、Major GC、Full GC 新生代 Young Generation、老年代 Old Generation 算法 标记-清除 标记-复制 标记-整理 HotSpost 算法实现- 类加载双亲委派 P281、283 父子关系非继承，而是组合的方式来复用父加载器的代码 一个类加载器收到类加载的请求，首先不会自己尝试加载，而是把这个请求委派给父加载器去加载，因此所有的加载都会被委派到最顶层的启动类加载器。 只有上层的无法加载，下面的小弟才会尝试加载 不然的话，要是用户自己写了个 Object 类，放到 ClassPath，就会有不同的加载器加载了不同的 Object 类 实现双亲委派的代码在 java.lang.ClassLoader 的 loadClass 方法中 类加载器启动（引导）类加载器、扩展类加载器、应用程序加载器（也叫系统类加载器） 图同上 ↑ P282 启动类加载器是无法被引用的，null 对于自定义加载器 作用主要有 添加除磁盘外的 Class 来源 隔离、重载（防止不同中间件的冲突） 防止源码泄露 继承 ClassLoader，重写 findClass 沙箱安全机制保护源码的安全性 自定义类如 String 类，加载时会率先使用引导类加载器，而不是自定义类的应用程序加载器 JVM 中对象是否是同一个： 完整类名 类加载器 类加载机制加载 - 连接（验证-准备-解析）- 初始化 加载（字节流 拿到类的类型数据（包括使用的类加载器（启动类加载器无法引用，为 null）），放到方法区（8 就是元空间了），然后在堆实例化一个 Class 对象，作为程序访问方法区的类型数据的入口 连接验证要保证字节码文件的正确性、安全性等 验证包括 文件格式、元数据、字节码、符号引用 准备为类中定义的静态变量分配内存还有设置初始值 7及以前，是方法区，而在8，类变量会随类对象一起到堆中 （这里不包括实例值，还只是初始值） 但要是静态变量还加了个 final，那就有赋值 解析Class 文件的常量池的符号引用转化为直接引用 初始化执行 类构造器方法 &lt;clinit&gt;() 要是没有静态语句块，也就没有这个 并且在静态中，是按顺序赋值的","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"摆烂了","slug":"摆烂了","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%86%E7%83%82%E4%BA%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://kebabshellgithub.github.io/tags/JVM/"}]},{"title":"操作系统","slug":"操作系统","date":"2021-01-10T16:24:23.000Z","updated":"2023-04-06T11:06:55.042Z","comments":true,"path":"2021/01/10/操作系统/","link":"","permalink":"https://kebabshellgithub.github.io/2021/01/10/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"操作系统 参考 参考 参考 用户态和内核态最简单的运行程序的方式是“直接执行”，即直接在 CPU 上执行任意程序。直接执行的问题是： 无法限制 无法进程调度 因此引入用户态和内核态和两种模式。用户态无法执行受限操作，如 I&#x2F;O 请求，执行这些操作会引发异常。内核态只能由操作系统运行，可以执行特权操作。用户程序通过系统调用执行这些特权操作。OS 执行前会判断进程是否有权限执行相应的指令 陷入内核态系统调用（trap）、中断（interrupt）和异常（exception） C 访问空指针会陷入内核态，访问指针相当于访问一个虚拟地址，直接映射到物理内存 进程与线程的区别 进程是一个拥有资源和执行任务的单元体。进程拥有的资源包括：内存空间中的代码、数据等；I&#x2F;O 资源；文件；处理机等。 线程是一个执行任务的单元体。线程只拥有处理机，线程之间共享进程的资源，如内存、I&#x2F;O 等。 为什么需要线程 只切换必需的、与处理机相关的信息，减少开销 当上下文切换的时候，正在运行的线程会将寄存器的状态保存到 TCB（Thread Control Block）里（进程是 PCB，Process Control Block），然后恢复另一个线程的上下文 问题就是并发，共享空间，一个线程出错，整个进程都会结束（使用多进程解决） 同一进程中的线程共享与独占的资源 共享 内存空间 代码 公共数据（全局变量、静态变量） 堆 文件描述符 信号处理器 进程 ID &#x2F; 进程组 ID 。。。 独占 线程 ID 栈（函数调用） 错误返回码 信号屏蔽码 作业、管程 作业：用户在一次解题或一个事务处理过程中要求计算机系统所做工作的集合。它包括用户程序、所需要的数据及控制命令等。作业时由一系列有序的步骤组成的 管程：是定义了一个数据结构和在该数据结构上能为并发进程所执行的一组操作。这些操作能同步进程和改变管程中的数据。它是一种进程同步机制。在结构上类似于面向对象中的类。在功能上和信号量和p，v操作类似。可以更方便的管理系统的临界资源 进程的三种基本状态 就绪：进程已获得除处理机以外的所需资源，等待分配处理机资源 执行：进程正在占用处理机资源执行 阻塞：进程等待某种条件，在条件满足之前无法执行。如发起了 I&#x2F;O 系统调用，会被阻塞，等待 I&#x2F;O 中断发生 注意挂起和阻塞的区别 “挂起”是指将暂不执行的进程换出到外存，节省内存空间 挂起就绪状态：进程在外存中，但是只要被载入内存就可以执行 挂起阻塞状态：进程在外存中并等待一个事件，即使被载入内存（激活）也无法运行 Linux 下的阻塞状态可分为 3 种：暂停、浅睡眠、深睡眠 若不需要等待资源，则切换为“暂停”；若需要等待资源，切换为“睡眠”；如果睡眠状态能被信号唤醒，则是“浅睡眠”，否则是“深睡眠” Linux 进程的 5 种状态进程调度算法 注意饥饿问题、僵尸进程（僵尸进程、孤儿进程、守护进程） 批处理系统 先来先服务 FCFS、最短作业优先 SJF、最短剩余时间优先 SRTN、最高响应比优先 HRRN 交互系统（分时系统） 时间片轮转 RR、优先级调度 Priority、多级反馈队列 MFQ、彩票法、公平分享法 实时系统 最早截止时间优先算法 僵尸进程、孤儿进程、守护进程 参考 僵尸进程：停止运行 孤儿进程：正在运行 守护进程：正在运行 进程通信（同步）方式（IPC） 信号 管道 匿名管道和命名管道 匿名管道（pipe） 只能用在亲缘进程中，管道文件信息保存在内存里 本质是一个伪文件(实为内核缓冲区)，由两个文件描述符引用，一个表示读端，一个表示写端 下游进程或者上游进程需要等另一方释放锁后才能操作管道。管道就相当于一个文件，同一时刻只能有一个进程访问 数据自己读不能自己写 管道不再被任何进程使用时，自动消失，生命周期随进程的结束结束 命名管道（FIFO） 以FIFO的文件形式存储于文件系统中，因此，可用于没有亲缘的进程间 也是通过内核缓冲区来实现数据传输 建立命名管道时，会在磁盘中创建一个索引节点，命名管道的名字就相当于索引节点的文件名 当不再被任何进程使用时，命名管道在内存中释放，但磁盘节点仍然存在 管道是由内核管理的一个缓冲区，缓冲区被设计成为环形的数据结构，以便管道可以被循环利用（循环队列） 信号量 Semaphore S 表示可用资源的数量 P(S) 即 down 请求分配一个单位资源，减少信号量 S 的数值，如果 S 为 0，则挂起进程 V(S) 即 up 释放资源，若S&gt;0，唤醒等待队列中的一个进程，增加信号量 S 的数值， 如果信号量只有二进制的 0 或 1，称为二进制信号量（binary semaphore）。二进制信号量可以用来实现一个互斥锁（Mutex） 共享内存 管道和消息队列，需要在内核和用户空间进行四次的数据拷贝（读输入文件、写到管道；读管道、写到输出文件），而共享内存则只拷贝两次（一次从输入文件到共享内存区，另一次从共享内存到输出文件） 缺点是存在并发问题 消息队列 接收者必须轮询消息队列，才能收到最近的消息 与管道相比，消息队列提供了有格式的数据，但消息队列仍然有大小限制 套接字 不同的计算机的进程之间通过 socket 通信，也可用于同一台计算机的不同进程 主机地址与端口号 网络层 锁 互斥锁、读写锁、自旋锁、条件锁 互斥锁的开销主要体现在线程的重新调度和上下文切换上，获取锁的开销是比较大的。因此 mutex 适用于线程持有锁时间比较长的场景 临界资源和临界区、互斥与同步 临界资源：一次仅允许一个进程使用的共享资源，也就是互斥资源 临界区：程序中访问临界资源的那段代码，也称危险区、敏感区 互斥：多个程序片段，同一时刻仅有一个能进入临界区 同步：若干程序片断运行必须严格按照规定的某种先后次序来运行。同步是一种更复杂的互斥：互斥不会限制程序对资源的访问顺序，即访问是无序的；而同步必须要按照某种次序来运行 常见的同步问题 生产者与消费者问题 生产者和消费者共享固定大小的缓冲区，生产者向缓冲区写入数据，消费者从缓冲区读出数据，生产者不能在缓冲区满时加入数据，消费者也不能在缓冲区空时消耗数据 这里如果直接使用操作系统提供的 sleep() 和 wakeup()，可能发生死锁，原因在于：「判断是否要休眠（缓冲区空&#x2F;满）」和「执行 sleep()」不是一个原子操作，有可能在执行 sleep() 之前被切换到另一个程序，导致 wakeup() 信号丢失，最后两者都进入休眠 使用信号量可以解决上述问题 在多个生产者和消费者的情况下，有可能出现两个或以上的进程同时读或写同一个缓冲区槽的情况，因此再用一个二值信号量 mutex 实现一个锁 读者写者问题 允许多个进程同时读数据库 有进程在读数据库的时候，不允许写数据库 如果有一个进程正在写数据库，则不允许其他任何进程访问数据库 浴室洗澡问题 一个浴室，当有一个女生在浴室里，其他女生可以进入，但是男生不行，反之亦然 哲学家就餐问题 假设有五位哲学家围坐在一张圆形餐桌旁，吃饭或者思考。每位哲学家之间各有一根筷子，哲学家必须用两根筷子吃东西。他们只能使用自己左右手边的那两根筷子 可能有死锁的写法：每个哲学家都拿着左边的筷子，永远都在等右边的筷子 死锁产生的四个必要条件 互斥条件 占有且等待条件：线程占有已经分配给它们的资源（如锁）并且等待其他的资源（也就是说不会主动释放） 不可抢占条件（也就是说不会被动释放） 环路等待条件：每个进程都在等待下一个进程占有的资源 死锁的避免破坏上面四个条件任意一个，但很难，所以 银行家算法：允许系统中同时存在四个必要条件，但是每当进程提出资源申请时，系统要分析满足该资源请求后，系统是否会发生死锁，若不会发生则实施分配，否则拒绝分配，即 通过先 试探 分配给该进程资源，然后通过安全性算法判断分配后的系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待 线程通信（同步）方式 信号，使用方法和进程几乎一样，但是是另一套相似的API，不可以互换 信号量，和进程类似，功能和互斥锁基本一样 互斥锁，保护临界资源 控制变量，常和互斥锁配合使用，控制线程执行的先后。暂时挂起线程还锁，解决线程为获得数据等待其他线程，导致长时间占用锁 内存抖动指内存频繁地分配和回收，占用了大量CPU时间 物理内存管理 内部碎片和外部碎片 内部碎片是固定分区法产生的，指被占用分区上未被利用的空间，由于该分区被占用，因此无法被分配使用 外部碎片是动态分区法产生的，指被占用分区之间的小空间，虽然可以被使用，但是由于太小而无法被分配 解决： 页面管理算法（Linux） Buddy（伙伴）分配算法 把相同大小的页框块用链表串起来 所有的空闲页框分组为11个块链表，每个块链表分别包含大小为1，2，4，8，16，32，64，128，256，512和1024个连续页框的页框块。最大可以申请1024个连续页框，对应4MB大小的连续内存 因为任何正整数都可以由 2^n 的和组成，所以总能找到合适大小的内存块分配出去，减少了外部碎片产生 slab 分配器 通过将内存按使用对象不同再划分成不同大小的空间，应用于内核对象的缓存 内核中有大量的小对象，对于每个内核中的相同类型的对象，如：task_struct、file_struct 等需要重复使用的小型内核数据对象，都会有个 slab 缓存池，缓存住大量常用的「已经初始化」的对象，每当要申请这种类型的对象时，就从缓存池的slab 列表中分配一个出去；而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免内部碎片，同时也大大提高了内存分配性能 slab 内存分配器是对伙伴分配算法的补充 slab 高速缓存分为两大类，通用高速缓存和专用高速缓存 固定分区法（等长、不等长） 动态分区法 页式内存管理 把固定分区面积缩小，一个进程可使用多个分区；进程被分割成若干块，装入内存中的几个分区中，物理上无需相连，逻辑上通过页表关联 段式内存管理 按照逻辑意义将程序分成若干个段，每个段独立载入到内存的不同区间中 缺点：每个段必须连续、全部加载到内存中 段页式内存管理 先把程序按照逻辑意义分成段，然后每个段再分成固定大小的页 页面、页框、页表 页表：每个进程有一个页表，描述该进程每个页面对应的页框号，以及该页面是否已经被载入内存（“在&#x2F;不在”位） 对大内存页表 多级页表 时间换空间，节省空间，时间可以用 TLB 来缓解 倒排页表 散列表 虚拟内存管理 原先的覆盖、交换技术太垃圾 虚存管理和覆盖技术一样，不是把程序所有内容全部放入内存，但这个操作是由操作系统完成，而不是程序员 和交换技术一样，实现进程在内存和外存的交换，但虚存管理做的更好，是只对进程的部分内容在内存和外存之间交换 需要有程序局部性（要有时间、空间局部性） P23 指程序在执行过程中的一个较短时期，所执行的指令地址和指令的操作数地址，分别局限于一定区域 物理内存分配不连续，虚拟地址空间使用不连续 简略实现 在系统中为每个程序定义一个虚拟地址空间，虚拟地址空间中的地址都是连续的 虚拟地址空间被分割成多个块，每块称为一个页或者页面 物理内存被分成和页面大小相同的多个区域，称作页框 程序加载时，可将任意一个页面放入内存中的任意一个页框 CPU 的硬件负责将虚拟地址映射到物理内存中的地址（页面 -&gt; 页框） 程序的整个地址空间无需全部载入物理内存，还有部分暂时存储在外存上，需要时再换入内存 如果程序引用到一部分不在物理内存中的虚拟地址时，会发生缺页中断，由操作系统负责将缺失的页面加载入页框中，并重新执行失败的指令 交换分区 转换检测缓冲区（TLB） 缓冲页表 缺页中断&#x2F;异常 请求调页和页面置换 页面置换&#x2F;淘汰 目的是减少页面换入换出的次数 局部页面置换算法 最优页面置换算法 判断未来，是理想情况，实际中不可能实现 这是评价标准 FIFO LRU 最近最久未使用 （算法题：链表 + 哈希表） 第二次机会算法 FIFO 的改进 时钟页面置换算法（Clock 算法） LRU 近似 + 第二次机会置换法的改进 将页面保存在环形链表中，只需要后移队头指针，就相当于是把原来的队头放到队尾了，避免了移动链表节点的开销 LFU 最不常用 Belady 现象：FIFO时，可能会出现分配的物理页面增多，缺页率反而提高 LRU 性能好，但开销大，FIFO 开销小，但会 Belady；还是 Clock 算法折中 全局页面置换算法 工作集页置换算法 缺页率置换算法 Linux虚存用户空间内存分配 malloc 当申请小于 128KB 小内存的时， malloc 使用 sbrk 或 brk 分配内存；当申请大于 128KB 的内存时，使用 mmap 函数申请内存 由于 brk&#x2F;sbrk&#x2F;mmap 属于系统调用，cpu 在用户态和内核态之间频繁切换 解决：malloc 使用的是内存池 先申请一块大内存，然后将内存分成不同大小的内存块，然后用户申请内存时，直接从内存池中选择一块相近的内存块分配出去 内核空间内存分配 kmalloc 分配的虚拟地址范围在内核空间的直接内存映射区 基于 slab 分配器 按字节为单位虚拟内存，一般用于分配小块内存，释放内存对应于 kfree ，可以分配连续的物理内存 vmalloc 分配的虚拟地址区间，位于 vmalloc_start 与 vmalloc_end 之间的动态内存映射区 （内核页表） 一般用分配大块内存，释放内存对应于 vfree，分配的虚拟内存地址连续，物理地址上不一定连续 两个再通过 Buddy 分配内存 文件系统 文件块 卷控制模块、控制块、目录节点会部分加载进内存以提高访问效率 文件表 层次目录结构 路径遍历 种类 磁盘文件系统：FAT、NTFS、ext2&#x2F;3&#x2F;4… 数据库文件系统 日志文件系统 。。。 虚拟文件系统 可以说整合了各种文件系统的复杂操作，成为一个虚拟文件系统层，提供了文件系统 API RAID RAID-0：把数据均匀的分布在不同的磁盘上，然后并行访问 RAID-1：写数据时往几个同样的硬盘写同样的数据（可靠性） RAID-4：0和1结合，用额外的一个盘（Parity Disk）来容错，这个盘会频繁写 RAID-5：把Parity Disk均匀分布在不同的硬盘上 。。。 I&#x2F;O 5 种 I&#x2F;O 模型：阻塞 I&#x2F;O、非阻塞 I&#x2F;O、信号驱动式 I&#x2F;O、I&#x2F;O 多路复用、异步 I&#x2F;O（AIO）","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://kebabshellgithub.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"ThreadLocal","slug":"ThreadLocal","date":"2021-01-10T16:22:29.000Z","updated":"2023-04-06T11:06:55.030Z","comments":true,"path":"2021/01/10/ThreadLocal/","link":"","permalink":"https://kebabshellgithub.github.io/2021/01/10/ThreadLocal/","excerpt":"","text":"参考 ThreadLocal 用于提供线程局部变量，在多线程环境可以保证各个线程里的变量独立于其它线程里的变量，保证了多线程环境下数据的独立性 使用注释写的： 1234567891011121314151617181920// 简单版public class ThreadLocalTest &#123; private static final ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;(); public static void main(String[] args) &#123; threadLocal.set(&quot;sss&quot;); new Thread(() -&gt; &#123; threadLocal.set(&quot;hhh&quot;); System.out.println(&quot;new Thread:&quot; + threadLocal.get()); &#125;).start(); System.out.println(&quot;main:&quot; + threadLocal.get()); &#125;&#125;// 输出：// main:sss// new Thread:hhh 原理每个线程维护了一个 ThreadLocalMap 类型的 threadLocals，存着自己定义的 ThreadLocal 的副本( 看 set 那里 ) 1ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocalMap用一个 Entry 数组来存储 key 和 value 12345678910private Entry[] table;private static final int INITIAL_CAPACITY = 16;// 阈值，超过了就扩容private int threshold;private void setThreshold(int len) &#123; threshold = len * 2 / 3;&#125; set 如果当前位置上的 key 相同，直接将该位置上面的 Entry 的 value 替换成最新的 如果当前位置上面的 Entry 的 key 为空, 说明 ThreadLocal 对象已经被回收了, 那么就调用 replaceStaleEntry 如果清理完无用条目( ThreadLocal 被回收的条目 )，并且数组中的数据大小 &gt; 阈值的时候，对当前的 Table 进行重新哈希 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125;// 首先扫描，删除陈旧的条目// 如果这样不能充分缩小大小，则将大小加倍private void rehash() &#123; expungeStaleEntries(); // Use lower threshold for doubling to avoid hysteresis if (size &gt;= threshold - threshold / 4) resize();&#125;// 大小加倍private void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; // Help the GC &#125; else &#123; int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; setThreshold(newLen); size = count; table = newTab;&#125; set12345678910111213141516171819public void set(T value) &#123; // 当前线程 Thread t = Thread.currentThread(); // 拿到当前线程的 threadLocals ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else // 如果为 null // 就 new 一个存有变量的 ThreadLocal 的 ThreadLocalMap // 赋给此线程的 threadLocals createMap(t, value);&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; get123456789101112131415public T get() &#123; Thread t = Thread.currentThread(); // 拿到当前线程的 threadLocals ThreadLocalMap map = getMap(t); if (map != null) &#123; // 拿到你定义的 ThreadLocal 的变量返回 ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; setInitialValue如果 get 的时候 threadLocals 为空，或者 threadLocals 不为空，但存的变量为空，就会返回初始值 如果不重写 initialValue，那默认就返回 null 1234567891011private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); // 和 set 差不多 ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; 应用场景应用最多的是 session 管理和数据库链接管理 我们希望通过某个类将状态(例如用户ID、事务ID)与线程关联起来，那么通常在这个类中定义private static类型的ThreadLocal 实例 由于在每个线程中都创建了副本，所以要考虑它对资源的消耗，比如内存的占用会比不使用 ThreadLocal 要大 内存泄漏1234567891011121314151617181920212223242526272829public class ThreadLocalDemo &#123; static class LocalVariable &#123; private Long[] a = new Long[1024 * 1024]; &#125; // (1) final static ThreadPoolExecutor poolExecutor = new ThreadPoolExecutor(5, 5, 1, TimeUnit.MINUTES, new LinkedBlockingQueue&lt;&gt;()); // (2) final static ThreadLocal&lt;LocalVariable&gt; localVariable = new ThreadLocal&lt;LocalVariable&gt;(); public static void main(String[] args) throws InterruptedException &#123; // (3) Thread.sleep(5000 * 4); for (int i = 0; i &lt; 50; ++i) &#123; poolExecutor.execute(new Runnable() &#123; public void run() &#123; // (4) localVariable.set(new LocalVariable()); // (5) System.out.println(&quot;use local varaible&quot; + localVariable.get()); localVariable.remove(); &#125; &#125;); &#125; // (6) System.out.println(&quot;pool execute over&quot;); &#125;&#125; 对于线程池里面不会销毁的线程，里面总会存在着 &lt;ThreadLocal, LocalVariable&gt; 的强引用，因为 final static 修饰的 ThreadLocal 并不会释放，而ThreadLocalMap 对于 Key 虽然是弱引用，但是强引用不会释放，弱引用当然也会一直有值，同时创建的 LocalVariable 对象也不会释放，就造成了内存泄露 ThreadLocal提供了一个清除线程中对象的方法，即 remove，内部实现就是调用 ThreadLocalMap 的 remove 12345678910111213141516171819public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125;private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; e.clear(); expungeStaleEntry(i); return; &#125; &#125;&#125; 找到 key 对应的 Entry，并且清除 Entry 的 key( ThreadLocal )置空，随后清除过期的 Entry 即可避免内存泄露","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://kebabshellgithub.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"ConcurrentHashMap","slug":"ConcurrentHashMap","date":"2021-01-07T22:05:47.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2021/01/07/ConcurrentHashMap/","link":"","permalink":"https://kebabshellgithub.github.io/2021/01/07/ConcurrentHashMap/","excerpt":"","text":"参考 1.8 相比 1.7 的改变1.7 的 ConcurrentHashMap 采用了分段锁技术，其中 Segment 继承于 ReentrantLock 理论上 ConcurrentHashMap 支持 CurrencyLevel( Segment 数组数量 )的线程并发 每当一个线程占用锁访问一个 Segment 时，不会影响到其他的 Segment 和 HashMap 一样，查询遍历链表效率太低 1.8 的 ConcurrentHashMap 抛弃了原有的 Segment 分段锁，而采用了 CAS + synchronized 来保证并发安全性 必识的变量和 HashMap 一样 默认数组大小都是 16 负载因子也是 0.75f 链表超过 8 时，且数组长度大于等于 64，转为红黑树，如果数组长度小于 64，就进行扩容 红黑树低于 6 时，转为链表 12345678910111213static final int MIN_TREEIFY_CAPACITY = 64; // 树化最小容量，容量小于64时，先扩容private static final int MIN_TRANSFER_STRIDE = 16; // 扩容时拆分散列表，最小步长private static int RESIZE_STAMP_BITS = 16; private static final int MAX_RESIZERS = (1 &lt;&lt; (32 - RESIZE_STAMP_BITS)) - 1; // 可参与扩容的最大线程static final int NCPU = Runtime.getRuntime().availableProcessors(); // CPU 数private transient volatile Node&lt;K,V&gt;[] nextTable; // 扩容时的过度表private transient volatile int sizeCtl; // 最重要的状态变量private transient volatile int transferIndex; // 扩容进度指示private transient volatile long baseCount; // 计数器，基础基数private transient volatile int cellsBusy; // 计数器，并发标记private transient volatile CounterCell[] counterCells; // 计数器，并发累计 插入 根据 key 计算出 hashcode 判断是否需要进行初始化 f 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功 如果当前位置的 hashcode &#x3D;&#x3D; MOVED &#x3D;&#x3D; -1，则需要进行扩容 如果都不满足，则利用 synchronized 锁写入数据 如果数量大于 TREEIFY_THRESHOLD 则要转换为红黑树 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); // 和 HashMap 一样，都是高低16位异或，保留高低位信息 int hash = spread(key.hashCode()); // 记录这个槽位的链表的长度 int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; // 如果数组空，就意味着要初始化，因为是 for 循环，所以重新进入循环 if (tab == null || (n = tab.length) == 0) // 初始化 tab = initTable(); // 数组不为空，就插入 // 如果数组此下标没元素，直接 cas 插入，成功就 break 了 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; &#125; // 如果此下标有元素，且元素正在移动，意味着在扩容 else if ((fh = f.hash) == MOVED) // 那就帮助扩容，看下面的 扩容 tab = helpTransfer(tab, f); // 如果此下标元素没在移动，那就分链表和红黑树 else &#123; V oldVal = null; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; // 头结点的 hash 值大于 0，说明是链表 if (fh &gt;= 0) &#123; // binCount 计算链表的长度 binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; // 如果有一样的 key，根据 onlyIfAbsent 来决定要不要替换 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; // 如果到链表终点还是没有一样的 key，那就新建元素，插入链表尾部 Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; // 如果此元素是红黑树节点，就按红黑树的插入方法 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; // 如果此槽位链表元素个数超过 8 时，treeifyBin // 数组长度大于等于 64，转为红黑树 // 数组长度小于 64，就进行扩容 if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; // 计数器 + 1 addCount(1L, binCount); return null;&#125; 拿 根据计算出来的 hash 寻址，如果就在桶上那么直接返回值 如果是红黑树那就按照树的方式获取值 就不满足那就按照链表的方式遍历获取值 扩容如果在插入时，此槽位链表元素个数超过 8 时，执行 treeifyBin 方法 如果数组长度大于等于 64，转为红黑树 如果数组长度小于 64，就 扩容( tryPresize ) 1234567891011private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; int n, sc; if (tab != null) &#123; if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) // 数组长度小于 64，就扩容，实参这里已经翻倍了！！ tryPresize(n &lt;&lt; 1); else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; // 转红黑树 &#125; &#125;&#125; tryPresize -&gt; transfer12345678910111213141516171819202122232425262728293031323334353637383940414243// 实参这里已经翻倍了private final void tryPresize(int size) &#123; // 如果翻倍的 size 大于最大容量的一半，那 c 就直接等于最大容量 // 如果小于等于，那 c 就等于 size 加上它自己的一半再加 1 int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); int sc; while ((sc = sizeCtl) &gt;= 0) &#123; Node&lt;K,V&gt;[] tab = table; int n; if (tab == null || (n = tab.length) == 0) &#123; n = (sc &gt; c) ? sc : c; if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if (table == tab) &#123; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = nt; sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; &#125; &#125; else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) break; else if (tab == table) &#123; int rs = resizeStamp(n); if (sc &lt; 0) &#123; Node&lt;K,V&gt;[] nt; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); &#125; &#125;&#125; 任务拆分，多线程同时扩容的方式，加速扩容，对 size 使用计数器思想 节点首先移动到过度表 nextTable，所有节点移动完毕时替换散列表 table 移动时先将散列表定长等分，然后 逆序 依次领取任务扩容，设置 sizeCtl 标记正在扩容 移动完成一个哈希桶或者遇到空桶时，将其标记为 ForwardingNode 节点，并指向 nextTable 后有其他线程在操作哈希表时，遇到 ForwardingNode 节点，则先帮助扩容( 继续领取分段任务 )，扩容完成后再继续之前的操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range if (nextTab == null) &#123; // initiating try &#123; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; int nextn = nextTab.length; ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; while (advance) &#123; int nextIndex, nextBound; if (--i &gt;= bound || finishing) advance = false; else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; if (finishing) &#123; nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit &#125; &#125; else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; if (fh &gt;= 0) &#123; int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125;&#125; 参考文章","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://kebabshellgithub.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"集合","slug":"集合","permalink":"https://kebabshellgithub.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"循环依赖","slug":"循环依赖","date":"2020-12-31T14:46:26.000Z","updated":"2023-04-06T11:06:55.042Z","comments":true,"path":"2020/12/31/循环依赖/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/31/%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/","excerpt":"","text":"循环依赖Spring 内部维护了三个 Map，也就是常说的三级缓存 1234567891011121314/** Cache of singleton objects: bean name to bean instance. */// 常说的第一级缓存// 存储的是所有创建好了的单例 Beanprivate final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);/** Cache of singleton factories: bean name to ObjectFactory. */// 常说的第三级缓存// 提前暴露的一个单例工厂，二级缓存中存储的就是从这个工厂中获取到的对象private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);/** Cache of early singleton objects: bean name to bean instance. */// 第二级缓存// 完成实例化，但是还未进行属性注入及初始化的对象private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16); 循环依赖分为有 AOP 的循环依赖，和没有 AOP 的循环依赖 Spring 解决循环依赖是有前置条件的 出现循环依赖的 Bean 必须要是 单例 依赖注入的方式不能 全是构造器注入 的方式 A 中注入 B 的方式为 setter 方法，B 中注入 A 的方式为构造器，这种情况能被解决 B 中注入 A 的方式为 setter 方法，A 中注入 B 的方式为构造器，这种情况不能被解决 在创建 Bean 的时候默认是按照 自然排序 来进行创建的，所以第一步 Spring 会去创建 A 步骤创建 Bean 的过程中分为 三步 实例化 AbstractAutowireCapableBeanFactory 中的 createBean 方法，即 createBeanInstance 方法 属性注入 AbstractAutowireCapableBeanFactory 的 populateBean 方法 初始化 AbstractAutowireCapableBeanFactory 的 initializeBean 方法 从 getBean( A ) 即 doGetBean 方法开始 1234// AbstractBeanFactorypublic Object getBean(String name) throws BeansException &#123; return doGetBean(name, null, null, false);&#125; doGetBean 先 尝试 从缓存中获取，若获取不到，就创建 12345678910111213141516171819202122232425262728293031protected &lt;T&gt; T doGetBean(final String name, @Nullable final Class&lt;T&gt; requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException &#123; // ... // 这里先尝试从缓存中获取，若获取不到，就走下面的创建 Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; // ... &#125; else &#123; // ... try &#123; // ... // 如果是 singleton if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; // 创建 Bean 的核心方法 return createBean(beanName, mbd, args); &#125; // ... &#125;); // ... &#125; // 如果是 prototype // ... &#125; // ... &#125; // ... return (T) bean;&#125; 从缓存尝试拿A首先到缓存中尝试去获取 Bean( A )，即 getSingleton(beanName, true) 12345Object sharedInstance = getSingleton(beanName);public Object getSingleton(String beanName) &#123; return getSingleton(beanName, true);&#125; 调用 getSingleton( 从缓存 ) 方法 123protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; // 省略...因为第一次来缓存里肯定没 A&#125; 但是第一次来缓存里肯定没有 A，就会走下面的 getSingleton(beanName, singletonFactory) 方法 因为 二参 是匿名函数，即 lambda，到 getSingleton 调用它的时候才执行 123456789101112if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, () -&gt; &#123; // lambda try &#123; // 在 getSingleton 里面调用 createBean 方法，即 doCreateBean // 即 createBeanInstance return createBean(beanName, mbd, args); &#125; // ... &#125;); // ...&#125; getSingleton( 从创建拿A )先看前半部分： 12345678910111213141516171819202122232425public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; // ... synchronized (this.singletonObjects) &#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; // logger... // ... try &#123; // 执行匿名函数，即执行 createBean，即执行 doCreateBean // 即 createBeanInstance singletonObject = singletonFactory.getObject(); newSingleton = true; &#125; // ... // 下半部分先不看 // 当 A 完成实例化，完成对 B 的属性注入后 // 加入到一级缓存中 // if (newSingleton) &#123; // addSingleton(beanName, singletonObject); // &#125; &#125; &#125;&#125; 执行匿名函数，先执行 createBean，即执行 doCreateBean 执行 createBeanInstance 拿到 Bean( A ) 实例后 看到 earlySingletonExposure 为 true 然后就会执行 addSingletonFactory，把 新的 Bean 实例( A ) 包装成工厂，添加到 三级缓存 singletonFactory 123456789101112131415161718192021222324252627282930313233343536// AbstractAutowireCapableBeanFactoryprotected Object doCreateBean( final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &#123; // ... if (instanceWrapper == null) &#123; // 实例化 instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; final Object bean = instanceWrapper.getWrappedInstance(); // ... // earlySingletonExposure boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; // logger... // 把新的 Bean 实例( A )包装成工厂，添加到三级缓存 singletonFactory // 在没有 AOP 的情况下，getEarlyBeanReference 返回的工厂里面的还是现在的 Bean 实例( A ) addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; // ... Object exposedObject = bean; try &#123; // 属性赋值 populateBean(beanName, mbd, instanceWrapper); // 就此打住，不看下面 // 初始化 // exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; // ... return exposedObject;&#125; 重点是 earlySingletonExposure 为 true 然后执行了 addSingletonFactory，把 新的 Bean 实例( A )包装成工厂添加到三级缓存 singletonFactory addSingletonFactory 的二参是匿名函数，里面是 getEarlyBeanReference 注意：在 没有 AOP！！！ 的情况下，getEarlyBeanReference 返回的工厂还是现在的 Bean 实例( A ) &#96;&#96;&#96;java&#x2F;&#x2F; 二参是匿名函数&#x2F;&#x2F; 在没有 AOP 的情况下，getEarlyBeanReference 返回工厂的还是现在的 Bean 实例protected void addSingletonFactory(String beanName, ObjectFactory&lt;?&gt; singletonFactory) {&#x2F;&#x2F; Assert..synchronized (this.singletonObjects) { &#x2F;&#x2F; 此时 A 实例化了，但还没完成初始化 &#x2F;&#x2F; 所以一级缓存单例池 singletonObjects 里面害没有 A if (!this.singletonObjects.containsKey(beanName)) { &#x2F;&#x2F; 将 A 的工厂加入到三级缓存 this.singletonFactories.put(beanName, singletonFactory); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); }}} 1234567891011121314151617181920212223242526272829然后 `doCreateBean` 还没完，还有 `populateBean` 属性注入- 就会发现 A 里面还有个 B，然后 `getBean(B)`，**开始套壳了！！**```java// AbstractAutowireCapableBeanFactoryprotected Object doCreateBean( final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &#123; // 实例化 // addSingletonFactory 加入三级缓存 Object exposedObject = bean; try &#123; // 属性赋值，会发现 B，然后 getBean(B) populateBean(beanName, mbd, instanceWrapper); // 就此打住，先不看下面 // 初始化 // exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; // ... return exposedObject;&#125; 套壳开始(A拿B)getBean(B) -&gt; doGetBean 还是先执行 getSingleton( 从缓存获取 )，发现 B 没实例化 然后 createBean 123456789if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; // 创建 Bean 的核心方法 return createBean(beanName, mbd, args); &#125; &#125;); // ...&#125; createBean 即 doCreateBean 先 createBeanInstance 创建 B 实例 然后执行 addSingletonFactory 加入三级缓存 1234567if (earlySingletonExposure) &#123; // logger... // 把新的 Bean 实例( B )包装成工厂，添加到三级缓存 singletonFactory // 在没有 AOP 的情况下，getEarlyBeanReference 返回的工厂里面的还是现在的 Bean 实例( B ) addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));&#125; 然后属性注入，发现 有个 A 然后 getBean( A ) 又套壳(B拿A,成功了)又回到 doGetBean 中的 getSingleton( 从缓存中获取 ) 但是这次发现 A 就在三级缓存中！！！ 拿到 A 把 A 放进 二级缓存 earlySingletonObjects 中( 表示 A 还未完全初始化，注意 未完全！！) 然后把 A 从三级缓存拿掉 1234567891011121314151617181920212223242526272829protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; // 单例池还没有 A，没完成属性注入呢，还在等 B Object singletonObject = this.singletonObjects.get(beanName); // 进入 if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; // 二级缓存也没有 singletonObject = this.earlySingletonObjects.get(beanName); // 进入 if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; // 这时候发现，三级缓存里有 A 包装而成的工厂 // ( 其实在没有 AOP 的情况下，这个工厂还是 A ) ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); // 拿到了，不为 null if (singletonFactory != null) &#123; // 拿到 A singletonObject = singletonFactory.getObject(); // 把 A 放进二级缓存 earlySingletonObjects 中 // 表示 A 还未完全初始化，注意未完全！！ this.earlySingletonObjects.put(beanName, singletonObject); // 然后把 A 从三级缓存拿掉 this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; // 把 A 返回 return singletonObject;&#125; 拿到 A 了，就直接返回，然后 B 完成属性注入，完成初始化 为什么 B 拿到的是 半残 的 A，但是没出问题？ 因为 B 拿的是 A 的 引用，之后 B 完成初始化还得回传给 A 回到A拿BB 完成初始化后，回到 A 拿 B 的时候的 getSingleton 当 B 完成实例化，即完成对 A 的属性注入后 把 B 加入到 一级缓存 中，即 单例池 把 B 从 三级缓存工厂 中 移除 把 B 从 二级工厂 移除 这标志着 B 彻底完成初始化！ 12345678910111213141516171819202122232425262728293031323334353637public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; // ... synchronized (this.singletonObjects) &#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; // logger... // ... try &#123; // 执行匿名函数，即执行 createBean，即执行 doCreateBean // 即 createBeanInstance // 这句执行完，表明 B 完成实例化，即完成 B 对 A 的属性注入，初始化 singletonObject = singletonFactory.getObject(); newSingleton = true; &#125; // ... // 当 B 完成实例化，即完成 B 的属性注入后 // 把 B 加入到一级缓存中、从三级缓存工厂中移除、从二级工厂移除 if (newSingleton) &#123; addSingleton(beanName, singletonObject); &#125; &#125; &#125;&#125;// 把 B 加入到一级缓存中，即单例池// 把 B 从三级缓存工厂中移除// 把 B 从二级工厂移除protected void addSingleton(String beanName, Object singletonObject) &#123; synchronized (this.singletonObjects) &#123; this.singletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125;&#125; A 完成属性注入，完成初始化 回到我们拿A回到我们自己( 容器 )拿 A 的时候，getSingleton 当 A 完成实例化，即完成对 B 的属性注入后 把 A 加入到一级缓存中，即单例池 把 A 从三级缓存工厂中移除 把 A 从二级工厂移除 这标志着 A 彻底完成初始化！ 1234567891011121314151617181920212223242526272829303132333435public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; // ... synchronized (this.singletonObjects) &#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; // logger... // ... try &#123; // 执行匿名函数，即执行 createBean，即执行 doCreateBean // 即 createBeanInstance // 这句执行完，表明 A 完成实例化，即完成 A 对 B 的属性注入，初始化 singletonObject = singletonFactory.getObject(); newSingleton = true; &#125; // ... // 当 A 完成实例化，即完成 A 的属性注入后 // 把 A 加入到一级缓存中、从三级缓存工厂中移除、从二级工厂移除 if (newSingleton) &#123; addSingleton(beanName, singletonObject); &#125; &#125; &#125;&#125;// 把 A 加入到一级缓存中，即单例池// 把 A 从三级缓存工厂中移除// 把 A 从二级工厂移除protected void addSingleton(String beanName, Object singletonObject) &#123; synchronized (this.singletonObjects) &#123; this.singletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125;&#125; 结束！！getEarlyBeanReference这里就是上面说到，即将注入到 B 中的 A 是通过 getEarlyBeanReference 方法 提前暴露 出去的一个工厂对象，还不是一个完整的 Bean 123456789101112protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123; Object exposedObject = bean; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof SmartInstantiationAwareBeanPostProcessor) &#123; SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp; exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName); &#125; &#125; &#125; return exposedObject;&#125; getEarlyBeanReference 方法实际上就是调用了后置处理器的 getEarlyBeanReference 方法，而真正实现了这个方法的后置处理器只有一个，就是通过 @EnableAspectJAutoProxy 注解导入的 AnnotationAwareAspectJAutoProxyCreator 也就是说如果在不考虑 AOP 的情况下，上面的代码等价于 1234protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123; Object exposedObject = bean; return exposedObject;&#125; 也就是说这个工厂啥都没干，直接将实例化阶段创建的对象返回了 在没 AOP 的情况下，三级缓存没毛用 在有 AOP 的情况下，getEarlyBeanReference 生成的工厂是经过包装的，不再是原来那个 A 或 B 了，因为 AOP 了 摘自大佬的一张图：","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://kebabshellgithub.github.io/tags/Spring/"}]},{"title":"简单的微服务","slug":"微服务简述","date":"2020-12-28T10:48:52.000Z","updated":"2023-04-06T11:06:55.042Z","comments":true,"path":"2020/12/28/微服务简述/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/28/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%AE%80%E8%BF%B0/","excerpt":"","text":"微服务Spring Cloud Alibaba 对内 RPC，对外 REST （RPC，Remote Procedure Call 即远程过程调用） JSON，序列化要 2 次，即 对象 - JSON 字符串 - 二进制 Nacos主要功能：服务注册和发现、服务健康监测、动态配置服务、动态DNS… Nacos Configtest Dubbo https://dubbo.apache.org/zh/docs/v2.7/user/ aobing 经典图： 0：服务容器负责启动，加载，运行服务提供者 1：服务提供者在启动时，向注册中心注册自己提供的服务 2：服务消费者在启动时，向注册中心订阅自己所需的服务 3：注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者 4：服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用 5：服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心 注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小 balabala概念什么鬼~~ Dubbo SPI改进版的 Java SPI 能够得到指定名字的实现类实例，Java SPI 只能一股脑全部实例化 自适应扩展@Adaptive 首先根据配置来进行 SPI 扩展的加载，但是不想在启动的时候加载这个扩展，我想根据请求的参数来动态选择对应的扩展 为你想扩展的接口生成一个代理类，可以通过JDK 或者 javassist 编译你生成的代理类代码，然后通过反射创建实例 end 服务暴露URL！！ 1protocol://username:password@host:port/path?key=value&amp;key=value 暴露的过程就在 Spring 容器刷新后调用 onApplicationEvent 方法 Sentineltest RocketMQtest Seatatest Alibaba Cloud SchedulerXtest","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"摆烂了","slug":"摆烂了","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%86%E7%83%82%E4%BA%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"微服务","slug":"微服务","permalink":"https://kebabshellgithub.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}]},{"title":"杂七杂八","slug":"这是置顶文章","date":"2020-12-28T10:41:46.000Z","updated":"2023-04-06T11:06:55.042Z","comments":true,"path":"2020/12/28/这是置顶文章/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/28/%E8%BF%99%E6%98%AF%E7%BD%AE%E9%A1%B6%E6%96%87%E7%AB%A0/","excerpt":"","text":"这图很喜欢 来自《火车上的中国人》 关于本站1、个人使用 2、由 GitHub Pages &amp; GitHub Actions &amp; Hexo &amp; Next 强劲驱动~ 3、有巨多网名：KebabShell、秋早亦朝、QZ…（看到了就点个关注吧，B站叫：秋早亦朝，主要更新摄影相关视频） 4、本站内容包罗万象，不只是技术类，还有摄影、音乐、艺术等 5、有别的我再加…","categories":[{"name":"总结","slug":"总结","permalink":"https://kebabshellgithub.github.io/categories/%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"置顶","slug":"置顶","permalink":"https://kebabshellgithub.github.io/tags/%E7%BD%AE%E9%A1%B6/"}]},{"title":"Bean 的生命周期","slug":"Bean-的生命周期","date":"2020-12-27T18:49:02.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/27/Bean-的生命周期/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/27/Bean-%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","excerpt":"","text":"参考文章 基本流程Bean 的生命周期分成四步（五个手指头）：实例化、属性赋值、初始化、使用、销毁 实例化( createBeanInstance 方法 )（doCreateBean里面） 实例化一个 bean 对象 属性赋值( populateBean 方法 ) 设置相关属性和依赖 初始化( initializeBean 方法 ) 检查 Aware 相关接口并设置相关依赖( 初始化前执行 ) BeanPostProcessor 前置 处理( 初始化前执行 ) 是否实现 InitializingBean 接口( 初始化 ) 是否配置自定义的 init-method( 初始化 ) BeanPostProcessor 后置 处理( 初始化后执行 ) 使用… 销毁( registerDisposableBeanIfNecessary 方法 + destroy 方法) 注册 Destruction 相关回调接口( ！！！在使用之前注册 ) 是否实现 DisposableBean 接口 是否配置自定义的 destroy-method 扩展点使用组件时，只要引用了一个依赖，几乎是零配置就能完成一个功能的装配 不同的扩展接口有不同的使用场景，只要实现了不同的接口 Spring 就会从 bean 被加载到最后初始化，根据不同的扩展接口执行不同的调用 Aware若 Spring 检测到 bean 实现了 Aware 接口，则会为其注入相应的依赖 Aware 类型的接口的作用就是让我们能够拿到 Spring 容器中的一些资源，Aware 之前的名字就是可以拿到什么资源，例如 BeanNameAware 可以拿到 BeanName 所有的 Aware 方法都是在初始化阶段之前调用的！ Aware 分成两种类型：针对 BeanFactory 和 ApplicationContext 类型的容器提供的 Aware 接口 ApplicationContext 和 BeanFactory 的区别，可以从 ApplicationContext 继承的这几个接口入手，除去 BeanFactory 相关的接口就是 ApplicationContext 独有的功能 针对 BeanFactory 类型的容器提供的 Aware 接口有： BeanNameAware：注入当前 bean 对应 beanName BeanClassLoaderAware：注入加载当前 bean 的 ClassLoader BeanFactoryAware：注入当前 BeanFactory 容器的引用 1234567891011121314151617// 检查 Aware 相关接口并设置相关依赖private void invokeAwareMethods(final String beanName, final Object bean) &#123; if (bean instanceof Aware) &#123; if (bean instanceof BeanNameAware) &#123; ((BeanNameAware) bean).setBeanName(beanName); &#125; if (bean instanceof BeanClassLoaderAware) &#123; ClassLoader bcl = getBeanClassLoader(); if (bcl != null) &#123; ((BeanClassLoaderAware) bean).setBeanClassLoader(bcl); &#125; &#125; if (bean instanceof BeanFactoryAware) &#123; ((BeanFactoryAware) bean).setBeanFactory(AbstractAutowireCapableBeanFactory.this); &#125; &#125;&#125; 以上是针对 BeanFactory 类型的容器 而对于 ApplicationContext 类型的容器，也提供了 Aware 接口，只不过这些 Aware 接口的注入实现，是通过 BeanPostProcessor 的方式注入的，但其作用仍是注入依赖 EnvironmentAware：注入 Enviroment，一般用于 获取配置属性 EmbeddedValueResolverAware：实现该接口能够获取 SpEL 解析器，用户的自定义注解需要支持 SpEL 表达式的时候可以使用 ApplicationContextAware(ResourceLoaderAware/ApplicationEventPublisherAware/MessageSourceAware)：注入 ApplicationContext 容器本身 123456789101112131415161718192021// ApplicationContextAwareProcessorprivate void invokeAwareInterfaces(Object bean) &#123; if (bean instanceof EnvironmentAware) &#123; ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); &#125; if (bean instanceof EmbeddedValueResolverAware) &#123; ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); &#125; if (bean instanceof ResourceLoaderAware) &#123; ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); &#125; if (bean instanceof ApplicationEventPublisherAware) &#123; ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); &#125; if (bean instanceof MessageSourceAware) &#123; ((MessageSourceAware) bean).setMessageSource(this.applicationContext); &#125; if (bean instanceof ApplicationContextAware) &#123; ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); &#125;&#125; BeanFactoryPostProcessorSpring 允许 BeanFactoryPostProcessor 在容器实例化 bean 之前 读取配置元数据，这个机制可以让我们在真正的实例化 bean 之前 对 BeanDefinition 进行修改 如配置文件中的数据库密码不能明文写在项目里，那就从密码中心拿到密码，然后注入 如可以把 bean 的 Scope 从 singleton 改为 prototype ，也可以把 property 的值给修改掉 此时 Bean 还未生成！！（注意和 BeanPostProcessor 区分开） 可以配置多个 BeanFactoryPostProcessor 实例，并且通过设置 order 属性，来控制这些 BeanFactoryPostProcessor 实例的运行顺序 BeanFactoryPostProcessor 的 postProcessBeanFactory 在 doCreateBean 之前，即 refresh 里面的 finishBeanFactoryInitialization 之前就执行完了 123public interface BeanFactoryPostProcessor &#123; void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException;&#125; BeanPostProcessorBeanPostProcessor 是 Spring 为修改 bean 提供的强大扩展点，其可作用于容器中所有 bean BeanPostProcessor 可以在 Spring 容器实例化 bean 之后，在执行 bean 的初始化方法前后，添加一些自己的处理逻辑 注意：是实例化 bean 之后，在执行 bean 的初始化方法前后 BeanFactoryPostProcessor 是用来对 BeanFactory 中的 BeanDefinition 进行处理，此时 Bean 还未生成 而 BeanPostProcessor 用来对我们 生成的 Bean 进行处理，如果想要改变 Bean 实例，应该使用 BeanPostProcessor 同样 可以配置多个 BeanPostProcessor 实例，并且通过设置 order 属性，来控制这些 BeanPostProcessor 实例的运行顺序 BeanPostProcessor 分为两个方法，一个是用于初始化 前置处理，一个是用于初始化 后置处理 12345678910public interface BeanPostProcessor &#123; // 初始化前置处理 default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125; // 初始化后置处理 default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125;&#125; 常用场景有： 对于标记接口的实现类，进行自定义处理。例如 ApplicationContextAwareProcessor，为其注入相应依赖 自定义对实现解密接口的类，将对其属性进行解密处理 为当前对象提供代理实现。例如 Spring AOP 功能，生成对象的代理类，然后返回（AOP其实是在实例化之前就创建了，即 createBean 里面有一个 resolveBeforeInstantiation 方法，是给 BeanPostProcessor 一个机会来返回一个代理对象代替目标对象） 对于 BeanPostProcessor 和 BeanFactoryPostProcessor 的注册，可以看 refresh 方法 InitializingBean 和 init-method实现 InitalizingBean 接口为 bean 初始化提供扩展，在 afterPropertiesSet() 方法写初始化逻辑 123public interface InitializingBean &#123; void afterPropertiesSet() throws Exception;&#125; 或在 xml 指定 init-method 方法 DisposableBean 和 destory-method 与上面类似 doCreateBean12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// AbstractAutowireCapableBeanFactoryprotected Object doCreateBean( final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &#123; // Instantiate the bean. // ... if (instanceWrapper == null) &#123; // 实例化 instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; final Object bean = instanceWrapper.getWrappedInstance(); // ... // Allow post-processors to modify the merged bean definition. // 此处处理这个接口的处理器：MergedBeanDefinitionPostProcessor // 他在 BeanPostProcessor 的基础上增加了 postProcessMergedBeanDefinition 方法，在此处就被调用了 // 主要是处理 @PostConstruct,@Autowire,@Value,@Resource，@PreDestory 等这些注解 // ... // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. // 这里面主要是解决循环引用问题 // 如果当前 bean 是单例，且支持循环依赖，且当前 bean 正在创建，通过往 singletonFactories 添加一个 objectFactory // 这样后期如果有其他 bean 依赖该 bean 可以从 singletonFactories 获取到 bean // getEarlyBeanReference 可以对返回的 bean 进行修改，这边目前除了可能会返回动态代理对象 其他的都是直接返回 bean //这里主要是调用处理器：SmartInstantiationAwareBeanPostProcessor#getEarlyBeanReference 方法去寻找到前期的 Bean 们( 若存在这种处理器的话 ) // ... // Initialize the bean instance. Object exposedObject = bean; try &#123; // 属性赋值，包括注解啥的 populateBean(beanName, mbd, instanceWrapper); // 初始化 exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable ex) &#123; // ... &#125; //如果 earlySingletonExposure 为 true，尝试从缓存获取该 bean( 一般存放在 singletonFactories 对象通过调用getObject 把对象存入earlySingletonObjects ) // 分别从 singletonObjects 和 earlySingletonObjects 获取对象 // 这里依然是处理循环依赖相关问题的 if (earlySingletonExposure) &#123; // ... &#125; // Register bean as disposable. try &#123; // 销毁-注册回调接口 // 如果有需要，就注册 DisposableBean，这样Bean销毁的时候此种后置处理器也会生效了 registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; catch (BeanDefinitionValidationException ex) &#123; // ... &#125; return exposedObject;&#125; initializeBean1234567891011121314151617181920212223242526272829303132333435363738// AbstractAutowireCapableBeanFactoryprotected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) &#123; // 检查 Aware 相关接口并设置相关依赖 // ( 针对 BeanFactory 类型的容器提供的 Aware 接口 ) if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; invokeAwareMethods(beanName, bean); return null; &#125;, getAccessControlContext()); &#125; else &#123; invokeAwareMethods(beanName, bean); &#125; // BeanPostProcessor 前置处理 // Aware 通过 BeanPostProcessor 的方式注入的 // (针对 ApplicationContext 类型的容器提供的 Aware 接口) Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; // 若实现 InitializingBean 接口，调用 afterPropertiesSet 方法 // 若配置自定义的 init-method 方法，则执行 try &#123; invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable ex) &#123; // ... &#125; // BeanPostProceesor 后置处理 if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125; destroy12345678910111213141516171819202122232425262728293031323334353637public void destroy() &#123; if (!CollectionUtils.isEmpty(this.beanPostProcessors)) &#123; for (DestructionAwareBeanPostProcessor processor : this.beanPostProcessors) &#123; processor.postProcessBeforeDestruction(this.bean, this.beanName); &#125; &#125; // 若实现 DisposableBean 接口，则执行 destory()方法 if (this.invokeDisposableBean) &#123; // ...logger // 若实现 DisposableBean 接口，则执行 destory()方法 try &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedExceptionAction&lt;Object&gt;) () -&gt; &#123; ((DisposableBean) this.bean).destroy(); return null; &#125;, this.acc); &#125; else &#123; ((DisposableBean) this.bean).destroy(); &#125; &#125; catch (Throwable ex) &#123; // ...logger &#125; &#125; // 若配置自定义的 detory-method 方法，则执行 if (this.destroyMethod != null) &#123; invokeCustomDestroyMethod(this.destroyMethod); &#125; else if (this.destroyMethodName != null) &#123; Method methodToInvoke = determineDestroyMethod(this.destroyMethodName); if (methodToInvoke != null) &#123; invokeCustomDestroyMethod(ClassUtils.getInterfaceMethodIfPossible(methodToInvoke)); &#125; &#125;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://kebabshellgithub.github.io/tags/Spring/"}]},{"title":"Spring Boot 的启动流程","slug":"Spring-Boot的启动流程","date":"2020-12-27T18:28:09.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/27/Spring-Boot的启动流程/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/27/Spring-Boot%E7%9A%84%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/","excerpt":"","text":"Spring Boot启动流程构造 SpringBootApplication 对象首先会创建 SpringBootApplication 对象 1234567891011121314151617181920212223242526272829303132public static void main(String[] args) &#123; SpringApplication.run(SpringbootLearnApplication.class, args);&#125;// ↓public static ConfigurableApplicationContext run(Class&lt;?&gt; primarySource, String... args) &#123; return run(new Class&lt;?&gt;[] &#123; primarySource &#125;, args);&#125;// ↓public static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources, String[] args) &#123; return new SpringApplication(primarySources).run(args);&#125;// ↓ 构造public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; // primarySources 就是当前 SpringBootApplication 对象 // Assert... this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); // 判断是否是 web 项目 this.webApplicationType = WebApplicationType.deduceFromClasspath(); // 从类路径下找到 META-INF/spring.factories 配置的所有 ApplicationContextInitializer，然后保存 setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); //从类路径下找到 META-INF/spring.factories 配置的所有 ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass();&#125; spring.factoriesspring.factories 表示这个组件需要配置的东西 12345678# PropertySource Loadersorg.springframework.boot.env.PropertySourceLoader=\\org.springframework.boot.env.PropertiesPropertySourceLoader,\\org.springframework.boot.env.YamlPropertySourceLoader# Run Listenersorg.springframework.boot.SpringApplicationRunListener=\\# ... runSpring Boot 的整个启动流程都封装在 run 方法中，本质上其实就是在 Spring 的基础之上封装，做了大量的扩张 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public ConfigurableApplicationContext run(String... args) &#123; // 启动开始停止的监听 StopWatch stopWatch = new StopWatch(); stopWatch.start(); // 声明 容器 ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); // 是关于 awt 的 configureHeadlessProperty(); // 通过 SpringFactoriesLoader 查找 // 并加载所有的 SpringApplicationRunListeners // ( 从 META-INF/spring.factories ) // 通过调用 starting() 方法通知所有的 SpringApplicationRunListeners，告知应用开始启动了 SpringApplicationRunListeners listeners = getRunListeners(args); // 回调所有的获取 SpringApplicationRunListener.starting() 方法 listeners.starting(); try &#123; // 封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 准备环境 // 创建环境完成后 // 回调 SpringApplicationRunListener.environmentPrepared() // 表示环境准备完成 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); // 打印 SPRING 那个大图标 Banner printedBanner = printBanner(environment); // 创建容器,会判断是不是 web，利用反射创建容器 context = createApplicationContext(); // 创建一系列 FailureAnalyzer exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); // 准备上下文环境 // 将 environment 保存到容器 // 还有 applyInitializers()，回调之前保存的所有的 ApplicationContextInitialize 方法 // 还要回调所有的 SpringApplicationRunListener 的 contextPrepared() // 还有什么 banner 什么的 prepareContext(context, environment, listeners, applicationArguments, printedBanner); // prepareContext 完成后回调所有的 SpringApplicationRunListener 的 contextLoaded() // 刷新容器，容器初始化的过程，扫描、创建、加载所有的组件 // 如果是 web，tomcat 也在这里创建好 // 这里就是传统 Spring 初始化的地方，即 refresh 方法 refreshContext(context); // 从容器中获取所有的 ApplicationRunner( 先 ) 和 CommandLineRunner( 后 ) 进行回调 afterRefresh(context, applicationArguments); //完成 stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; // throw &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); // throw &#125; //返回启动的容器 return context;&#125; refreshContext即 refresh 方法 12345678910111213141516171819// 刷新容器，容器初始化的过程，扫描、创建、加载所有的组件// 如果是 web，tomcat 也在这里创建好// 这里就是传统 Spring 初始化的地方，即 refresh 方法refreshContext(context);// ↓private void refreshContext(ConfigurableApplicationContext context) &#123; // 这儿 refresh(context); if (this.registerShutdownHook) &#123; try &#123; context.registerShutdownHook(); &#125; catch (AccessControlException ex) &#123; // Not allowed in some environments. &#125; &#125;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://kebabshellgithub.github.io/tags/Spring/"}]},{"title":"MarkDown技巧","slug":"MarkDown技巧","date":"2020-12-26T22:24:31.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/26/MarkDown技巧/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/26/MarkDown%E6%8A%80%E5%B7%A7/","excerpt":"","text":"站内跳转： 1234&#123;% post_link title name %&#125;// post_link 关键字// title: 文章标题// name: 该链接标题(不写的话默认是文章标题) 如果需要定位到页内锚点( 小标题 )，可以直接使用该文章的相对地址： 12[小标题](/2020/12/26/文章标题#小标题)// 此博客使用 [小标题](/blog/2020/12/26/文章标题#小标题) 文章内小标题跳转： 1[小标题](#小标题) 文字注释： 1[//]: # (This may be the most platform independent comment)","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://kebabshellgithub.github.io/tags/Hexo/"},{"name":"博客","slug":"博客","permalink":"https://kebabshellgithub.github.io/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"MarkDown","slug":"MarkDown","permalink":"https://kebabshellgithub.github.io/tags/MarkDown/"}]},{"title":"Thread","slug":"Thread","date":"2020-12-25T15:43:25.000Z","updated":"2023-04-06T11:06:55.030Z","comments":true,"path":"2020/12/25/Thread/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/25/Thread/","excerpt":"","text":"Thread类进程与线程进程程序是静止的，运行中的程序是进程 特征： 动态性：动态的占用内存、CPU、网络… 独立性：各进程相互独立，有自己的内存空间 并发性：如果 CPU 单核，一个时刻只能一个进程被执行。CPU 会分时轮询切换依次服务进程，因为切换速度快，感受就是各个进程都在同时执行 并行： 一个时刻同时有多个在执行 线程 线程属于进程，一个进程至少一个线程 线程开销相对于进程少 线程也有并发性 乱七八糟： StringBuilder 是不安全的，而 StringBuffer 是安全的，但是淘汰了，性能差 SringBuffer的 append 方法，为了实现同步，很多方法使用 synchronized 修饰 底层字符串都是由 char 数组 StringBuilder和StringBuffer的append(String str)方法都是通getChars方法来实现字符串拼接的 关于变量不可见 原因 JMM( Java Memory Model )，所有共享变量存放于主内存，每个线程有工作内存，保留了变量的副本，所有线程所有的操作都在操作副本 解决方法 volatile 子线程修改了变量后，当变量写入主内存，会失效其他线程的此变量的副本，其他线程操作此变量时，会从主内存 copy 最新的值，使得变量可见，区分 synchronized，两者不同 synchronized 线程拿到锁，清空工作内存，从主内存 copy 共享变量到工作内存，变量如果有修改，会将修改的变量刷新回主内存，释放锁 线程状态共 6 种 12345678public enum State &#123; NEW, RUNNABLE, BLOCKED, WAITING, TIMED_WAITING, TERMINATED;&#125; 注意事项sleep、wait、yield sleep 使当前线程让出了 CPU，但是，当前线程仍然持有它所获得的监视器锁 wait 同时让出 CPU 资源和监视器锁 wait(0) 表示无限等待 sleep(0) 会让其他线程有机会优先执行，调用 sleep(0) 的线程的状态可能变成 TIMED_WAITING yield 指当前线程愿意让出 CPU，但是对于 CPU 这只是一个建议，要不要让看厂商调度 yield 顶多会让当前线程状态从 RUNNING 变成 READY，并不会退出 RUNNABLE join注意 join 方法有加 synchronized，说明执行某个线程实例的 join 方法必须拿到对象锁( this 锁 )，即 myThread 对象所关联的监视器对象 123456789101112131415161718192021222324252627282930// join() 就是 join(0)public final void join() throws InterruptedException &#123; join(0);&#125;public final synchronized void join(long millis) throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException(&quot;timeout value is negative&quot;); &#125; // 如果 millis 为 0，就无限等待 if (millis == 0) &#123; while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125; 123456789101112131415161718192021222324252627public static void main(String[] args) &#123; System.out.println(Thread.currentThread().getName() + &quot;: main 开始&quot;); Thread myThread = new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot;: 开始&quot;); System.out.println(Thread.currentThread().getName() + &quot;: 要睡觉了&quot;); try &#123; Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + &quot;: 醒了&quot;); System.out.println(Thread.currentThread().getName() + &quot;: 结束&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;, &quot;myThread&quot;); try &#123; myThread.start(); System.out.println(Thread.currentThread().getName() + &quot;: 我要等下面的线程执行完我才继续&quot;); myThread.join(); // myThread.join(500); System.out.println(Thread.currentThread().getName() + &quot;: 上面的线程执行完了&quot;); System.out.println(Thread.currentThread().getName() + &quot;: 退出&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125; main 方法中调用了 myThread.join()，会无限等待，等到 myThread 执行结束( 线程结束默认会执行 this.notifyAll )，main 线程会被唤醒，继续执行，发现 myThread 的 isAlive 是 false，join 执行完毕 12345678main: main 开始main: 我要等下面的线程执行完我才继续myThread: 开始myThread: 要睡觉了myThread: 醒了myThread: 结束main: 上面的线程执行完了main: 退出 而如果 main 方法中调用了 myThread.join(500)，main 只会等待 0.5 s，发现 myThread 还是活着，那就 break 12345678main: main 开始main: 我要等下面的线程执行完我才继续myThread: 开始myThread: 要睡觉了main: 上面的线程执行完了main: 退出myThread: 醒了myThread: 结束 参考文章","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://kebabshellgithub.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"CyclicBarrier","slug":"CyclicBarrier","date":"2020-12-24T17:02:52.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/24/CyclicBarrier/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/24/CyclicBarrier/","excerpt":"","text":"循环使用屏障：让一组线程等待至某个状态之后再全部同时执行 也是count 内部使用了ReentrantLock和Condition 默认的构造方法是CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程使用await()方法告诉CyclicBarrier我已经到达了屏障，然后当前线程被阻塞 线程执行 await() 方法之后count会减 1，并进行等待，直到count为 0，所有调用 await() 方法而在等待的线程才能继续执行","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"摆烂了","slug":"摆烂了","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%86%E7%83%82%E4%BA%86/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://kebabshellgithub.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"CountDownLatch","slug":"CountDownLatch","date":"2020-12-24T17:02:26.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/24/CountDownLatch/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/24/CountDownLatch/","excerpt":"","text":"利用它可以实现类似计数器的功能。比如有一个任务 A，它要等待其他 4 个任务执行完毕之后才能执行 调用 await() 方法的线程会被挂起，它会等待直到 count 值为 0 才继续执行 countDown 方法将 count 值减 1 内部 Sync 继承了 AQS","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"摆烂了","slug":"摆烂了","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%86%E7%83%82%E4%BA%86/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://kebabshellgithub.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"ReentrantReadWriteLock","slug":"ReentrantReadWriteLock","date":"2020-12-24T16:52:01.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/24/ReentrantReadWriteLock/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/24/ReentrantReadWriteLock/","excerpt":"","text":"ReentrantReadWriteLock读写可重入锁 为了避免脏读 当前线程拿到写锁，允许当前线程拿读锁（锁降级），不允许其他线程获取读锁&#x2F;写锁 当前线程拿到读锁，允许当前&#x2F;其他线程拿读锁，不允许任何线程拿写锁 读锁和写锁都支持重入 支持 Nonfair（默认）和 Fair 的锁 123456789101112131415private final ReentrantReadWriteLock.ReadLock readerLock;private final ReentrantReadWriteLock.WriteLock writerLock;final Sync sync;// 默认非公平public ReentrantReadWriteLock() &#123; this(false);&#125;public ReentrantReadWriteLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); readerLock = new ReadLock(this); writerLock = new WriteLock(this);&#125; 获取读锁和写锁的两个方法： 12public ReentrantReadWriteLock.WriteLock writeLock() &#123; return writerLock; &#125;public ReentrantReadWriteLock.ReadLock readLock() &#123; return readerLock; &#125; 除此之外，还有一些用于展示工作状态的： 读写锁的获取次数存放在 AQS 里面的 state 上，state 的 高 16 位 存放 readLock 获取的次数，低 16 位 存放 writeLock 获取的次数 获取读状态 就是将状态值 右移 16 位 获取写状态 就是将状态值的 高 16 位抹去 123456789static final int SHARED_SHIFT = 16;static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT);static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1;static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;/** Returns the number of shared holds represented in count */static int sharedCount(int c) &#123; return c &gt;&gt;&gt; SHARED_SHIFT; &#125;/** Returns the number of exclusive holds represented in count */static int exclusiveCount(int c) &#123; return c &amp; EXCLUSIVE_MASK; &#125; 每个线程获得读锁的次数用内部类 HoldCounter 保存，并且存储在 ThreadLocal 里面 写锁获取先拿到 WriteLock 1public ReentrantReadWriteLock.WriteLock writeLock() &#123; return writerLock; &#125; 然后一样，调 Sync 的 acquire，因为 Sync 是 AQS 的子类，即是 AQS 的 acquire，然后就是 tryAcquire 123public void lock() &#123; sync.acquire(1);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); // 获取同步状态 int c = getState(); // 获取写状态，即写线程的数量 int w = exclusiveCount(c); // 同步状态不为 0 即有线程持有锁 if (c != 0) &#123; // (Note: if c != 0 and w == 0 then shared count != 0) // c 不为 0 而 w 为 0，说明此时读锁不为 0，无法获取写锁，false // 或者是 // w 不为 0，存在写锁，但是却是其他线程拿到了，false // 此时有读锁，无法获取写锁 // 或者，存在写锁，但是却是其他线程拿到了 if (w == 0 || current != getExclusiveOwnerThread()) return false; // 如果重入数量太大，Error if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); // Reentrant acquire // 重入 setState(c + acquires); return true; &#125; // 此时同步状态 c 等于 0，即没有读锁也没写锁 // writerShouldBlock 判断要不要获取锁 // 如果是非公平锁，直接 CAS 尝试获取锁，失败了才排队 // 如果是公平锁，如果队列前面有在排队，就放弃，没有排队才拿锁 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; // 记录拥有写锁的线程 setExclusiveOwnerThread(current); return true;&#125;// 公平锁final boolean writerShouldBlock() &#123; return hasQueuedPredecessors();&#125;// 非公平锁final boolean writerShouldBlock() &#123; return false; // writers can always barge&#125; 读锁获取1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); // 拿到同步状态 c int c = getState(); // 如果写锁不为 0 且 当前持有锁的线程不是当前线程(考虑锁降级)，退出 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; // 读锁的线程数 int r = sharedCount(c); // 公平锁看队列前面有没有在排队，有就放弃 // 没有在排队，且读线程小于最大数量，才 CAS 拿锁 // 非公平锁直接搞 if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; // CAS 如果失败了，那就 // 如果没有读线程 if (r == 0) &#123; // holdCount 等于 1 firstReader = current; firstReaderHoldCount = 1; // 如果有读线程，且是自己之前拿的锁，那 holdCount 就 ++ &#125; else if (firstReader == current) &#123; // ++ firstReaderHoldCount++; // 如果不是自己之前拿的锁 &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125;// 公平锁final boolean readerShouldBlock() &#123; return hasQueuedPredecessors();&#125;// 非公平锁final boolean readerShouldBlock() &#123; return apparentlyFirstQueuedIsExclusive();&#125;final boolean apparentlyFirstQueuedIsExclusive() &#123; Node h, s; return (h = head) != null &amp;&amp; (s = h.next) != null &amp;&amp; !s.isShared() &amp;&amp; s.thread != null;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354final int fullTryAcquireShared(Thread current) &#123; /* * This code is in part redundant with that in * tryAcquireShared but is simpler overall by not * complicating tryAcquireShared with interactions between * retries and lazily reading hold counts. */ HoldCounter rh = null; for (;;) &#123; int c = getState(); if (exclusiveCount(c) != 0) &#123; if (getExclusiveOwnerThread() != current) return -1; // else we hold the exclusive lock; blocking here // would cause deadlock. &#125; else if (readerShouldBlock()) &#123; // Make sure we&#x27;re not acquiring read lock reentrantly if (firstReader == current) &#123; // assert firstReaderHoldCount &gt; 0; &#125; else &#123; if (rh == null) &#123; rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) &#123; rh = readHolds.get(); if (rh.count == 0) readHolds.remove(); &#125; &#125; if (rh.count == 0) return -1; &#125; &#125; if (sharedCount(c) == MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); if (compareAndSetState(c, c + SHARED_UNIT)) &#123; if (sharedCount(c) == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; if (rh == null) rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; cachedHoldCounter = rh; // cache for release &#125; return 1; &#125; &#125;&#125; 释放123456789101112131415161718192021222324252627282930protected final boolean tryReleaseShared(int unused) &#123; Thread current = Thread.currentThread(); if (firstReader == current) &#123; // assert firstReaderHoldCount &gt; 0; if (firstReaderHoldCount == 1) firstReader = null; else firstReaderHoldCount--; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); int count = rh.count; if (count &lt;= 1) &#123; readHolds.remove(); if (count &lt;= 0) throw unmatchedUnlockException(); &#125; --rh.count; &#125; for (;;) &#123; int c = getState(); int nextc = c - SHARED_UNIT; if (compareAndSetState(c, nextc)) // Releasing the read lock has no effect on readers, // but it may allow waiting writers to proceed if // both read and write locks are now free. return nextc == 0; &#125;&#125; 锁降级锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程 先释放写锁再获取读锁这种分段的不能称为锁降级 主要是为了保证数据的可见性，如果当前线程不获取读锁而直接释放写锁，假设此刻另一个线程（T）获取了写锁并修改了数据，那么当前线程是无法感知线程 T 的数据更新。如果当前线程获取读锁，即遵循锁降级的步骤，则线程T将会被阻塞，知道当前线程使用数据并释放读锁之后，线程T才能获取写锁进行数据更新。 示例： 123456789101112131415161718192021222324252627282930313233class CachedData &#123; Object data; volatile boolean cacheValid; final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); void processCachedData() &#123; rwl.readLock().lock(); if (!cacheValid) &#123; // 必须先释放读锁 rwl.readLock().unlock(); // 锁降级从写锁获取到时开始 rwl.writeLock().lock(); try &#123; // Recheck state because another thread might have // acquired write lock and changed state before we did. if (!cacheValid) &#123; data = ... cacheValid = true; &#125; // Downgrade by acquiring read lock before releasing write lock rwl.readLock().lock(); &#125; finally &#123; rwl.writeLock().unlock(); // Unlock write, still hold read &#125; &#125; try &#123; use(data); &#125; finally &#123; rwl.readLock().unlock(); &#125; &#125;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://kebabshellgithub.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"锁","slug":"锁","permalink":"https://kebabshellgithub.github.io/tags/%E9%94%81/"}]},{"title":"Condition","slug":"Condition","date":"2020-12-22T23:00:33.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/22/Condition/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/22/Condition/","excerpt":"","text":"使用任何一个类都有父类 Object 提供的等待&#x2F;通知的监视器方法：wait、notify 等等 Condition 提供类似的等待&#x2F;通知方法，await 和 signal 等 12345678910Lock lock = new ReentrantLock();Condition condition = lock.newCondition();lock.lock();try &#123; condition.await(); // condition.signal();&#125; finaly &#123; lock.unlock();&#125; 对于 lock 的 newCondition，是 new 了一个 ConditionObject 123final ConditionObject newCondition() &#123; return new ConditionObject();&#125; 数据结构 &amp; 原理这个 ConditionObject 定义在 AQS 中 而 ConditionObject 同样维护了一个队列，叫 条件队列( condition queue ) 它和锁的 同步队列( sync queue )一样，都是由 AQS 定义的 Node 节点组成，不同的是： 在同步队列中 Node 节点的连接是用 prev 和 next，是双向队列，nextWaiter 属性为 null waitStatus 有 CANCELLED、SIGNAL 等 在条件队列中 Node 节点的连接是用 nextWaiter，是单向队列，prev 和 next 都为 null waitStatus 只有 CONDITION( - 2 )一个，它表示线程处于正常的等待状态 每创建一个 Condtion 对象就会 对应一个条件队列，每一个调用了 Condtion 对象的 await 方法的线程都会被包装成 Node 扔进一个条件队列中 每个条件队列都是独立的，互相不影响 sync queue 是等待锁的队列，当一个线程被包装成 Node 加到该队列中时，必然是没有获取到锁；当处于该队列中的节点获取到了锁，它将从该队列中移除( 事实上移除操作是将获取到锁的节点设为新的 dummy head，并将 thread 属性置为 null ) condition queue 是等待在 特定条件 下的队列，因为调用 await 方法时，必然是已经获得了 lock 锁，所以在进入 condition queue 之前 已经获取了锁；在被包装成 Node 扔进条件队列中后，线程将 释放 锁，然后挂起；当处于该队列中的线程被 signal 方法唤醒后，由于队列中的节点在之前挂起的时候已经释放了锁，被唤醒的线程和普通线程一样需要去争锁，如果没有抢到，则同样要被加到等待锁的 sync queue 中，此时节点就从 condition queue 被转移到 sync queue 中。因此，条件队列在出队时，线程并不持有锁 所以事实上，这两个队列的锁状态正好相反： condition queue：入队时已经持有了锁 -&gt; 在队列中释放锁 -&gt; 离开队列时没有锁 -&gt; 转移到 sync queue sync queue：入队时没有锁 -&gt; 在队列中争锁 -&gt; 离开队列时获得了锁 唤醒的线程加到 sync queue 时，Node 是被一个一个转移过去的，哪怕调用的是 signalAll 也是一个一个转移过去的，而不是将整个 condition queue 接在 sync queue 的末尾 signal123456789101112131415161718192021222324252627282930313233343536373839public final void signal() &#123; // 先看此线程是否持有锁 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 把第一个 Node 移到 sync queue 并唤醒 Node first = firstWaiter; if (first != null) // 执行 doSignal(first);&#125;// 这里只移动第一个 Nodeprivate void doSignal(Node first) &#123; do &#123; // 修改队列第一个节点 firstWaiter if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; // 把之前的第一个节点 first 独立出来 first.nextWaiter = null; // transferForSignal 移动 first，成功就结束循环了 &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null);&#125;final boolean transferForSignal(Node node) &#123; // 修改移动的节点的 waitStatus if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; // enq 自旋 + CAS 加到 sync queue 尾部 // 成功后返回前一个节点 Node p = enq(node); // 拿到前一个节点的 waitStatus int ws = p.waitStatus; // 设置前一个节点的 waitStatus 为 SIGNAL，相对于设闹钟，然后唤醒 unpark 尾节点 if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;&#125; await 对于中断模式 interruptMode，有： THROW_IE( - 1 ) 表示退出 await 方法时需要抛出 InterruptedException，这种模式对应于中断发生在 signal 之前 0 表示整个过程中一直没有中断发生 REINTERRUPT( 1 ) 表示退出 await 时只需要再自我中断，这种模式对应于中断发生在 signal 之后，即中断来的太晚了 12345678910111213141516171819202122232425262728293031323334public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 构造 Node 节点，把节点加到条件队列 Node node = addConditionWaiter(); // 释放所有锁，包括多次重入的锁，savedState 是释放之前的锁状态 int savedState = fullyRelease(node); int interruptMode = 0; // 如果没有出现在 sync queue，说明已经 await，还没被 signal // 此时应该把线程挂起，等待 signal while (!isOnSyncQueue(node)) &#123; // 挂起当前线程，此时线程已经挂起，没有继续执行 LockSupport.park(this); // 当执行到这里，有两种情况 // 1.当前线程被 signal // 2.当前线程中断 // checkInterruptWhileWaiting 检查是否有中断 // 如果在 signal 之前被中断，则返回 THROW_IE // 在 signal 之后，则返回 REINTERRUPT // 如果没有被中断，则返回 0 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; // 唤醒后就得按 sync queue 争锁的方式了，抢到锁就返回，抢不到锁就继续被挂起 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // 获取到锁后，调用 unlinkCancelledWaiters 将自己从条件队列中移除 // 该方法还会顺便移除其他取消等待的锁 if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) // 处理中断 reportInterruptAfterWait(interruptMode);&#125; 123456789101112131415161718192021222324252627282930private Node addConditionWaiter() &#123; Node t = lastWaiter; // If lastWaiter is cancelled, clean out. // 如果尾节点是 cancel，则先遍历队列，清除所有 cancel 的节点 if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; // 该方法将从头节点开始遍历整个队列，剔除其中 waitStatus 不为 Node.CONDTION 的节点 unlinkCancelledWaiters(); // 此时拿到 不是 cancel 的尾节点 t = lastWaiter; &#125; // 构造新 Node，设为 CONDITION Node node = new Node(Thread.currentThread(), Node.CONDITION); // 如果空，那 node 就是头，不空，node 就是尾 if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node;&#125;// 处理中断private void reportInterruptAfterWait(int interruptMode) throws InterruptedException &#123; // 抛出 if (interruptMode == THROW_IE) throw new InterruptedException(); // 自己决定 else if (interruptMode == REINTERRUPT) selfInterrupt();&#125; signal 唤醒 or 中断唤醒signal 唤醒为正常唤醒 中断唤醒为不正常唤醒，分为 signal 之前中断 和 signal 之后中断 12345678910111213141516171819202122// 检查是否有中断// 如果在 signal 之前被中断，则返回 THROW_IE// 在 signal 之后被中断，则返回 REINTERRUPT// 如果没有被中断，则返回 0private int checkInterruptWhileWaiting(Node node) &#123; return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0;&#125;final boolean transferAfterCancelledWait(Node node) &#123; // 如果 signal 之前发生中断，就加入 sync queue，返回 true if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) &#123; enq(node); return true; &#125; // 如果之前状态不是 CONDITION，表明是 signal 之后发生中断 // 看看有没有加入 sync queue // 到这里只需要等待线程成功进入 sync queue 即可 while (!isOnSyncQueue(node)) Thread.yield(); return false;&#125; 对于在 signal 之前中断唤醒的流程： 线程因为中断，从挂起的地方被唤醒 通过transferAfterCancelledWait 确认了线程的 waitStatus 值为 CONDITION，说明并没有 signal 发生过 然后我们修改线程的 waitStatus 为 0，并通过 enq 将其添加到 sync queue 中 接下来线程将在 sync queue 中以阻塞的方式获取，如果获取不到锁，将会被再次挂起 线程在sync queue中获取到锁后，将调用 unlinkCancelledWaiters 方法将自己从条件队列中移除，该方法还会顺便移除其他取消等待的锁 最后 reportInterruptAfterWait 抛出 InterruptedException 对于在 signal 之后中断： 忽略中断，推迟至 await() 返回时再发生 总结 进入 await 时必须是已经持有了锁 离开 await 时同样必须是已经持有了锁 调用 await 会使得当前线程被封装成 Node 扔进条件队列，然后释放所持有的锁 释放锁后，当前线程将在 condition queue 中被挂起，等待 signal 或者中断 线程被唤醒后会将会离开 condition queue 进入 sync queue 中进行抢锁 若在线程抢到锁之前发生过中断，则根据中断发生在 signal 之前还是之后记录中断模式 线程在抢到锁后进行善后工作( 离开 condition queue，处理中断异常 ) 线程已经持有了锁，从 await 方法返回 注意中断 中断和 signal 所起到的作用都是将线程从 condition queue 中移除，加入到 sync queue 中去争锁 所不同的是，signal 方法被认为是正常唤醒线程，中断方法被认为是非正常唤醒线程 如果中断发生在 signal 之前，则我们在最终返回时，应当抛出 InterruptedException 如果中断发生在 signal 之后，我们就认为线程本身已经被正常唤醒了，这个中断来的太晚了，我们直接忽略它，并在 await 返回时再自我中断一下，这种做法相当于将中断推迟至 await() 返回时再发生 在await()方法返回后，如果是因为中断被唤醒，则await()方法需要抛出InterruptedException异常，表示是它是被非正常唤醒的 只要它是在signal之后发生的，我们就认为它来的太晚了，我们将忽略这个中断。因此，从await()方法返回的时候，我们只会将当前线程重新中断一下，而不会抛出中断异常 awaitUninterruptibly中断属于将一个等待中的线程非正常唤醒，可能即使线程被唤醒后，也抢到了锁，但是却发现当前的等待条件并没有满足，则还是得把线程挂起 awaitUninterruptibly 即不希望 await 方法被中断 awaitNanos如果设定的超时时间还没到，就将线程挂起 超过等待的时间了，就将线程从 condtion queue 转移到 sync queue 当设定的超时时间很短时( 小于 spinForTimeoutThreshold )，就简单的自旋，而不是将线程挂起，以减少挂起线程和唤醒线程所带来的时间消耗 await(long time, TimeUnit unit)awaitNanos(long nanosTimeout) 的返回值是剩余的超时时间 如果该值大于 0，说明超时时间还没到，则说明该返回是由 signal 行为导致的 而 await(long time, TimeUnit unit) 的返回值就是 transferAfterCancelledWait(node) 的值 如果调用该方法时，node 还没有被 signal 过则返回 true，node 已经被 signal 过了，则返回 false 因此当 await(long time, TimeUnit unit) 方法返回 true，则说明在超时时间到之前就已经发生过 signal 了，该方法的返回是由 signal 方法导致的而不是超时时间 await(long time, TimeUnit unit) 等价于 awaitNanos(unit.toNanos(time)) &gt; 0 参考文章","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://kebabshellgithub.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"Spring 基础","slug":"Spring-基础","date":"2020-12-17T21:50:35.000Z","updated":"2023-04-06T11:06:55.026Z","comments":true,"path":"2020/12/17/Spring-基础/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/17/Spring-%E5%9F%BA%E7%A1%80/","excerpt":"","text":"Spring 基础Spring 最重要的特性就是控制反转、依赖注入和面向切面编程 这三个特性都不是 Spring 提出的，只是使用 而 DI 是 IOC 的一种实现方式 基本概念IOCIOC: Inversion of Control 在 Spring 里，控制反转就是使用者把对象的控制权交给 Spring 反转的是自己对对象的控制，这个控制交给 Spring Spring 控制的是 bean 的创建、管理和生命周期 DIDI: Dependency Injection DI 是 IOC 的实现方式 对象的创建需要外部的各种资源，如数据、文件、对象等 Spring 把这些资源自动帮你注入到 bean，顺带着帮你维护 bean 之间的依赖关系 组成 总共 8 个模块，每个模块既可以单独使用，又可与其他模块联合使用 绿色表示一个模块 黑色表示 jar 包 ( SpEL, Spring Express Language ) Bean bean 是 Spring 帮你自己的对象穿上衣服，形成的对象 在 Spring 中，操作的都是 bean，bean 在 Spring 实现中是 BeanDefinition 容器容器管理着 bean 的生命周期，控制着 bean 的依赖注入 有两个接口定义 容器的根本 BeanFactory BeanFactory 代表 低级容器，基本就是个 Map，key 是 BeanName，value 是 Bean 实例。通常只提供注册（put），获取（get）这两个功能 ApplicationContext ApplicationContext 代表 高级容器，提供了更全面、高级的功能，例如获取资源，发布事件等 ApplicationContext 就是升级版的 BeanFactory ApplicationContext 继承自 BeanFactory，但是它不应该被理解为 BeanFactory 的实现类，而是说其内部持有一个实例化的 BeanFactory（DefaultListableBeanFactory）。以后所有的 BeanFactory 相关的操作其实是委托给这个实例来处理的 ListableBeanFactory: 通过这个接口，可以获取多个 Bean 最顶层 BeanFactory 接口的方法 都是获取单个 Bean 的 HierarchicalBeanFactory: 可以在应用中起 多个 BeanFactory，然后可以将各个 BeanFactory 设置为父子关系 AutowireCapableBeanFactory: 用来自动装配 Bean 用的，但是 ApplicationContext 并没有继承它 ApplicationContext 接口定义的 getAutowireCapableBeanFactory 可拿到 ConfigurableListableBeanFactory: 它继承了上面的三个接口 应用上下文ApplicationContext 作为基本的应用上下文接口，有不同的实现类 常用的就是 AnnotationConfigApplicationContext: 基于注解，不需要配置文件 ClassPathXmlApplicationContext: classpath 下的 xml 配置文件 FileSystemXmlApplicationContext: 系统下的 xml 配置文件 容器启动过程以 ClassPathXmlApplicationContext 为例 1234567891011121314151617181920public class Car &#123; private String brand; private int age; public Car()&#123; System.out.println(&quot;constructor&quot;); &#125; public void setAge(int age)&#123; this.age = age; &#125; public void setBrand(String brand)&#123; this.brand = brand; &#125; public String toString()&#123; return &quot;brand:&quot; + this.brand + &quot;,age:&quot; + this.age; &#125;&#125; 12345678910&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;car&quot; class=&quot;cn.kebabshell.learn.bean.Car&quot;&gt; &lt;property name=&quot;age&quot; value=&quot;12&quot; /&gt; &lt;property name=&quot;brand&quot; value=&quot;bmw&quot; /&gt; &lt;/bean&gt;&lt;/beans&gt; 12345678public static void main(String[] args) &#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;services.xml&quot;); Car car = applicationContext.getBean(&quot;car&quot;, Car.class); System.out.println(car);&#125; 在构造中 1234567891011public ClassPathXmlApplicationContext( String[] configLocations, boolean refresh, @Nullable ApplicationContext parent) throws BeansException &#123; super(parent); setConfigLocations(configLocations); if (refresh) &#123; // 重中之重，初始化和运行时刷新 refresh(); &#125;&#125; refresh 关于 BeanPostProcessor 和 BeanFactoryPostProcessor，看这里 实例化的意思在对象还未生成，初始化的意思在对象已经生成 重点：finishBeanFactoryInitialization 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public void refresh() throws BeansException, IllegalStateException &#123; // 互斥锁，不然 refresh 还没结束，又来个启动或销毁容器的操作，就乱了 synchronized (this.startupShutdownMonitor) &#123; // 准备工作，记录下容器的启动时间、标记“已启动”状态、处理配置文件中的占位符 prepareRefresh(); // 这步比较关键，这步完成后，配置文件就会解析成一个个 Bean 定义，注册到 BeanFactory 中 // 当然，这里说的 Bean 还没有实例化，只是配置信息都提取出来了 // 注册也只是将这些信息都保存到了注册中心 // ( 说到底核心是一个 beanName-&gt; beanDefinition 的 map ) ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 设置 BeanFactory 的类加载器，添加几个 BeanPostProcessor，手动注册几个特殊的 bean prepareBeanFactory(beanFactory); try &#123; // Bean 如果实现了接口 BeanFactoryPostProcessor // 在容器实例化之前，会调用 postProcessBeanFactory 方法 // 这里是提供给子类的扩展点，到这里的时候，所有的 Bean 都找到了、注册完成了，但是都还没有实例化 // 具体的子类可以在这步的时候添加一些特殊的 BeanFactoryPostProcessor 的实现类或做点什么事 // 如修改 BeanDefinition postProcessBeanFactory(beanFactory); // 调用 BeanFactoryPostProcessor 各个实现类的 postProcessBeanFactory(factory) 回调方法 invokeBeanFactoryPostProcessors(beanFactory); // 注册 BeanPostProcessor 的实现类，注意看和 BeanFactoryPostProcessor 的区别 // 此接口有两个方法: postProcessBeforeInitialization 和 postProcessAfterInitialization // 两个方法分别在 Bean 初始化之前和初始化之后得到执行 // 这里仅仅是注册，之后会在 doCreateBean 看到回调这两方法的时机 registerBeanPostProcessors(beanFactory); // 初始化当前 ApplicationContext 的 MessageSource，国际化 initMessageSource(); // 初始化当前 ApplicationContext 的事件广播器 initApplicationEventMulticaster(); // 模板方法 // 子类可以在这里初始化一些特殊的 Bean( 在初始化 singleton beans 之前 ) onRefresh(); // 注册事件监听器，监听器需要实现 ApplicationListener 接口 registerListeners(); // 重点，重点，重点 // 初始化所有的 singleton beans // ( lazy-init 的除外 ) finishBeanFactoryInitialization(beanFactory); // 最后，广播事件，ApplicationContext 初始化完成 finishRefresh(); &#125; catch (BeansException ex) &#123; // log // Destroy already created singletons to avoid dangling resources. // 销毁已经初始化的 singleton 的 Beans，以免有些 bean 会一直占用资源 destroyBeans(); // Reset &#x27;active&#x27; flag. cancelRefresh(ex); // 把异常往外抛 throw ex; &#125; finally &#123; // Reset common introspection caches in Spring&#x27;s core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 1、prepareRefresh创建 Bean 容器前的准备工作 记录启动时间 校验 xml 配置文件 … 1234567891011121314151617181920212223242526272829protected void prepareRefresh() &#123; // Switch to active. this.startupDate = System.currentTimeMillis(); this.closed.set(false); this.active.set(true); // logger... // Initialize any placeholder property sources in the context environment. initPropertySources(); // Validate that all properties marked as required are resolvable: // see ConfigurablePropertyResolver#setRequiredProperties getEnvironment().validateRequiredProperties(); // Store pre-refresh ApplicationListeners... if (this.earlyApplicationListeners == null) &#123; this.earlyApplicationListeners = new LinkedHashSet&lt;&gt;(this.applicationListeners); &#125; else &#123; // Reset local application listeners to pre-refresh state. this.applicationListeners.clear(); this.applicationListeners.addAll(this.earlyApplicationListeners); &#125; // Allow for the collection of early ApplicationEvents, // to be published once the multicaster is available... this.earlyApplicationEvents = new LinkedHashSet&lt;&gt;();&#125; 2、obtainFreshBeanFactory初始化 BeanFactory、加载 Bean、注册 Bean 等等 这步结束后，Bean 并没有完成实例化和初始化 注册也只是将这些信息都保存到了一个 map 里 1234protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; refreshBeanFactory(); return getBeanFactory();&#125; refreshBeanFactory 12345678910111213141516171819protected final void refreshBeanFactory() throws BeansException &#123; if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); // 配置是否允许 BeanDefinition 覆盖、是否允许循环引用 customizeBeanFactory(beanFactory); loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; // throw... &#125;&#125; customizeBeanFactory 12345678protected void customizeBeanFactory(DefaultListableBeanFactory beanFactory) &#123; if (this.allowBeanDefinitionOverriding != null) &#123; beanFactory.setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; if (this.allowCircularReferences != null) &#123; beanFactory.setAllowCircularReferences(this.allowCircularReferences); &#125;&#125; 配置是否允许 BeanDefinition 覆盖、是否允许循环引用 BeanDefinition 的覆盖问题可能会有开发者碰到这个坑，就是在配置文件中定义 bean 时使用了相同的 id 或 name，默认情况下，allowBeanDefinitionOverriding 属性为 null，如果在同一配置文件中重复了，会抛错，但是如果不是同一配置文件中，会发生覆盖 循环引用即：A 依赖 B，而 B 依赖 A。或 A 依赖 B，B 依赖 C，而 C 依赖 A 默认情况下，Spring 允许循环依赖，当然如果你在 A 的构造方法中依赖 B，在 B 的构造方法中依赖 A 是不行的 loadBeanDefinitions根据配置，加载各个 Bean，然后放到 BeanFactory 中 读取配置的操作在 XmlBeanDefinitionReader 中，其负责加载配置、解析 1234// XmlBeanDefinitionReaderpublic int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException &#123; return loadBeanDefinitions(new EncodedResource(resource));&#125; 123456789101112131415161718192021222324252627public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &#123; Assert.notNull(encodedResource, &quot;EncodedResource must not be null&quot;); // logger... Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (!currentResources.add(encodedResource)) &#123; // throw... &#125; try (InputStream inputStream = encodedResource.getResource().getInputStream()) &#123; InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; catch (IOException ex) &#123; // throw... &#125; finally &#123; currentResources.remove(encodedResource); if (currentResources.isEmpty()) &#123; this.resourcesCurrentlyBeingLoaded.remove(); &#125; &#125;&#125; doRegisterBeanDefinitions 解析标签 注册 此时 Bean 依然还没有实例化初始化 12345678910111213protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; // 解析 Document doc = doLoadDocument(inputSource, resource); // 注册 int count = registerBeanDefinitions(doc, resource); // logger... return count; &#125; // catch throw...&#125; 3、prepareBeanFactory设置 BeanFactory 的类加载器，添加几个 BeanPostProcessor，Spring 手动注册几个 bean 如果没有定义 environment systemProperties systemEnvironment 这几个 bean，那么 Spring 会 “手动” 注册一个 12345678910111213141516171819202122232425262728293031323334353637383940414243protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; // Tell the internal bean factory to use the context&#x27;s class loader etc. beanFactory.setBeanClassLoader(getClassLoader()); beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader())); beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment())); // Configure the bean factory with context callbacks. beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this)); beanFactory.ignoreDependencyInterface(EnvironmentAware.class); beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class); beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class); beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class); beanFactory.ignoreDependencyInterface(MessageSourceAware.class); beanFactory.ignoreDependencyInterface(ApplicationContextAware.class); // BeanFactory interface not registered as resolvable type in a plain factory. // MessageSource registered (and found for autowiring) as a bean. beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory); beanFactory.registerResolvableDependency(ResourceLoader.class, this); beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this); beanFactory.registerResolvableDependency(ApplicationContext.class, this); // Register early post-processor for detecting inner beans as ApplicationListeners. beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this)); // Detect a LoadTimeWeaver and prepare for weaving, if found. if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); // Set a temporary ClassLoader for type matching. beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125; // Register default environment beans. if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) &#123; beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment()); &#125; if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) &#123; beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties()); &#125; if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) &#123; beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment()); &#125;&#125; 4、finishBeanFactoryInitialization一些基本的步骤可通过 debug 查看： 123456789101112131415161718192021222324252627282930313233protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123; // Initialize conversion service for this context. // 初始化名字为 conversionService 的 Bean if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp; beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) &#123; beanFactory.setConversionService( beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)); &#125; // Register a default embedded value resolver if no bean post-processor // (such as a PropertyPlaceholderConfigurer bean) registered any before: // at this point, primarily for resolution in annotation attribute values. if (!beanFactory.hasEmbeddedValueResolver()) &#123; beanFactory.addEmbeddedValueResolver(strVal -&gt; getEnvironment().resolvePlaceholders(strVal)); &#125; // Initialize LoadTimeWeaverAware beans early to allow for registering their transformers early. String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false); for (String weaverAwareName : weaverAwareNames) &#123; getBean(weaverAwareName); &#125; // Stop using the temporary ClassLoader for type matching. beanFactory.setTempClassLoader(null); // Allow for caching all bean definition metadata, not expecting further changes. // 不希望这个时候还出现 bean 定义解析、加载、注册，就得 freeze beanFactory.freezeConfiguration(); // Instantiate all remaining (non-lazy-init) singletons. // 对于普通的 Bean，只要调用 getBean(beanName) 这个方法就可以进行初始化了 beanFactory.preInstantiateSingletons();&#125; 实例化所有的 singleton beans ( 没有设置懒加载 ) preInstantiateSingletons对于普通的 Bean，只要调用 getBean(beanName) 这个方法就可以进行实例化了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// DefaultListableBeanFactorypublic void preInstantiateSingletons() throws BeansException &#123; // logger... // Iterate over a copy to allow for init methods which in turn register new bean definitions. // While this may not be part of the regular factory bootstrap, it does otherwise work fine. List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); // Trigger initialization of all non-lazy singleton beans... for (String beanName : beanNames) &#123; RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123; if (isFactoryBean(beanName)) &#123; Object bean = getBean(FACTORY_BEAN_PREFIX + beanName); if (bean instanceof FactoryBean) &#123; final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) bean; boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123; isEagerInit = AccessController.doPrivileged((PrivilegedAction&lt;Boolean&gt;) ((SmartFactoryBean&lt;?&gt;) factory)::isEagerInit, getAccessControlContext()); &#125; else &#123; isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); &#125; if (isEagerInit) &#123; getBean(beanName); &#125; &#125; &#125; else &#123; getBean(beanName); &#125; &#125; &#125; // Trigger post-initialization callback for all applicable beans... for (String beanName : beanNames) &#123; Object singletonInstance = getSingleton(beanName); if (singletonInstance instanceof SmartInitializingSingleton) &#123; final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; smartSingleton.afterSingletonsInstantiated(); return null; &#125;, getAccessControlContext()); &#125; else &#123; smartSingleton.afterSingletonsInstantiated(); &#125; &#125; &#125;&#125; getBean -&gt; doGetBean -&gt; createBeansingleton 和 prototype 分别处理 1234// AbstractBeanFactorypublic Object getBean(String name) throws BeansException &#123; return doGetBean(name, null, null, false);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123protected &lt;T&gt; T doGetBean(final String name, @Nullable final Class&lt;T&gt; requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException &#123; // 如果是 FactoryBean,会去掉 Bean 开头的 &amp; 符号 // 能存在传入别名且别名存在多重映射的情况，这里会返回最终的名字 // 如存在多层别名映射 A-&gt;B-&gt;C-&gt;D，传入 D，最终会返回 A final String beanName = transformedBeanName(name); Object bean; // Eagerly check singleton cache for manually registered singletons. // getSingleton() 方法的实现，在父类 DefaultSingletonBeanRegistry 中 Object sharedInstance = getSingleton(beanName); // 这里先尝试从缓存中获取，若获取不到，就走下面的创建( 循环依赖 ) if (sharedInstance != null &amp;&amp; args == null) &#123; // ... &#125; else &#123; // Fail if we&#x27;re already creating this bean instance: // We&#x27;re assumably within a circular reference. // 原型对象不允许循环创建，如果是原型对象正在创建，那就抛异常 if (isPrototypeCurrentlyInCreation(beanName)) &#123; // throw &#125; // Check if bean definition exists in this factory. // 若存在父容器，得看看父容器是否实例化过它了，避免被重复实例化（若父容器被实例化，就以父容器的为准） // 比如扫描 controller，哪怕不加排除什么的，也不会出问题的原因，因为 Spring 中的单例 Bean 只会被实例化一次，即使父子容器都扫描了 BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // Not found -&gt; check parent. String nameToLookup = originalBeanName(name); if (parentBeanFactory instanceof AbstractBeanFactory) &#123; return ((AbstractBeanFactory) parentBeanFactory).doGetBean( nameToLookup, requiredType, args, typeCheckOnly); &#125; else if (args != null) &#123; // Delegation to parent with explicit args. return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else if (requiredType != null) &#123; // No args -&gt; delegate to standard getBean method. return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; else &#123; return (T) parentBeanFactory.getBean(nameToLookup); &#125; &#125; // alreadyCreated 字段增加此值。表示此 Bean 已经创建了 if (!typeCheckOnly) &#123; markBeanAsCreated(beanName); &#125; try &#123; // 根据名字获取合并过的对应的 RootBeanDefinition final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // Guarantee initialization of beans that the current bean depends on. // 我们会有属性注入等等，这里就是要保证它依赖的那些属性先初始化才行 // 这部分是处理循环依赖的核心 // @DependsOn 注解可以控制 Bean 的初始化顺序 String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; // throw &#125; registerDependentBean(dep, beanName); try &#123; getBean(dep); &#125; // throw &#125; &#125; // Create bean instance. // 开始创建 Bean 实例 // 如果是 singleton if (mbd.isSingleton()) &#123; // 也是一样先尝试从缓存去获取，获取失败就通过 ObjectFactory 的 createBean 方法创建 // 这个 getSingleton 方法和上面是重载方法，它支持通过 ObjectFactory 去根据 Scope 来创建对象 sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; // 创建 Bean 的核心方法 return createBean(beanName, mbd, args); &#125; // throw 执行失败，就销毁 Bean。然后执行对应的 destroy 方法 &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; // 如果是 prototype else if (mbd.isPrototype()) &#123; // It&#x27;s a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; // ... &#125; // throw &#125; // Check if required type matches the type of the actual bean instance. if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) &#123; try &#123; T convertedBean = getTypeConverter().convertIfNecessary(bean, requiredType); if (convertedBean == null) &#123; // throw &#125; return convertedBean; &#125; // throw &#125; return (T) bean;&#125; createBean -&gt; doCreateBeandoCreateBean 的步骤 实例化，createBeanInstance 工厂模式实例化，然后看参数来调用不同的构造函数 解决 循环依赖 前面只是实例化，这里是属性注入&#x2F;设值 populateBean 处理 bean 初始化完成后的各种回调 initializeBean 12345678910111213141516171819202122232425262728293031323334353637383940414243// AbstractAutowireCapableBeanFactoryprotected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; // logger... RootBeanDefinition mbdToUse = mbd; // Make sure bean class is actually resolved at this point, and // clone the bean definition in case of a dynamically resolved Class // which cannot be stored in the shared merged bean definition. // 确保对应 BeanClass 完成解析(已经加载进来了 Class 对象) // ... // Prepare method overrides. // ... try &#123; // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. // 给 BeanPostProcessors 一个机会来返回一个代理对象代替目标对象( AOP ) // 在所有 bean 创建之前，都会先调用 resolveBeforeInstantiation 方法 // 如果返回的 bean 为 null，就不会执行 postProcessBeforeInitialization 和 after // 到下面才调用 doCreateBean 来创建 bean，以及执行 postProcessBeforeInitialization 和 after // 来形成代理对象 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) &#123; return bean; &#125; &#125; catch (Throwable ex) &#123; // throw &#125; try &#123; Object beanInstance = doCreateBean(beanName, mbdToUse, args); // logger.. return beanInstance; &#125; // throw&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243protected Object doCreateBean( final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &#123; // Instantiate the bean. // ... if (instanceWrapper == null) &#123; // 实例化 instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; // ... // Allow post-processors to modify the merged bean definition. // ... // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. // ... // Initialize the bean instance. Object exposedObject = bean; try &#123; // 属性赋值 populateBean(beanName, mbd, instanceWrapper); // 初始化 exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; // throw if (earlySingletonExposure) &#123; // ... &#125; // Register bean as disposable. try &#123; // 销毁-注册回调接口 registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; // throw return exposedObject;&#125; AOP使用 参考文章 Instantiation 表示实例化，Initialization 表示初始化 实例化的意思在对象还未生成，初始化的意思在对象已经生成 原理之前的 文章 说到 AOP 的实现是依靠 BeanPostProcessor 而 AbstractAutoProxyCreator 实现了 postProcessAfterInitialization 方法 在实例化对象之前，createBean 里面会先执行 resolveBeforeInstantiation，给 BeanPostProcessors 一个机会 来返回一个代理对象代替目标对象( AOP ) 在所有 bean 创建之前，都会先调用 resolveBeforeInstantiation 方法 如果返回的 bean 为 null，就不会执行 postProcessBeforeInitialization 和 after 形成代理对象，到下面才调用 doCreateBean 来创建 bean postProcessAfterInitializationAbstractAutoProxyCreator 的 postProcessAfterInitialization 12345678910public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) &#123; if (bean != null) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); if (this.earlyProxyReferences.remove(cacheKey) != bean) &#123; // 核心！！！ return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean;&#125; 核心方法 wrapIfNecessarywrapIfNecessary 会执行 createProxy 创建代理对象 1234567891011121314151617181920212223242526protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123; if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123; return bean; &#125; if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123; return bean; &#125; if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; // Create proxy if we have advice. Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); if (specificInterceptors != DO_NOT_PROXY) &#123; this.advisedBeans.put(cacheKey, Boolean.TRUE); // createProxy 创建代理对象 Object proxy = createProxy( bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean;&#125; createProxy 创建代理对象 12345678910111213141516171819202122232425262728293031protected Object createProxy(Class&lt;?&gt; beanClass, @Nullable String beanName, @Nullable Object[] specificInterceptors, TargetSource targetSource) &#123; if (this.beanFactory instanceof ConfigurableListableBeanFactory) &#123; AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass); &#125; ProxyFactory proxyFactory = new ProxyFactory(); proxyFactory.copyFrom(this); if (!proxyFactory.isProxyTargetClass()) &#123; if (shouldProxyTargetClass(beanClass, beanName)) &#123; proxyFactory.setProxyTargetClass(true); &#125; else &#123; evaluateProxyInterfaces(beanClass, proxyFactory); &#125; &#125; Advisor[] advisors = buildAdvisors(beanName, specificInterceptors); proxyFactory.addAdvisors(advisors); proxyFactory.setTargetSource(targetSource); customizeProxyFactory(proxyFactory); proxyFactory.setFrozen(this.freezeProxy); if (advisorsPreFiltered()) &#123; proxyFactory.setPreFiltered(true); &#125; return proxyFactory.getProxy(getProxyClassLoader());&#125; ProxyFactory 的 getProxy 123public Object getProxy(@Nullable ClassLoader classLoader) &#123; return createAopProxy().getProxy(classLoader);&#125; DefaultAopProxyFactory 继承了 AopProxyFactory 123public interface AopProxyFactory &#123; AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException;&#125; 来到子类 DefaultAopProxyFactory 的 createAopProxy，这里会看是 JDKProxy 还是 CglibProxy 1234567891011121314151617public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; // throw... &#125; if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123; // JDKProxy return new JdkDynamicAopProxy(config); &#125; // CglibProxy return new ObjenesisCglibAopProxy(config); &#125; else &#123; return new JdkDynamicAopProxy(config); &#125;&#125; JDK or Cglib JDKProxy 以及 CglibProxy 这两种生成代理对象的方式在 AOP 中分别对应两个类：JdkDynamicAopProxy 和 CglibAopProxy，而 AopProxy 是这两个类的父接口 代理生成后会保存到 BeanWrappper 包装类里面，通过容器的 getBean() 方法获得的对象就是通过 JDK 或者 Cglib 生成的代理对象，我们使用的都是 代理对象 JDKProxy 实现是通过把 Advised 封装到 InvocationHandler 中实现的 CglibProxy 实现是通过把 Advised 封装到 MethodInterceptor 中实现的 对 JDKProxy 来说在 getProxy 方法里面，会： 获取代理类要实现的接口，除了 Advised 对象中配置的，还会加上 SpringProxy，Advised(opaque = false) 检查上面得到的接口中有没有定义 equals 或者 hashcode 的接口 调用 Proxy.newProxyInstance 创建代理对象 123456public Object getProxy(@Nullable ClassLoader classLoader) &#123; // logger... Class&lt;?&gt;[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised, true); findDefinedEqualsAndHashCodeMethods(proxiedInterfaces); return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this);&#125; 执行目标方法 InvocationHandler 是 JDK 动态代理的核心，织入切面，生成的代理对象的方法调用会委托到 InvocationHandler.invoke() 方法 JdkDynamicAopProxy 是 JDK 动态代理的实现类 JdkDynamicAopProxy 本身是一个 InvocationHandler，所以执行代理的某个方法时，会经过 JdkDynamicAopProxy.invoke 方法然后去调用目标方法 代理对象每次执行方法首先会进入 JdkDynamicAopProxy.invoke() 方法 首先会看是不是 equals、hashcode 等原生方法 如果是 DecoratingProxy 类和 Advised 接口的方法，都交由 proxy config 去执行，也就是 this.advised 然后会通过 getInterceptorsAndDynamicInterceptionAdvice() 方法获取 拦截链，这里面包括了增强，还有他们的执行顺序 如果拦截链空，则这个方法没有增强，那就 直接通过反射 执行目标对象方法，不会创建 如果拦截链不空，说明要增强，就创建 MethodInvocation( 这里是 ReflectiveMethodInvocation ) 递归执行 所有增强器 Adivce，执行 Advice.invoke() 方法进行拦截处理，在 链的尾部 通过反射执行目标方法 处理返回值 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Object target = null; try &#123; if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) &#123; // The target does not implement the equals(Object) method itself. // 如果对象没重写 equals，就返回JdkDynamicAopProxy 的 equals return equals(args[0]); &#125; else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &#123; // The target does not implement the hashCode() method itself. // 如果对象没重写 hashCode，就返回JdkDynamicAopProxy 的 hashCode return hashCode(); &#125; else if (method.getDeclaringClass() == DecoratingProxy.class) &#123; // There is only getDecoratedClass() declared -&gt; dispatch to proxy config. // DecoratingProxy 类和 Advised 接口的方法都交由 proxy config 去执行，也就是 this.advised return AopProxyUtils.ultimateTargetClass(this.advised); &#125; else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp; method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123; // Service invocations on ProxyConfig with the proxy config... return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); &#125; Object retVal; // 是否暴露代理对象，如果暴露就把当前代理对象放到 AopContext 上下文中 // 这样在本线程的其他地方也可以获取到代理对象了 if (this.advised.exposeProxy) &#123; // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; // 通过目标源获取目标对象 target = targetSource.getTarget(); Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null); // 拿到这个方法的拦截链 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); // 如果这个方法没有增强，那就直接通过反射执行目标对象方法，不会创建 MethodInvocation if (chain.isEmpty()) &#123; // We can skip creating a MethodInvocation: just invoke the target directly // Note that the final invoker must be an InvokerInterceptor so we know it does // nothing but a reflective operation on the target, and no hot swapping or fancy proxying. Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &#125; // 如果拦截链不空，说明要增强，就创建 MethodInvocation( 这里是 ReflectiveMethodInvocation ) else &#123; // 创建方法执行器 MethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); // 递归执行所有增强器 Adivce // 执行 Advice.invoke() 方法进行拦截处理，在链的尾部通过反射执行目标方法 retVal = invocation.proceed(); &#125; // 处理返回值 Class&lt;?&gt; returnType = method.getReturnType(); if (retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123; // Special case: it returned &quot;this&quot; and the return type of the method // is type-compatible. Note that we can&#x27;t help if the target sets // a reference to itself in another returned object. retVal = proxy; &#125; else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &#123; // throw... &#125; return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; // Must have come from TargetSource. targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; // Restore old proxy. AopContext.setCurrentProxy(oldProxy); &#125; &#125;&#125; 123456789101112131415161718192021222324252627public Object proceed() throws Throwable &#123; // 调用完了所有的拦截链中拦截器的增强方法，直接调用目标对象的方法并退出 if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return invokeJoinpoint(); &#125; // 从拦截器链中获取拦截器 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); // 动态匹配 if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; // 如果和定义的切点匹配，那么这个通知就会得到执行 if (dm.methodMatcher.matches(this.method, this.targetClass, this.arguments)) &#123; return dm.interceptor.invoke(this); &#125; else &#123; // 不适用递归继续获取拦截器进行匹配、判断、调用 return proceed(); &#125; &#125; else &#123; // 判断出这个拦截器是一个 MethodInterceptor，则直接调用 // 动态匹配失败则直接调用 return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); &#125;&#125; 对于 CglibProxy 来说CglibAopProxy 是 ObjenesisCglibAopProxy 的父类 123public ObjenesisCglibAopProxy(AdvisedSupport config) &#123; super(config);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public Object getProxy(@Nullable ClassLoader classLoader) &#123; // logger... try &#123; Class&lt;?&gt; rootClass = this.advised.getTargetClass(); // Assert... Class&lt;?&gt; proxySuperClass = rootClass; if (rootClass.getName().contains(ClassUtils.CGLIB_CLASS_SEPARATOR)) &#123; proxySuperClass = rootClass.getSuperclass(); Class&lt;?&gt;[] additionalInterfaces = rootClass.getInterfaces(); for (Class&lt;?&gt; additionalInterface : additionalInterfaces) &#123; this.advised.addInterface(additionalInterface); &#125; &#125; // Validate the class, writing log messages as necessary. validateClassIfNecessary(proxySuperClass, classLoader); // Configure CGLIB Enhancer... Enhancer enhancer = createEnhancer(); if (classLoader != null) &#123; enhancer.setClassLoader(classLoader); if (classLoader instanceof SmartClassLoader &amp;&amp; ((SmartClassLoader) classLoader).isClassReloadable(proxySuperClass)) &#123; enhancer.setUseCache(false); &#125; &#125; enhancer.setSuperclass(proxySuperClass); enhancer.setInterfaces(AopProxyUtils.completeProxiedInterfaces(this.advised)); enhancer.setNamingPolicy(SpringNamingPolicy.INSTANCE); enhancer.setStrategy(new ClassLoaderAwareGeneratorStrategy(classLoader)); Callback[] callbacks = getCallbacks(rootClass); Class&lt;?&gt;[] types = new Class&lt;?&gt;[callbacks.length]; for (int x = 0; x &lt; types.length; x++) &#123; types[x] = callbacks[x].getClass(); &#125; // fixedInterceptorMap only populated at this point, after getCallbacks call above enhancer.setCallbackFilter(new ProxyCallbackFilter( this.advised.getConfigurationOnlyCopy(), this.fixedInterceptorMap, this.fixedInterceptorOffset)); enhancer.setCallbackTypes(types); // Generate the proxy class and create a proxy instance. // 这里创建代理对象 return createProxyClassAndInstance(enhancer, callbacks); &#125; // catch...&#125; 执行目标方法 Cglib 动态代理执行链： 调用方法 -&gt; 动态代理类.方法 -&gt; MethodInterceptor.intercept 方法 -&gt; MethodInvocation.proceed 执行增强器链 -&gt; Adivce.invoke 方法 -&gt; 目标方法 CglibAopProxy 会创建一个 DynamicAdvisedInterceptor 来拦截目标方法的执行 DynamicAdvisedInterceptor 实现了 MethodInterceptor 当我们执行代理的某个方法时，会经过 DynamicAdvisedInterceptor.intercept() 方法然后去调用目标方法 intercept 的步骤 首先判断是否暴露代理 如果暴露，就把代理放到 AopContext 中，以便在其他地方也可以拿到 然后和 JDKProxy 中是一样，通过 DefaultAdvisorChainFactory 获取拦截链 如果拦截链为空，同时目标方法是 public 方法的话，直接使用反射执行目标方法 增强链不为空，则创建一个方法执行器 MethodInvocation( 这里创建的是 CglibMethodInvocation，JDKProxy 创建的是 ReflectiveMethodInvocation )来封装增强链和目标方法，执行 MethodInvocation.proceed() 因为 CglibMethodInvocation 是 ReflectiveMethodInvocation 的子类，所以后面就跟 JDKproxy 的执行一样了 最后就是处理返回值 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; Object target = null; TargetSource targetSource = this.advised.getTargetSource(); try &#123; // 是否暴露代理对象，如果暴露就把当前代理对象放到 AopContext 上下文中， // 这样在本线程的其他地方也可以获取到代理对象了 // 和 JDKProxy 类似 if (this.advised.exposeProxy) &#123; // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; // Get as late as possible to minimize the time we &quot;own&quot; the target, in case it comes from a pool... target = targetSource.getTarget(); Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null); // 一样，通过 DefaultAdvisorChainFactory 的 getInterceptorsAndDynamicInterceptionAdvice 拿到拦截链 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); Object retVal; // Check whether we only have one InvokerInterceptor: that is, // no real advice, but just reflective invocation of the target. // 如果拦截链空，且方法为 public，则这个方法没有增强，那就直接通过反射执行目标对象方法，不会创建 if (chain.isEmpty() &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = methodProxy.invoke(target, argsToUse); &#125; // 如果拦截链不空，说明要增强 // 创建一个方法执行器 MethodInvocation( 此处创建的是 CglibMethodInvocation )封装增强链 + 目标方法 // 执行 MethodInvocation.proceed() // 因为 CglibMethodInvocation 是 ReflectiveMethodInvocation 的子类 // 所以后面就跟 JDKproxy 的执行一样了 else &#123; // We need to create a method invocation... retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed(); &#125; // 处理返回值 retVal = processReturnType(proxy, target, method, retVal); return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; // Restore old proxy. AopContext.setCurrentProxy(oldProxy); &#125; &#125;&#125; 区别 JDK动态代理 利用拦截器(拦截器必须实现InvocationHanlder)加上反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理 CGLIB动态代理 利用ASM开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理 何时使用JDK还是CGLIB 如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP 如果目标对象实现了接口，可以强制使用CGLIB实现AOP 如果目标对象没有实现了接口，必须采用CGLIB库，Spring会自动在JDK动态代理和CGLIB之间转换。 事务传播行为总共 7 种 参考 PROPAGATION_REQUIRED所有 Propagation.REQUIRED 修饰的内部方法和外围方法均属于同一事务，只要一个方法回滚，整个事务均回滚 PROPAGATION_REQUIRES_NEWPropagation.REQUIRES_NEW 修饰的内部方法会单独开启独立事务，且与外部方法事务独立 注意：外部方法开启了事务，内部方法抛异常，会被外部方法感知，也会回滚（try catch可以让异常不被外部感知） PROPAGATION_NESTED在外围方法未开启事务的情况下Propagation.NESTED和Propagation.REQUIRED作用相同，修饰的内部方法都会新开启自己的事务，且开启的事务相互独立，互不干扰 外围开启事务，内围是外围的子事务，外围回滚，内围也要回滚 外围开启事务，内围是外围的子事务，内围抛异常回滚，外围感知到，外围也回滚，包括其他子事务（同样也可以try catch拒绝感知，这样外围不会回滚，其他子事务也就不会回滚了） 等等balabala 应用场景注册和添加积分 注册失败，添加积分也要回滚 添加积分失败，注册不回滚","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://kebabshellgithub.github.io/tags/Spring/"}]},{"title":"ReentrantLock","slug":"ReentrantLock","date":"2020-12-16T20:34:51.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/16/ReentrantLock/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/16/ReentrantLock/","excerpt":"","text":"ReentrantLock先看AQS 可重入锁、独占锁！！！ ReentrantLock 实现了 Lock 接口，实现 lock 等方法，lock由 Sync 实现，而 Sync 有抽象方法 lock ，由其子类实现 ReentrantLock 的抽象子类 Sync 继承了 AQS，子类公平锁 FairSync 和非公平锁 NonfairSync 继承 Sync 如果是同一个线程拿锁，就直接叠加状态 state 有两个构造，默认实现非公平锁： 12345678910111213141516171819202122232425262728public ReentrantLock() &#123; sync = new NonfairSync();&#125;public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125;public void lock() &#123; sync.lock();&#125;static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else // 这里会到 AQS 的 acquire，然后到下面的 tryAcquire acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; // tryAcquire 到这里的 nonfairTryAcquire return nonfairTryAcquire(acquires); &#125;&#125; 为什么默认是非公平锁？ 在恢复一个被挂起的线程与该线程真正运行之间存在着严重的延迟，这时候锁是空闲的，这段时间是浪费的 非公平锁是插队，但是如果插不了也要继续排队的( 在 lock 方法和 acquire 均有体现 ) Sync 继承了 AQS，那么需要实现独占锁相对应的 tryAcquire 方法，来获取锁( 读写锁就需要相对应的共享锁了 ) nonfairTryAcquire 和 tryAcquireSync 实现了非公平锁获取锁的逻辑，公平锁自己会实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475abstract static class Sync extends AbstractQueuedSynchronizer &#123; // 非公平锁 获取锁的实现 // 公平锁会自己实现 final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 直接插队 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; // 可重入 // 如果还是当前线程来拿锁，就直接叠加 // 在释放的时候也要一个一个释放 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125;&#125;// 非公平锁static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; // 对比 FairSync 的 lock // 这里直接尝试 CAS 获取锁 // 失败了才到 AQS acquire 里面获取锁，获取失败了排队( AQS acquireQueued ) final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125;// 公平锁static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1); &#125; // 公平锁获取失败会乖乖排队 protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 看前面有没有节点 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; // 可重入 int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125;&#125; 响应中断 关键：doAcquireInterruptibly lock 是不响应中断的 要响应中断，要用 lockInterruptibly 方法，有中断就会抛出 InterruptedException 无论是公平还是非公平，都是同一个 123public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1);&#125; 调用 AQS 的 acquireInterruptibly 123456789101112// AQSpublic final void acquireInterruptibly(int arg) throws InterruptedException &#123; // 先检查该线程是不是已经中断 // 如果中断，就直接抛异常 if (Thread.interrupted()) throw new InterruptedException(); // 如果没中断过，就继续尝试用 tryAcquire 获取锁，成功啥事没有 // 不成功就要跟之前的 lock 一样扔进队列，只是这一次是有响应中断的，即有中断，就抛异常 if (!tryAcquire(arg)) // 扔队列，和 acquireQueued 差不多，只是有响应中断 doAcquireInterruptibly(arg);&#125; doAcquireInterruptibly1234567891011121314151617181920212223// AQS// 有响应中断，对比下面的 acquireQueuedprivate void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; // 这里不一样 &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); // 不一样，如果检测到中断，会抛异常，而且进入 finally &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 123456// AQSprivate final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); // 如果有中断，就返回 true，在 doAcquireInterruptibly 里就会抛异常 return Thread.interrupted();&#125; 1234567891011121314151617181920212223242526272829// AQS// 对比 acquireQueuedfinal boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); // 只有前驱是头节点才能尝试获取同步状态 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 获取同步状态成功 // 设置头节点 // 这里都不需要 CAS，因为已经拿到锁了 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 如果获取同步状态失败，会将前驱节点设置为 SIGNAL 状态，然后阻塞 // shouldParkAfterFailedAcquire 返回 true 时才会执行 parkAndCheckInterrupt if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; // 不响应中断，只是记录 &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; cancelAcquirecancelAcquire 取消了当前节点的排队，还会同时将当前节点之前的那些已经 CANCEL 掉的节点移出队列 在并发条件下，新的节点可能已经入队了，成为了新的尾节点，会将当前节点即尾节点的 waitStatus 修改成了 SIGNAL，而在这时，我们发起了中断，又将这个 waitStatus 修改成 CANCELLED，它的闹钟就莫得了，所以在当前节点在出队之前，要负责唤醒后面新加入的节点 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// AQSprivate void cancelAcquire(Node node) &#123; // Ignore if node doesn&#x27;t exist // 忽略 if (node == null) return; node.thread = null; // Skip cancelled predecessors // 由当前节点向前遍历，跳过那些 Cancel 的节点 // 从当前节点向前开始查找，找到第一个 waitStatus &gt; 0 的 Node, 该节点为 pred Node pred = node.prev; while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // predNext 即是 pred 节点的下一个节点 // 到这里可知，pred 节点是没有被 Cancel 的节点，但是 pred 节点往后，一直到当前节点 Node 都处于被 Cancel 的状态 Node predNext = pred.next; // 把当前 Node 节点设为 Cancel node.waitStatus = Node.CANCELLED; // 如果当前节点是尾节点，则将之前找到的节点 pred 重新设置成尾节点，并将 pred 节点的 next 属性由 predNext 修改成 Null // 这一段本质上是将 pred 节点后面的节点全部移出队列，因为它们都被 Cancel 掉了 if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123; // 当前节点已经不是尾节点了，或者说设置新的尾节点失败了 // 在并发条件下，其他线程可能已经入队了，成为了新的尾节点 // 虽然我们之前已经将当前节点的 waitStatus 设为了 CANCELLED // 但在 lock 方法中，新的节点入队后会让前面的节点为自己设闹钟，即将前面节点的 status 设为 SIGNAL 以唤醒自己 // 所以，在当前节点的后继节点入队后，可能将当前节点的 waitStatus 修改成了 SIGNAL // 而在这时，我们发起了中断，又将这个 waitStatus 修改成 CANCELLED // 它的闹钟就莫得了 // 所以在当前节点在出队之前，要负责唤醒后继节点 int ws; // pred 不是头节点，thread 不为 null // waitStatus 为 SIGNAL 或者是小于等于 0 但是被我们成功的设置成 SIGNAL // 保证了 pred 确实是一个正在正常等待锁的线程，并且它是 SIGNAL 的 if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); // 把 pred 的后继改为新加入的那个 &#125; else &#123; // 如果不满足，直接唤醒 node 的 next，即新加入的节点 unparkSuccessor(node); &#125; node.next = node; // help GC &#125;&#125; tryLock无论是公平还是非公平，tryLock 都是实现了非公平的尝试 仅仅是用于检查锁在当前调用的时候是不是可获得的 123public boolean tryLock() &#123; return sync.nonfairTryAcquire(1);&#125; 带超时的 tryLock1234public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout));&#125; 看 AQS 的独占式超时获取 unlock123public void unlock() &#123; sync.release(1);&#125; newCondition123public Condition newCondition() &#123; return sync.newCondition();&#125; 直接 new 一个 AQS 的 ConditionObject： 123final ConditionObject newCondition() &#123; return new ConditionObject();&#125; 参考文章","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://kebabshellgithub.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"锁","slug":"锁","permalink":"https://kebabshellgithub.github.io/tags/%E9%94%81/"}]},{"title":"AQS","slug":"AQS","date":"2020-12-15T23:13:44.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/15/AQS/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/15/AQS/","excerpt":"","text":"要点 独占式 对获取过程的总结 独占式释放 共享式 doReleaseShared 独占式超时 独占式超时获取 简述队列同步器 AbstractQueueSynchronizer 是用来构建锁或者其他同步组件的基础框架。 它使用了 state 表示同步状态，volatile 修饰 1234/** * The synchronization state. */private volatile int state; 通过内置的 FIFO 双向队列 来放还没获取到锁的线程( 节点 )，由 [内部类 Node](#内部类 Node) 组成 主要的使用方式是继承。子类继承 AQS 并实现抽象方法来管理同步状态。同步状态的管理需要同步器提供的三个方法：getState()、setState(int newState)、compareAndSetState(int expect, int update)。这些方法能够保证状态的改变是安全的。 继承同步器需要重写指定的方法，然后同步器有固定的模板方法，这些模板方法会调用重写的方法，实现同步 AQS 可以支持独占式获取同步状态，也可以共享式获取。以实现不同类型的同步组件：ReentrantLock( 可重入锁、独占锁 )、ReentrantReadWriteLock( 可重入读写锁、共享锁 )、CountDownLatch … AQS 继承了 AbstractOwnableSynchronizer ，能得知是哪个线程持有锁： 1234/** * The current owner of exclusive mode synchronization. */private transient Thread exclusiveOwnerThread; 内部类 Node123456789101112131415// 此节点所属线程volatile Thread thread;// 此节点前驱volatile Node prev;// 后驱volatile Node next;// 此节点为共享模式static final Node SHARED = new Node();// 此节点为独占模式static final Node EXCLUSIVE = null;// new Node() 和 null 只是用来区分而已，new Node() 并不会串联节点// 用于 Condition 和 共享式Node nextWaiter; Node 状态Node 作为队列的节点，有下面的四种状态，由 waitStatus 来决定( 默认为 0 ) 123456789101112131415// 节点取消、放弃在同步队列中竞争static final int CANCELLED = 1;// 此节点的后继节点的线程处于等待状态// 如果当前节点释放同步状态，则会通知后继节点，使得后继节点的线程能够尝试获取状态// 一般是新加入的节点给前一个节点设置 SIGNAL（新加入的节点，即队列的尾节点，状态为 0）// 如果当前节点为 SIGNAL，表示它的后继节点已经挂起，或者即将被挂起，因此如果一个节点是 SIGNAL// 在释放时，还要有一个额外的操作：唤醒它的后继节点static final int SIGNAL = -1;// 该节点当前在条件等待队列中( 这是 Condition 的东西了 ) static final int CONDITION = -2;// 表示下一次共享式同步状态获取将会无条件传播下去，大量线程在 doReleaseShared// 在 doReleaseShared 中设置static final int PROPAGATE = -3;volatile int waitStatus; 理解 SIGNAL 如果当前节点为 SIGNAL，表示它的后继节点已经挂起，或者即将被挂起，因此如果一个节点是 SIGNAL，在释放时，还要有一个额外的操作：唤醒它的后继节点 一般是新加入的节点给前一个节点设置 SIGNAL，而新加入的节点，即队列的尾节点，状态为 0 而当新加入的节点要挂起( park、BLOCKED )时，要看前驱是不是 SIGNAL，要设置它，相当于让前驱给自己订了一个闹钟，如果前驱释放，让它记得叫醒自己 同步队列当前线程获取同步状态失败时，AQS 会将当前线程以及等待状态等信息构成一个 Node 节点，并加入同步队列尾部，同时阻塞当前线程。当头节点释放状态时，会把后续节点唤醒，再次尝试获取同步状态 同步器提供了基于 CAS 的设置尾节点的方法：compareAndSetTail(Node expect, Node update) 首节点的线程释放同步状态时，会唤醒后继结点，后继结点获取同步状态成功时会将自己设置为首节点 而队列的首节点的 thread 变量是 null，不代表任何线程！！！ 因为 exclusiveOwnerThread 已经记录了，也可以认为是当前持有锁的线程，不参与排队，因为它已经获得了同步状态了，方便 gc 12345private void setHead(Node node) &#123; head = node; node.thread = null; node.prev = null;&#125; 队列的初始化是延时的，发生在 enq 方法 独占式状态获取与释放获取acquire使用 acquire 方法，且对中断不敏感( 线程获取状态失败进入队列，线程中断，线程不会从队列移除 ) 12345678public final void acquire(int arg) &#123; // tryAcqure 获取同步状态，失败就加入同步队列尾部 if (!tryAcquire(arg) &amp;&amp; // EXCLUSIVE: 独占式，意味着 nextWaiter 就为 null 了 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // 因为不响应中断，所以在全部搞完，出去之前，再让线程自身中断( 线程自己判断 ) selfInterrupt();&#125; tryAcquire首先使用 tryAcqure( 由继承 AQS 的子类实现 ) 获取同步状态 tryAcqure 的作用简单来说就是把同步状态 state 从 0 修改为 非 0 addWaiter如果获取锁失败，就构造 Node 节点，并使用 addWaiter 尝试加入队列尾部 成功就返回 不成功就 enq 死循环继续 因为可能多个线程尝试 CAS 设置尾节点，如果被其他线程抢先，CAS 就失败了，就得进入 enq 重新拿到尾节点，重新 CAS 设置尾节点 enq 的作用除了 死循环 + CAS 设置尾节点，还有初始化队列 12345678910111213141516171819private Node addWaiter(Node mode) &#123; // new 一个 Node 节点，传入的是 EXCLUSIVE // 构造里面的 nextWaiter 被设置为 null，可知每个独占式的节点的 nextWaiter 一定为 null Node node = new Node(Thread.currentThread(), mode); // 尾节点不为空 if (pred != null) &#123; // 设置新的 Node 节点的前驱节点为之前的尾节点 node.prev = pred; // CAS 设置新的 Node 节点为尾结点，成功就返回，不成功就 enq 死循环保证能设置 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // “死循环” 保证节点能顺利添加到尾部( CAS )，enq 也用于初始化 // 尾节点如果为空，即还没初始化 -&gt; enq enq(node); return node;&#125; enq使用 enq + 死循环 保证节点能顺利添加到尾部( CAS ) 如果队列为空，还要初始化队列 这里没有用新传进来的 Node，而是 new 了一个空的 Node！！！！然后重新循环 尾节点的设置不是原子操作，可能导致“尾分叉” 1234567891011121314151617private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; // 队列空，初始化 if (t == null) &#123; // Must initialize // 设置一个空的 Node，head 和 tail 指向他，下一个循环再添加节点 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; // 尾节点的设置不是原子操作，可能导致“尾分叉” node.prev = t; // 1 if (compareAndSetTail(t, node)) &#123; // 2 t.next = node; // 3 return t; &#125; &#125; &#125;&#125; 尾分叉这里的三步并不是一个原子操作，第一步很容易成功；而第二步由于是一个 CAS 操作，在并发条件下有可能失败，第三步只有在第二步成功的条件下才执行 这里的 CAS 保证了同一时刻只有一个节点能成为尾节点，其他节点将失败，失败后将回到 for 循环中继续重试 所以，当有大量的线程在同时入队的时候，同一时刻，只有一个线程能完整地完成这三步，而其他线程只能完成第一步，于是就出现了尾分叉： 而在下一轮的循环中，它们的 prev 属性会重新指向新的尾节点，继续尝试新的 CAS 操作，最终，所有节点都会通过自旋不断的尝试入队，直到成功为止 acquireQueued把新的 Node 设置为尾节点后，acquireQueued 会让节点一直 自旋 等待获取同步( 等待是因为前驱不是头节点的情况，等待是不会尝试获取同步状态的 )( 并会 阻塞( BLOCKED ) 节点的线程！！！ ) BLOCKED 是指线程正在等待获取锁 只有前驱节点是 头节点 才能尝试获取同步状态 成功当然好，荣升头节点 失败了说明锁在头节点那里，人家还没用完呢，那就只能继续 BLOCKED ( park )，设置前驱为 SIGNAL ( 如果前驱不是的话 )，等待锁释放( shouldParkAfterFailedAcquire 和 parkAndCheckInterrupt ) shouldParkAfterFailedAcquire 是使用 CAS 将前驱节点状态设置成 SIGNAL(-1) CAS 设置失败则说明 shouldParkAfterFailedAcquire 返回 false，然后会在 acquireQueued 中死循环继续重试 直到 CAS 设置 SIGNAL 成功 shouldParkAfterFailedAcquire 返回 true 时，才会执行 parkAndCheckInterrupt 来阻塞当前节点( 让前驱设置了闹钟，它会在释放的时候唤醒自己 ) 123456789101112131415161718192021222324252627final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); // 只有前驱是头节点才能尝试获取同步状态 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 获取同步状态成功 // 设置头节点 // 这里都不需要 CAS，因为已经拿到锁了 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 如果获取同步状态失败，会将前驱节点设置为 SIGNAL 状态，然后阻塞 // shouldParkAfterFailedAcquire 返回 true 时才会执行 parkAndCheckInterrupt if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 12345678910111213141516171819202122232425private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; // 前驱节点状态 int ws = pred.waitStatus; if (ws == Node.SIGNAL) // -1 /* * 前驱状态是 SIGNAL 了，就返回 true，执行 parkAndCheckInterrupt 来阻塞，等头节点唤醒 */ return true; // 大于 0 只能是 CANCELLED 了，即这个节点已经取消竞争了，跳过它，往前 if (ws &gt; 0) &#123; // 往前拿节点，直到节点的小于等于 0 do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); // 拿到最近的有效的前驱节点，使之后驱为本节点 node，跳出到 acquireQueued 重新循环 pred.next = node; &#125; else &#123; /* * 这时候前驱的 watiStatus 肯定是 0 或者 PROPAGATE * 要设置前驱为 SIGNAL，给自己设闹钟！！让它释放的时候记得唤醒自己 */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 12345private final boolean parkAndCheckInterrupt() &#123; // 挂起、阻塞自己 LockSupport.park(this); return Thread.interrupted();&#125; 对获取过程的总结 调用 acquire，接着会调用 tryAcquire 尝试获取锁，即设置 state 为 1 如果失败，就使用 addWaiter 构造新的 Node 节点 如果是第一次，则直接调用 enq 初始化队列，即设置一个属性为空的头节点，接着在 enq 里面继续下一个循环来 CAS 设置尾节点为之前构造的 Node 节点 如果不是第一次，尝试 CAS 插入同步队列尾部，失败也到 enq 死循环 + CAS 直到成功设置尾节点，addWaiter 结束，回到外层的 acquireQueued acquireQueued 会一直自旋，如果前驱节点为头节点，就尝试获取锁( tryAcquire ) 如果成功拿到锁，就要把自己设置为头节点，这时候就不需要 CAS 了，因为已经拿到锁了 如果失败，就进入 shouldParkAfterFailedAcquire 看看前驱节点是不是 SIGNAL 是就返回 true，再执行 parkAndCheckInterrupt 继续阻塞自己，返回 acquireQueued 如果不是，就尝试 CAS 设置前驱节点为 SIGNAL，但成功是返回 false，返回到 acquireQueued 继续循环 如果不是 SIGNAL，而且等于 0，就意味着是 CANCELLED，即前驱节点是放弃竞争的，就往前找前驱节点的“替代者”，找到了返回到 acquireQueued 继续循环 独占式释放使用 release 释放同步状态，会唤醒它的后续节点 tryRelease 释放同步状态 使用 unparkSuccessor 唤醒后续节点( 一个 )，会使用 LockSupport 来唤醒( unpark 方法 ) 1234567891011public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; // 拿到头节点，判空和看看状态是不是头 if (h != null &amp;&amp; h.waitStatus != 0) // 释放 unparkSuccessor(h); return true; &#125; return false;&#125; 12345678910111213141516171819private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; // 设置 waitStatus 为 0 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; // 后继节点不存在，或者后继节点取消了排队 if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 从后往前遍历 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; // 这里使用 LockSupport 来唤醒后续节点( 只是一个 )，让它尝试获取同步状态 if (s != null) LockSupport.unpark(s.thread);&#125; if (s &#x3D;&#x3D; null || s.waitStatus &gt; 0) 代表： 后继节点不存在，或者后继节点取消了排队( CANCELLED ) 之所以从后往前遍历是因为之前提到的“尾分叉” 我们是处于多线程并发的条件下的，如果一个节点的 next 属性为 null，并不能保证它就是尾节点( 可能是因为新加的尾节点还没来得及执行 pred.next = node )，但是一个节点如果能入队，则它的 prev 属性一定是有值的，所以反向查找一定是最精确的 共享式状态获取与释放以读写为例，同一时刻能多个读，不能写；同一时刻有一个写，不能读 共享状态下，获取与释放都会唤醒后续节点！！！ 获取使用 acquireShared 可以共享式获取同步状态 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; tryAcquireShared 获取成功返回值 &gt;&#x3D; 0 尝试失败，在 doAcquireShared 中，自旋，且前驱为头节点，尝试获取同步状态，阻塞啥的，跟独占式几乎一模一样 不同的是： tryAcquireShared 获取成功后，就能唤醒后继节点开始获取同步状态了，而不是像独占式那样，需要头节点释放，才能唤醒后续节点 头节点的设置问题：setHeadAndPropagate 12345678910111213141516171819202122232425262728293031private void doAcquireShared(int arg) &#123; // 节点以 SHARED 共享状态放入同步队列 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); // 只有前驱节点是头节点，才能尝试获取同步状态 if (p == head) &#123; int r = tryAcquireShared(arg); // 获取成功，设置头节点为自己，balabala...然后退出 if (r &gt;= 0) &#123; // 注意！！！ setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; setHeadAndPropagate在 setHeadAndPropagate 中，除了 setHead 之外，还有一个 doReleaseShared 来唤醒后续节点 这里唤醒了，等下头节点释放又唤醒一次 等等在 释放 那里再看 1234567891011private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) // 唤醒后续节点 doReleaseShared(); &#125;&#125; 12345private void setHead(Node node) &#123; head = node; node.thread = null; node.prev = null;&#125; 释放使用 releaseShared 释放同步状态 123456789public final boolean releaseShared(int arg) &#123; // tryReleaseShared 释放 if (tryReleaseShared(arg)) &#123; // 释放成功的话，就 doReleaseShared 唤醒后续节点 doReleaseShared(); return true; &#125; return false;&#125; 它和独占式的区别在于 tryReleaseShared 必须确保同步状态线程安全释放，一般是通过 循环 + CAS 保证的，因为释放同步状态的线程可能有多个 doReleaseShared上面说的，是说会有多个线程调用 doReleaseShared，而且每个线程会有两次调用 一次是成为头节点时调用 一次是头节点释放时调用 1234567891011121314151617181920212223242526272829private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; // SIGNAL 说明后继节点需要释放，尝试设为 0 if (ws == Node.SIGNAL) &#123; // CAS // 保证大量的 doReleaseShared 方法在同时执行时 // 只有一个线程 unpark 成功 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; // 为 0 的情况可能是上面的情况，但是上面的情况不会进入这个条件了 // 那为 0 只能意味着这是同步队列的最后一个节点成为了头节点 // 因为进入队列的新节点的状态是 0 // 而 compareAndSetWaitStatus(h, 0, Node.PROPAGATE) 失败的情况是 // 执行到这儿的瞬间，有新节点进入 // 新节点进入队列时要把前驱节点设为 SIGNAL，这时候本节点就不是 0 了 // 就会 continue，继续循环 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 多个线程意味着头节点会变，而循环退出的条件是： 12if (h == head) // loop if head changed break; 意思就是：如果头节点仍然是同一个节点，就退出，否则继续循环 为什么这样做？ 因为是多个线程，线程 1 成为头节点，会调用 doReleaseShared1，唤醒线程 2 线程 2成功成为头节点，接着又调用 doReleaseShared2，唤醒线程 3 此时 doReleaseShared1 还没结束，但是头节点已经变了，所以继续循环 循环开始，拿到头节点：Node h &#x3D; head 这时候线程 3成功成为头节点，doReleaseShared3……. 然后就有大量线程在执行 doReleaseShared 注意现在是共享式，就是要效率，就是要共享 独占式超时获取在指定时间内获取同步状态，能响应中断 如果 nanosTimeout 小于等于 spinForTimeoutThreshold ( 1000 纳秒 )，就快速进入自旋。 独占式超时获取和之前的独占式获取( acquire )很像，acquire 在未获取的时候，会使当前线程一直处于等待状态，而 doAcquireNanos 会使当前线程等待 nanosTimeout 纳秒，如果线程还没有获取到同步状态，就从等待逻辑中自动返回 1234567public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout);&#125; 12345678910111213141516171819202122232425262728293031private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; // 多了时间检测 nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 参考文章","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://kebabshellgithub.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"Synchronized","slug":"Synchronized","date":"2020-12-15T23:09:42.000Z","updated":"2023-04-06T11:06:55.030Z","comments":true,"path":"2020/12/15/Synchronized/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/15/Synchronized/","excerpt":"","text":"原理JVM 基于进入和退出 Monitor 对象来实现方法同步和代码块同步的 代码块同步是 monitorenter 和 monitorexit，方法的同步是依靠ACC_SYNCHRONIZED实现。方法的同步也可以通过前面的两个指令实现。 无论哪种，都是获取一个对象的 Monitor( 监视器 )，这个获取过程是排他的、独占的 Synchronized 用的锁是与 Java 对象头息息相关的 Mark Word 中存储的数据会随着锁标志位的变化而变化 锁升级JDK 1.6 后，锁有4种状态，级别从低到高：无锁、偏向锁、轻量级锁、重量级锁 锁只能升级，不能降级 偏向锁 偏向锁的获取就是登记自己的 ID，已经登记的就不用再登记了 大多数情况下，锁经常会被同一线程获取，所以为了让获取锁的代价更低，引入了偏向锁 当一个线程访问同步块并获取锁时，会在 对象头 和 栈桢 ( 在虚拟机栈 VM Stack 里 )中的锁记录( Lock Record )存入自身的线程 ID，下次访问就不用 CAS 来加锁解锁了。 线程来，判断 如果是本线程 ID，就执行代码。 如果来的线程和记录的线程 ID 不一样 可能你是第一次来，也可能锁被别人获取了。 接着看 Mark Word 里面的偏向锁标识是不是 1 如果不是就 CAS 竞争锁( 就是第一次来 ) 如果标识是 1，就是另外的线程来竞争( 此时持有锁的线程可能活着，也可能没有 )，就尝试 CAS 将对象头的线程 ID改为自己的( 这时候就触发原来线程偏向锁的撤销 ) 撤销需要等到全局安全点( 在这个时间点上没有正在执行的字节码 )。会挂起原来的线程，看看线程还活着不 如果不处于活动状态，设置偏向锁标识 0，设置为无锁 01，按正常获取偏向锁。CAS 替换线程 ID。( 重新偏向 ) 如果还活着，偏向锁 升级 成轻量级锁，新来的线程自旋获取锁。 锁撤销的开销花费还是挺大的： 在一个安全点停止拥有锁的线程。 遍历线程栈，如果存在锁记录的话，需要修复锁记录和 Markword，使其变成无锁状态。 唤醒当前线程，将当前锁升级成轻量级锁。 所以如果确定是两个及以上线程竞争，就通过 JVM 参数默认关闭偏向锁：-XX:UseBiasedLocking=false 轻量级锁加锁JVM 会先在当前线程的栈桢中创建用于存放锁记录( Lock Record )的空间，并将对象头中的 Mark Word 复制到锁记录，官方称为 Displaced Mark Word( 用于轻量级锁解锁 )，然后将锁记录的 Owner 指针指向锁对象 然后线程尝试 CAS 把对象头的 Mark Word 替换为指向锁记录的指针 如果成功，当前线程顺利拿锁 如果失败，表示还有其他线程在竞争，当前线程就 自旋 + CAS 获取锁 解锁所谓自旋，就是指当有另外一个线程来竞争锁时，这个线程会在原地循环等待，而不是把该线程给阻塞 但自旋也得有限度，所以默认自旋的次数为10，超过就自旋失败，锁就会升级为 重量级锁 除了自旋锁，还有自适应自旋锁 所谓自适应自旋锁就是线程空循环等待的自旋次数并非是固定的，而是会动态着根据实际情况来改变自旋等待的次数 假如一个线程1刚刚成功获得一个锁，当它把锁释放了之后，线程 2 获得该锁，并且线程 2 在运行的过程中，此时线程 1 又想来获得该锁了，但线程 2 还没有释放该锁，所以线程 1 只能自旋等待，但是虚拟机认为，由于线程 1 刚刚获得过该锁，那么虚拟机觉得线程 1 这次自旋也是很有可能能够再次成功获得该锁的，所以会延长线程 1 自旋的次数 另外，如果对于某一个锁，一个线程自旋之后，很少成功获得该锁，那么以后这个线程要获取该锁时，是有可能直接忽略掉自旋过程，直接升级为重量级锁的，以免空循环等待浪费资源 重量级锁也叫互斥锁、悲观锁 Mutex，懂的都懂 加锁：锁方法、锁代码块和锁对象 参考： 线程安全(中)–彻底搞懂synchronized(从偏向锁到重量级锁) 《Java并发编程的艺术》 在JVM中，对象在内存中分为三块区域： 对象头( Header ) **Mark Word( 标记字段 )**：默认存储对象的 HashCode，分代年龄和锁标志位信息，包括 GC 分代年龄、哈希码、锁状态、线程持有的锁等数据，这部分的数据长度在 32 位和 64 位虚拟机中分别为 32 位和 64 位。它会根据对象的状态复用自己的存储空间，也就是说在运行期间 Mark Word 里存储的数据会随着锁标志位的变化而变化 对象在不同的状态下，Mark Word 会存储不同的内容 类型指针：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例 实例数据( Instance Data ) 存放类的数据信息、父类的信息 对齐填充( Padding ) 由于虚拟机要求对象起始地址必须是8字节的整数倍，填充数据不是必须存在的，仅仅是为了占位置 一个空对象占 8 个字节，是因为对齐填充的关系，不到 8 个字节对其填充会帮我们自动补齐","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://kebabshellgithub.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"集合的迭代器","slug":"集合的迭代器","date":"2020-12-13T23:23:18.000Z","updated":"2023-04-06T11:06:55.042Z","comments":true,"path":"2020/12/13/集合的迭代器/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/13/%E9%9B%86%E5%90%88%E7%9A%84%E8%BF%AD%E4%BB%A3%E5%99%A8/","excerpt":"","text":"迭代器新建文件夹 手动滑稽","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"摆烂了","slug":"摆烂了","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%86%E7%83%82%E4%BA%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"集合","slug":"集合","permalink":"https://kebabshellgithub.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"ArrayList","slug":"ArrayList","date":"2020-12-13T20:35:59.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/13/ArrayList/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/13/ArrayList/","excerpt":"","text":"变量 elementData：用来存放数据 elementData 是用 transient 修饰的 ArrayList 实现了 Serializable 接口，这意味着 ArrayList 是可以被序列化的，用 transient 修饰 elementData 意味着不希望 elementData 数组被序列化 因为序列化 ArrayList 的时候，elementData 未必是满的 比方说 elementData 有 10 的大小，但是只用了其中的 3 个，那么没有必要序列化整个 elementData ，因此 ArrayList 中重写了 writeObject 方法 提高了序列化的效率，减少了无意义的序列化 减少了序列化后文件大小 初始化 &amp; 扩容ArrayList 的初始化是在插入的时候，跟 HashMap 一样 扩容也在插入的时候判断 扩容后的数组大小是 newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1) 初始化发生在 calculateCapacity 里面( 这里是针对没指定数组大小的初始化，如果给了指定的数组大小，初始化就在构造里 ) 扩容在 grow 方法里面 对于没有指定数组大小的构造，直接给一个空数组 1234private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; 对于有指定大小的，直接在构造里初始化 123456789public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; // throw... &#125;&#125; 精华都在注释里( 下面的 初始化 是针对没指定数组大小的情况！！！ ) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public boolean add(E e) &#123; // 实参是 假如添加成功后的 真·元素个数 ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;// 注意 minCapacity 是 假如添加成功后的 真·元素个数private void ensureCapacityInternal(int minCapacity) &#123; // 先进入 calculateCapacity 确定是不是第一次来，要不要初始化 // 然后通过 ensureExplicitCapacity 再看看需不需要扩容 ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125;// 先看 calculateCapacity// 初始化// 确定是不是第一次来，要不要初始化private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; // 如果 elementData 是空的，就意味着要初始化，即返回默认一开始要开辟的数组大小 // 默认是 10 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; // 如果 elementData 不为空，就知道你来过了，不需要初始化 return minCapacity;&#125;// 这里判断需不需要扩容private void ensureExplicitCapacity(int minCapacity) &#123; // 操作数 + 1 modCount++; // overflow-conscious code // 如果新添加元素后的元素个数 &gt; 原来数组的大小，就需要扩容了 if (minCapacity - elementData.length &gt; 0) // 扩容 grow(minCapacity); // 要是没超过数组大小，就不需要扩容&#125;// 扩容private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; // 扩容是加上原数组的一半 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 如果加了一半还是比假设成功添加元素后的元素个数小，那就直接把按传进来的来 // ( 这种情况发生在 add 了另一个集合，两个长度和都比原来加了一半还大 ) if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 无论是哪种情况，如果都超过了 MAX_ARRAY_SIZE( Integer.MAX_VALUE - 8 ) // 那就直接 Integer.MAX_VALUE if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: // 把原数据复制到新数组 elementData = Arrays.copyOf(elementData, newCapacity);&#125;// 如果都超过了 MAX_ARRAY_SIZE( Integer.MAX_VALUE - 8 )，那就直接Integer.MAX_VALUEprivate static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125;// 复制到新数组public static &lt;T&gt; T[] copyOf(T[] original, int newLength) &#123; return (T[]) copyOf(original, newLength, original.getClass());&#125;// 复制到新数组// 再下去就 native 了，不看了。。。public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) &#123; T[] copy = ((Object)newType == (Object)Object[].class) ? (T[]) new Object[newLength] : (T[]) Array.newInstance(newType.getComponentType(), newLength); System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy;&#125; 遍历迭代器最强 对于集合的迭代器，请看 集合的迭代器 子集SubList 是 ArrayList 的子类 其实也就那样，大多数用的还是 ArrayList 的接口 1234public List&lt;E&gt; subList(int fromIndex, int toIndex) &#123; subListRangeCheck(fromIndex, toIndex, size); return new SubList(this, 0, fromIndex, toIndex);&#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"集合","slug":"集合","permalink":"https://kebabshellgithub.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"LinkedList","slug":"LinkedList","date":"2020-12-13T16:04:01.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/13/LinkedList/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/13/LinkedList/","excerpt":"","text":"内部类 Node 1234567891011private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; 意味着是双向链表，每个节点都记录着前后节点 基本操作加默认添加到末尾，add(E e) 调用 linkLast(E e) 相对于的，就会有 addFirst(E e)、addLast(E e)，就会有 linkFirst(E e) 123456789101112131415161718192021222324252627/** * Appends the specified element to the end of this list. * * &lt;p&gt;This method is equivalent to &#123;@link #addLast&#125;. * * @param e element to be appended to this list * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123; linkLast(e); return true;&#125;/** * Links e as last element. */void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125;// 等等 还有一个 add(int index, E element) 在指定位置插入 先判断下标有没有越界：checkPositionIndex(index)，越界就抛异常了 12345678910111213141516171819public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index));&#125;private void checkPositionIndex(int index) &#123; // 不合法 if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;// Tells if the argument is the index of a valid position for an iterator or an add operation.private boolean isPositionIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt;= size;&#125; 会判断是不是插入末尾，要是插中间就会调 void linkBefore(E e, Node&lt;E&gt; succ)，而这个 Node&lt;E&gt; node(int index) 方法就是返回了这个下标处本来的节点 这个 Node&lt;E&gt; node(int index) 方法返回方式是 看下标在左半部分还是右半部分，来确定是从左边遍历还是右边遍历 最后再调 void linkBefore(E e, Node&lt;E&gt; succ) 方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public void add(int index, E element) &#123; // 判断下标有没有越界 checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index));&#125;/** * Returns the (non-null) Node at the specified element index. */Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); // 看下标在左半部分还是右半部分，来确定是从左边遍历还是右边遍历 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125;/** * Inserts element e before non-null Node succ. */void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; // 这个 succ 就是原本下标的元素 // 前 final Node&lt;E&gt; pred = succ.prev; // 新插入的 final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++;&#125; 清空对于清空 clear()，置空是为了方便 GC 1234567891011121314151617181920/** * Removes all of the elements from this list. * The list will be empty after this call returns. */public void clear() &#123; // Clearing all of the links between nodes is &quot;unnecessary&quot;, but: // - helps a generational GC if the discarded nodes inhabit // more than one generation // - is sure to free memory even if there is a reachable Iterator for (Node&lt;E&gt; x = first; x != null; ) &#123; Node&lt;E&gt; next = x.next; x.item = null; x.next = null; x.prev = null; x = next; &#125; first = last = null; size = 0; modCount++;&#125; 找int indexOf(Object o) 返回此列表中指定元素首次出现的索引 会分成是不是 null 两种情况 1234567891011121314151617public int indexOf(Object o) &#123; int index = 0; if (o == null) &#123; // 是 null for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) return index; index++; &#125; &#125; else &#123; // 不是 null for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) return index; index++; &#125; &#125; return -1;&#125; 删最基本的方法就是 E unlinkFirst(Node&lt;E&gt; f) 和 E unlinkLast(Node&lt;E&gt; l)","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"集合","slug":"集合","permalink":"https://kebabshellgithub.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"RocketMQ","slug":"RocketMQ","date":"2020-12-12T15:04:08.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/12/RocketMQ/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/12/RocketMQ/","excerpt":"","text":"参考 参考2 参考3 消息队列有两种模型：队列模型（RabbitMQ）和发布&#x2F;订阅模型（RocketMQ、Kafka） 异步、削峰、解耦 解耦： 你下单了，你就把你支付成功的消息告诉别的系统，他们收到了去处理就好了，你只用走完自己的流程，把自己的消息发出去，那后面要接入什么系统简单，直接订阅你发送的支付成功消息，你支付成功了我监听就好了。 问题： 数据一致性（使用分布式事务）、高可用、消息重复消费（幂等（强校验、弱校验））、消息丢失、消息的顺序消费（一个topic下有多个队列，为了保证发送有序，RocketMQ提供了MessageQueueSelector队列选择机制） 分布式事务： 2pc（两段式提交） 3pc（三段式提交） TCC（Try、Confirm、Cancel） 最大努力通知 XA 本地消息表（ebay研发出的） 半消息&#x2F;最终一致性（RocketMQ） 业务主动方本地事务提交失败，业务被动方不会收到消息的投递。 只要业务主动方本地事务执行成功，那么消息服务一定会投递消息给下游的业务被动方，并最终保证业务被动方一定能成功消费该消息（消费成功或失败，即最终一定会有一个最终态）。 为了提高并发度，往往发布&#x2F;订阅模型还会引入队列或者分区的概念。即消息是发往一个主题下的某个队列或者某个分区中。RocketMQ中叫队列，Kafka叫分区，本质一样，例如某个主题下有 5 个队列，那么这个主题的并发度就提高为 5 ，同时可以有 5 个消费者并行消费该主题的消息。一般可以采用轮询或者 key hash 取余等策略来将同一个主题的消息分配到不同的队列中。 与之对应的消费者一般都有组的概念 Consumer Group, 即消费者都是属于某个消费组的。一条消息会发往多个订阅了这个主题的消费组。 假设现在有两个消费组分别是Group 1 和 Group 2，它们都订阅了Topic-a。此时有一条消息发往Topic-a，那么这两个消费组都能接收到这条消息。 然后这条消息实际是写入Topic某个队列中，消费组中的某个消费者对应消费一个队列的消息。 在物理上除了副本拷贝之外，一条消息在Broker中只会有一份，每个消费组会有自己的offset即消费点位来标识消费到的位置。在消费点位之前的消息表明已经消费过了。当然这个offset是队列级别的。每个消费组都会维护订阅的Topic下的每个队列的offset 正文开始发布&#x2F;订阅 基本组件：Producer 消息发送者、Broker 消息服务器（存储消息）、Consumer 消息消费、NameServer 路由发现 底层的通信和连接都是基于 Netty 实现 的 路由中心 NameServer Producer 发送某一主题的消息到 Broker，Broker 负责该消息的持久化存储，Consumer 订阅感兴趣的主题，Broker 根据订阅信息（路由信息）将消息推送到 Consumer（PUSH）或者 Consumer 主动向 Broker 拉取消息（PULL），从而实现 Producer 与 Consumer 解耦。 为了避免 Broker 的单点故障导致的整个系统瘫痪，通常会部署多台 Broker 共同承担消息的存储。那 Producer 如何知道消息要发往哪台 Broker 呢？如果某一台 Broker 宕机了，那么 Producer 如何在不重启服务的情况下感知呢？ 这就是 NameServer 的作用了 由图可知，多个 NameServer 之间互不通信，即某一时刻的数据并不会完全一样，但不会对消息发送造成影响，简单高效 Broker 在启动时向所有 NameServer 注册，Producer 在发送消息之前先从 NameServer 获取 Broker 地址列表，然后根据负载算法从列表中选择一台 Broker 进行消息发送。NameServer 与每台 Broker 服务器保持长连接，并间隔 30 s 检测 Broker 是否存活，如果检测到 Broker 宕机，则从路由注册表中将其移除。但是路由变化不会马上通知 Producer，这是为了降低 NameServer 的复杂性，在消息发送端提供容错机制来保证消息发送的高可用性。 如果代码中使用了线程池，一种优雅停机的方式就是注册一个 JVM 钩子函数，在 JVM 进程关闭之前，先将线程池关闭，及时释放资源。 路由元消息NameServer 由 RouteInfoManager 实现，通过 HashMap 存储元消息 topicQueueTable：Topic 消息队列路由信息，消息发送时根据路由表进行负载均衡 HashMap&lt;String &#x2F;* topic *&#x2F;, List&lt;QueueData&gt;&gt; topic：List&lt;QueueData&gt; brokerAddrTable：Broker 基础信息，包含 brokerName、所属集群名称、主备 Broker 地址 HashMap&lt;String &#x2F;* brokerName *&#x2F;, BrokerData&gt; brokerName：BrokerData clusterAddrTable：Broker 集群信息，存储集群中所有 Broker 名称 HashMap&lt;String &#x2F;* clusterName *&#x2F;, Set&lt;String &#x2F;* brokerName *&#x2F;&gt;&gt; clusterName：Set&lt;String &#x2F;* brokerName *&#x2F;&gt; brokerLiveTable：Broker 状态信息，NameServer 每次收到心跳包时会替换该信息 HashMap&lt;String &#x2F;* brokerAddr *&#x2F;, BrokerLiveinfo&gt; brokerAddr：BrokerLiveinfo filterServerTable：Broker上的 FilterServer 列表，用于类模式消息过滤 HashMap&lt;String &#x2F;* brokerAddr *&#x2F;, List&lt;String&gt; &#x2F;* Filter Server *&#x2F;&gt; brokerAddr：List&lt;String&gt; &#x2F;* Filter Server *&#x2F; RocketMQ 基于订阅发布机制 一个 Topic 拥有多个消息队列 一个 Broker 为每一个 Topic 默认创建 4 个读队列 4 个写队列 多个 Broker 组成一个集群，BrokerName 由相同的多台 Broker 组成 Master-Slave 架构 brokerId 为 0 代表 Master，大于 0 表示 Slave BrokerLiveInfo 中的 lastUpdateTimestamp 存储上次收到 Broker 心跳包的时间 路由注册通过 Broker 与 NameServer 的心跳功能实现注册 Broker 启动时向集群中所有的 NameServer 发送心跳语句，每隔 30 s 向集群中所有 NameServer 发送心跳包 NameServer 收到 Broker 心跳包时会更新 brokerLiveTable 缓存中 BrokerLiveInfo 的 lastUpdateTimestamp 然后 NameServer 每隔 10 s 扫描 brokerLiveTable，如果连续 120 s 没有收到心跳包，NameServer 将移除该 Broker 的路由信息，同时关闭 Socket 连接 注册需要加读写锁（ReentrantReadWriteLock），防止并发修改 RouteInfoManager 中的路由表 NameServe 与 Broker 保持长连接，Broker 状态存储在 brokerLiveTable 中，NameServer 每收到一个心跳包，将更新 brokerLiveTable 中关于 Broker 的状态信息以及路由表（topicQueueTable、brokerAddrTable、brokerLiveTable、filterServerTable）更新上述路由表使用了 ReentrantReadWriteLock，允许多个消息发送者(Producer）并发读，保证消息发送时的高并发。但同一时刻 NameServer 只处理一个 Broker 心跳包，多个心跳包请求串行执行 路由删除如果 Broker 宕机，NameServer 无法收到心跳包 NameServer 会每隔 10 s 扫描 brokerLiveTable 状态表，如果 BrokerlLive 的 lastUpdateTimestamp 的时间戳距当前时间超过 120s，则认为 Broker 失效，移除该 Broker，关闭与 Broker 连接，并同时更新 topicQueueTable、brokerAddrTable、brokerLiveTable、filterServerTable RocktMQ 有两个触发点来触发路由删除 NameServer 定时扫描 brokerLiveTable 检测上次心跳包与当前系统时间的时间差，如果时间戳大于 120 s，则需要移除该 Broker 信息 Broker 在正常被关闭的情况下，会执行 unregisterBroker 指令 两种方式触发的路由删除，都是从 topicQueueTable、brokerAddrTable、brokerLiveTable、filterServerTable 删除与该 Broker 相关的信息，这两种方式维护路由信息时会抽取公共代码 路由发现RocketMQ 路由发现是非实时的，当 Topic 路由出现变化后，NameServer 不主动推送给客户端，而是由客户端根据主题名定时拉取主题最新的路由 总结 消息Message 类 Message 的基础属性主要包括消息所属主题 topic、消息 Flag（不做处理）、扩展属性、消息体 Message 扩展属性主要包含下面几个 tag：消息 TAG，用于消息过滤（可以看成低级的 topic） keys：Message 索引键，多个用空格隔开，RocketMQ 可以根据这些 key 快速检索到消息 waitStoreMsgOK：消息发送时是否等消息存储完成后再返回 delayTimeLeve：消息延迟级别，用于定时消息或消息重试 这些扩展属性存储在 Message properties 消息发送RocketMQ 发送普通消息有 3 种实现方式：可靠同步发送、可靠异步发送、单向 (Oneway）发送 RocketMQ 支持 3 种消息发送方式 ：同步 sync、异步 async、单向 oneway 同步：发送者向 MQ 执行发送消息 API 时，同步等待，直到到消息服务器返回发送结果 异步：发送者向 MQ 执行发送消息 API 时，指定消息发送成功后的回调函数，然后调用消息发送 API 后，立即返回，消息发送者线程不阻塞，直到运行结束，消息发送成功或失败的回调任务在另一个新的线程中执行 单向：发送者向 MQ 执行发送消息 API 时，直接返回，不等待消息服务器的结果，也不注册回调函数，简单地说，就是只管发，不在乎消息是否成功存储在消息服务器上 生产者消息生产者的代码都在 client 模块中 DefaultMQProducer 默认的消息生产者实现类，它实现 MQAdmin 接口 启动一个 JVM 实例中只存在一个 MQCientManager 实例，维护一个 MQClientlnstance 缓存表（ConcurrentHashMap），也就是一个 clientld 只会创建一个 MQClientinstance clientld 为客户端 IP + instance +（unitname 可选） 如果在一台物理服务器部署两个应用程序，应用程序 clientld 相同，可能造成混乱，所以 如果 instance 为默认值 DEFAULT 的话， RocketMQ 会自动将 instance 设置为进程 ID ，这样避免了不同进程的相互影响，但同 JVM 的不同消费者和不同生产者在启动时获取到的 MQClientlnstane 实例都是同一个。 MQClientlnstance 封装了 RocketMQ 网络处理 API ，是 Producer、Consumer 与 NameServer、Broker 打交道的网络通道 主要流程消息发送流程：验证消息、查找路由、消息发送（包括异常处理）（sendMessage 方法） 默认是同步，默认超时时间为 3s 验证主要是判空、判大小：maxMessageSize &#x3D; 1024 * 1024 * 4（4M） 查找路由。。。 根据路由消息选择消息队列，返回的消息队列按照 broker、序号排序 首先在一次消息发送过程中，可能会多次执行选择消息队列这个方法，lastBrokerName 就是上一次选择的执行发送消息失败的 Broker。第一次执行消息队列选择时，lastBrokerName 为 null 此时直接用 sendWhichQueue 自增再获取值，与当前路由表中消息队列个数取模，返回该位置的 MessageQueue（selectOneMessage Queue() 方法），如果消息发送再失败的话，下次进行消息队列选择时规避上次 MessageQueue 所在的 Broker，否则还是很有可能再次失败。 该算法在一次消息发送过程中能成功规避故障的 Broker，但如果 Broker 宕机，由于路由算法中的消息队列是按 Broker排序的，如果上一次根据路由算法选择的是宕机的 Broker 的第一个队列，那么随后的下次选择的是宕机 Broker 的第二个队列，消息发送很有可能会失败，再次引发重试，带来不必要的性能损耗，那么有什么方法在一次消息发送失败后，暂时将该 Broker 排除在消息队列选择范围外呢？或许有朋友会问，Broker不可用后，路由信息中为什么还会包含该 Broker 的路由信息呢？其实这不难解释：首先，Name Server 检测 Broker 是否可用是有延迟的，最短为一次心跳检测间隔（10s），其次，NameServer 不会检测到 Broker 宕机后马上推送消息给消息生产者，而是消息生产者每隔 30s 更新一次路由信息，所以消息生产者最快感知 Broker 最新的路由信息也需要 30s。如果能引入一种机制，在 Broker 宕机期间，如果一次消息发送失败后，可以将该 Broker 暂时排除在消息队列的选择范围中。-》Borker 故障延迟机制 Borker 故障延迟机制。。。 消息发送DefaultMQProducerImpl#sendKernelImpl 消息消费Consumer支持PUSH和PULL两种消费模式，支持集群消费和广播消息，提供实时的消息订阅机制 Pull：拉取型消费者（Pull Consumer）主动从消息服务器拉取信息，只要批量拉取到消息，用户应用就会启动消费过程，所以 Pull 称为主动消费型。 Push：推送型消费者（Push Consumer）封装了消息的拉取、消费进度和其他的内部维护工作，将消息到达时执行的回调接口留给用户应用程序来实现。所以 Push 称为被动消费类型，但从实现上看还是从消息服务器中拉取消息，不同于 Pull 的是 Push 首先要注册消费监听器，当监听器处触发后才开始消费消息。 问题消费模式有几种 集群消费（CLUSTERING） 一个 ConsumerGroup 中的 Consumer 实例平均分摊消费消息。例如某个 Topic有 9 条消息，其中一个 ConsumerGroup 有 3 个实例（可能是 3 个进程，或者 3 台机器），那么每个实例只消费其中部分，消费完的消息不能被其他实例消费 存在消息重复消费 广播消费（BROADCASTING） 一条消息被多个 Consumer 消费，即使这些 Consumer 属于同一个ConsumerGroup，消息也会被 ConsumerGroup 中的每个 Consumer 都消费一次，广播消费中 ConsumerGroup 概念可以认为在消息划分方面无意义 消息重复消费 发送时消息重复 当一条消息已被成功发送到服务端并完成持久化，此时出现了网络闪断或者客户端宕机，导致服务端对客户端应答失败。 如果此时生产者意识到消息发送失败并尝试再次发送消息，消费者后续会收到两条内容相同并且Message ID也相同的消息 投递时消息重复 消息消费的场景下，消息已投递到消费者并完成业务处理，当客户端给服务端反馈应答的时候网络闪断。为了保证消息至少被消费一次，消息队列RocketMQ版的服务端将在网络恢复后再次尝试投递之前已被处理过的消息，消费者后续会收到两条内容相同并且Message ID也相同的消息 负载均衡时消息重复（包括但不限于网络抖动、Broker重启以及消费者应用重启） 当消息队列RocketMQ版的Broker或客户端重启、扩容或缩容时，会触发Rebalance，此时消费者可能会收到重复消息 通过幂等性来保证不重复 因为Message ID有可能出现冲突（重复）的情况，所以真正安全的幂等处理，不建议以Message ID作为处理依据。最好的方式是以业务唯一标识作为幂等处理的关键依据，而业务的唯一标识可以通过消息Key设置 以支付场景为例，可以将消息的Key设置为订单号，作为幂等处理的依据 消费者收到消息时可以根据消息的Key，即订单号来实现消息幂等 即生产者 setkey，在消费者 getkey 消息顺序消费首先多个 queue 只能保证单个 queue 里的顺序，queue 是典型的 FIFO，天然顺序。多个queue 同时消费是无法绝对保证消息的有序性的 可以使用同一 topic，同一个 queue，发消息的时候一个线程去发送消息，消费的时候 一个线程去消费一个 queue 里的消息 即： 如果是使用 MessageListenerOrderly 则自带此实现 如果是使用 MessageListenerConcurrently，则需要把线程池改为单线程模式 rocketmq怎么保证队列完全顺序消费？ - Jaskey Lam的回答 - 知乎 https://www.zhihu.com/question/30195969/answer/142416274 保证消息不丢失 https://segmentfault.com/a/1190000023661463 Producer 采取 send() 同步发消息，发送结果是同步感知的。发送失败后可以重试，设置重试次数。默认3次 Broker 修改刷盘策略为同步刷盘。默认情况下是异步刷盘的。集群部署 Consumer 完全消费正常后在进行手动ack确认 实现分布式事务 https://www.jianshu.com/p/878fed4e3165 half message 发送prepared消息（half消息，一个意思） 消息成功后执行本地事务 本地事务成功，发送confirm消息 以上是正常成功流程 本地事务失败处理：在发送prepared消息时，会在MQ Server注册监听回调，MQ Server会启定时任务，查询MQ服务器上所有的prepared状态消息，根据消息id，回查接入方producor，看本地事务是否成功，根据本地事务成功与否，确认是发送confirm消息还是callback消息。 最后，mq订阅方都是通过拉的方式，去消费。往MQ Server发送confirm消息就是，根据消息id查找到对应log，把消息状态置为commit，而MQ订阅方就是拉取commit的消息。 消息堆积1、如果可以添加消费者解决，就添加消费者的数据量 2、如果出现了queue，但是消费者多的情况。可以使用准备一个临时的topic，同时创建一些queue，在临时创建一个消费者来把这些消息转移到topic中，让消费者消费","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://kebabshellgithub.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"中间件","slug":"中间件","permalink":"https://kebabshellgithub.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"RabbitMQ","slug":"RabbitMQ","date":"2020-12-12T15:03:53.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/12/RabbitMQ/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/12/RabbitMQ/","excerpt":"","text":"无计划","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"摆烂了","slug":"摆烂了","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%86%E7%83%82%E4%BA%86/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://kebabshellgithub.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"中间件","slug":"中间件","permalink":"https://kebabshellgithub.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"Netty","slug":"Netty","date":"2020-12-12T15:03:28.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/12/Netty/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/12/Netty/","excerpt":"","text":"IOBIO NIO Channeltest EventLooptest EventLoopGrouptest ServerBootstraptest Bootstraptest ChannelHandlertest ChannelPipelinetest ChannelFuturetest","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"摆烂了","slug":"摆烂了","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%86%E7%83%82%E4%BA%86/"}],"tags":[]},{"title":"Kafka","slug":"Kafka","date":"2020-12-12T15:03:15.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/12/Kafka/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/12/Kafka/","excerpt":"","text":"…","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"摆烂了","slug":"摆烂了","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%86%E7%83%82%E4%BA%86/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://kebabshellgithub.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"中间件","slug":"中间件","permalink":"https://kebabshellgithub.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"HashMap","slug":"HashMap","date":"2020-12-09T23:00:46.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/09/HashMap/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/09/HashMap/","excerpt":"","text":"顾名思义，HashMap 就是以 hash 值为 key 的 Map 集合 HashMap 是以 数组 作为容器的 1transient Node&lt;K,V&gt;[] table; Node 是 HashMap 内部实现了 Map.Entry 的类： 1234567891011121314151617static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; // 链表要用到 Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; /** * 其他 balabala 鬼东西 */&#125; HashMap 就是以 hash 值为 key put 方法： 1234public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) 而 putVal 第一个参数就是 hash 值，再看看 hash 方法： 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 可以看到，如果 key 为 null，hash 值为 0；否则： hash 值为 hashCode() 做一次 16 位右位移异或 为什么这样做，是因为 扰动函数，具体请看：知乎传送门 下面提到的 putVal 也有讲 必识的变量biss：最讨厌看这些静态常量了，每个字母都是大写 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/*** 默认的容量* default_initial_capacity* 为什么是 16 ，且为什么推荐 2 的幂次方，看下面的 putVal 方法*/static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 16/*** 最大容量上限* maximun_capacity*/static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;/*** 在构造函数中未指定时使用的负载系数* 负载因子* default_load_factor*/static final float DEFAULT_LOAD_FACTOR = 0.75f;/*** 链表转换为树的阈值，超过这个长度的链表会被转换为红黑树* treeify_threshold*/static final int TREEIFY_THRESHOLD = 8;/*** 当进行resize操作时，小于这个长度的树会被转换为链表* untreeify_threshold*/static final int UNTREEIFY_THRESHOLD = 6;/*** 链表被转换成树形的最小容量，如果没有达到这个容量只会执行 resize 进行扩容* 应该至少为4 * treeify_threshold，以避免大小调整和树化阈值之间发生冲突* 链表超过 8 时，且数组长度大于等于 64，转为红黑树，如果数组长度小于 64，就进行扩容* min_treeify_capacity*/static final int MIN_TREEIFY_CAPACITY = 64;/** * 存储元素的实体数组 */transient Node&lt;K,V&gt;[] table;/** * set 数组，用于迭代元素 */transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;/** * 存放元素的个数，但不等于数组的长度 */transient int size;/** * 修改的次数 * 与快速失败有关 */transient int modCount;/** * 临界值 如果实际大小超过临界值，就会进行扩容 * threshold = 负载因子 * 容量 */int threshold;/** * 加载因子、负载因子 */final float loadFactor; resize resize 方法不仅用来调整大小，还用来进行 初始化 配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // 如果已经初始化 if (oldCap &gt; 0) &#123; // 如果目前 table 的容量大于最大容量的上限，则不会进行扩容，并设置临界值为最大 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 先对容量进行两倍扩容 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // 如果扩大两倍没超过上限，并且原来的容量大于等于16( DEFAULT_INITIAL_CAPACITY 16 ) // 就会对临界值( threshold )也进行两倍扩容 newThr = oldThr &lt;&lt; 1; // double threshold &#125; // 如果没有初始化 else if (oldThr &gt; 0) // initial capacity was placed in threshold // 这个分支针对的指定初始化容量的构造方法 newCap = oldThr; else &#123; // 这个分支是针对默认构造函数的分支，对 newCap 和 newThr 进行赋值 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 临界值 = 容量 * 负载因子 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; // 设置 threshold threshold = newThr; // 新数组 @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 扩容完毕，需要把原来的元素逐一拷贝到新数组中去 if (oldTab != null) &#123; // 遍历原数组的元素 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; //将原来的置为 null，方便垃圾回收器进行回收 oldTab[j] = null; // 如果e.next为null，表示此链表是单节点 // 直接根据 e.hash &amp; (newCap - 1) 得到新的位置进行赋值即可 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) // 如果是红黑树节点，则调用红黑树的方法 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // 链表的复制 // 确定链表里面的元素在数组中的位置 // 元素有些不动，有些动 // 动的不是根据 hash 算法生成新的位置 // 而是采用 原始位置 + 原始容量 得到 新的位置 // 表示一条链表，该链表在新数组中的下标不变 Node&lt;K,V&gt; loHead = null, loTail = null; // 表示一条链表，该链表在新数组中的下标比原来增加 oldCap Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 判断：元素的在数组中的位置是否需要移动 // (e.hash &amp; oldCap)结果为 0 就代表没有变化，否则就是有变化( 看下面 ) // 这些是在新数组中位置不变的节点 if ((e.hash &amp; oldCap) == 0) &#123; // 将符合条件的元素进行新的链表拼接 if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 这些是在新数组中位置 = 原位置 + oldCap 的节点 else &#123; // 和上面同理 if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; // 只要链表元素有下一个元素就循环进行拼接 &#125; while ((e = next) != null); // 添加到新数组 // 位置不变 if (loTail != null) &#123; // 将链表的尾部的 next 置为空 loTail.next = null; // 直接将这个链插到新数组 newTab[j] = loHead; &#125; // 位置 + oldCap if (hiTail != null) &#123; // 将链表的尾部的 next 置为空 hiTail.next = null; // + 原始容量 newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 扩容后链表元素的位置直接判断 (e.hash &amp; oldCap) ，结果为 0 就代表与之前的位置相比 没有变化，否则就是有变化 为什么要这样来决定？ 我们知道( 如果不知道，看下面的 putVal )，(n - 1) &amp; hash 是元素在数组的位置( n 是容量大小 ) 假设 oldCap 为 16，也就是 2^4 n - 1 &#x3D; 15，即 0000 0000 …… 1111 而 &amp; hash 就是取 hash 的低 4 位，设为 xxxx 此时数组扩容是2倍，也就是 2 * oldCap &#x3D; 32 &#x3D; 2^5，&amp; hash 后就是取 hash 的低 5 位 对于低 5 位，对于同一个元素，无非就是 1xxxx 0xxxx 0xxxx 和 没扩容前的低 4 位一样 1xxxx &#x3D; 原来的低 4 位 + oldCap 但是怎么才能知道是 0 还是 1？ 直接 (e.hash &amp; oldCap) 即 hash &amp; 0000 0000 …… 1 0000 不就行了！！ 如果 (e.hash &amp; oldCap) = 0 那就是说元素在新数组的位置还是之前的，不变； 如果 (e.hash &amp; oldCap) = 1 那就是说元素在新数组的位置 &#x3D; 原来的位置 + oldCap 参考文章 putVal123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121// 参数 onlyIfAbsent 表示是否替换原值// true: 不替换，false: 替换// 参数 evict 我们可以忽略它，它主要用来区别通过 put 添加还是创建时初始化数据的// 如果为 false，该 table 处于创建阶段final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 如果 table 数组为空 或 长度为 0，则对其进行初始化，分配内存空间 if ((tab = table) == null || (n = tab.length) == 0) // resize()不仅用来调整大小，还用来进行初始化配置 // 这里就用到 resize 初始化 n = (tab = resize()).length; // 当 put 的 key 在数组中不存在时，直接 new 一个 Node 元素放入 if ((p = tab[i = (n - 1) &amp; hash]) == null) // (n - 1) &amp; hash 就是把 hash &amp; ( 数组长度 - 1 ) // 为什么要 n - 1 呢，这里正好解释了为什么 HashMap 的数组长度要取 2 的整次幂 // n - 1 正好相对于做了一个&quot;低位掩码&quot; // &amp; 操作的结果就是散列值的高位全部归零 // 只保留低位值，用来做数组下标访问 // 以初始长度 16 为例，16 - 1 = 15 // 二进制就是 0000 …… 1111 // 和 hash &amp; 后，就是取低 4 位 // 0000 0000 0000 0000 0000 1111 // &amp; 0000 0001 0100 1010 1010 0101 // = 0000 0000 0000 0000 0000 0101 高位归零，只保留末四位 // 但是只取末四位碰撞也很严重 // 所有就有了 hash(Object key) 这个扰动函数，putVal 的参数 hash 要先搞扰动 // 再进来 hash(Object key) // hashCode() 获取哈希值 h，然后 h &gt;&gt;&gt; 16，右位移 16 位，正好是 32 位一半 // 然后把自己的高半区和低半区异或(^) // ( 为了加大低位的随机性，而且混合后低位掺杂了高位的部分特征，这样高位的信息变相保留了下来 ) // 简单版 // 先通过 hashcode 拿到最初的 hash 值，也就是 32 位的内存地址 // 然后高 16 位右移和原来的 hash 异或( 两个不同就为真 ) // 这时候低 16 位就保留了高低位的信息 // 然后再和( 数组大小 - 1 )与( &amp; )，拿到低位 // 而数组大小建议是 2 的幂次方，这样减 1 后低位就是 000...1111，和已经扰动的 hash 值与( &amp; )一下就拿到低位 // 这样这个低位就有很大的随机性，这个低位来充当数组下标，能更有效的避免哈希碰撞 // 这里就是看下在 hash 位置有没有元素，实际位置是 hash % (length - 1) // 将元素直接插进去 tab[i] = newNode(hash, key, value, null); else &#123; // 如果元素在集合中已存在 // 这时就需要链表或红黑树了 // e 是用来查看是不是待插入的元素已经有了，有就替换 Node&lt;K,V&gt; e; K k; // p 是存储在当前位置的元素 // 如果 tab[(n - 1) &amp; hash] 位置的第一个元素的 key 和要保存的 key 相等 // 这说明目的是修改值 // 将 p 的值赋给 e if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 如果是红黑树节点，则调用其put方法 else if (p instanceof TreeNode) // 把节点添加到树中 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 不是替换第一个节点，也不是红黑树节点，那就是链表了 // 循环每一个元素 else &#123; // 这时候就是链表结构了，使用尾插法!!! for (int binCount = 0; ; ++binCount) &#123; // 如果找找找，也没有找到一样的 key，且 p 没有下一个了 // 就直接 new if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 如果超过树的阈值，就要变成红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 由于初始即为 p.next，所以当插入第 8 个元素才会树化 // -1 for 1st 如果链表的长度超过 8，则进行红黑树进行转换。 // 1.8后追加：链表查询的复杂度是 O(n)，而红黑树是 O(log(n))， // 但是如果 hash 不均匀会极大的影响性能 // 此方法里面会判断，如果数组长度大于等于 64，转为红黑树， // 如果数组长度小于 64，就进行扩容 resize treeifyBin(tab, hash); break; &#125; // 找到了对应元素，就可以停止了 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) //此时 e 就是找到的相同 key 的，要替换的节点 break; // 继续向后循环 p = e; &#125; &#125; // 此时 e 就是找到的相同 key 的，要替换的节点 if (e != null) &#123; // 原值 V oldValue = e.value; // 如果 onlyIfAbsent 为 false，或者原值为 null，就是要替换 if (!onlyIfAbsent || oldValue == null) // 改 e.value = value; // afterNodeAccess 默认为空实现，允许我们修改完成后做一些操作 // 它由 LinkedHashMap 的实现，并调用 afterNodeAccess(e); // 返回，这里是返回已经更新的值，这是引用 return oldValue; &#125; &#125; // 操作数 + 1 ++modCount; // 如果 size 大于扩容阀值 threshold，则进行扩容操作 if (++size &gt; threshold) resize(); // 由 LinkedHashMap 的实现，并调用 // 作用：在执行一次插入操作都会执行的操作 // 主要就是对 LRU 算法的支持 // 是否移动最早的元素。、但是 LinkedHashMap 中总是返回 false，所以在这里没什么用 // 回调移除最早放入 Map 的对象 // 默认也是空实现，允许我们插入完成后做一些操作 afterNodeInsertion(evict); return null;&#125; 尾插法1.8 之前插入元素是使用头插法，可能觉得新来的被访问的可能性高 但是 1.8 之后却使用尾插法 简单来说：头插法，多线程 插入时，会在扩容的时候造成 Infinite Loop ，即 A 指向 B，B 指向 A 具体是为什么请看：参考文章 总结首先 HashMap 是实现了 Map 接口的，所以是它的每个元素都是以键值对的形式存放 而这个键值对 是实现了 Map 接口定义的 Node 类，它的成员变量有 hash、key、value，还有下一个节点 next 而存放这些键值对元素的底层就是 Node 数组 当第一次发生插入时，首先是初始化，即使用 resize 方法 插入1、下标而插入的时候，数组下标是 key 的 hash 值 &amp; ( 数组长度 - 1 ) 这个 hash 值是经过扰动得来的，先通过 hashcode 拿到最初的 hash 值，也就是 32 位的内存地址 然后高 16 位右移和原来的 hash 异或^( 两个不同就为真 ) 这时候低 16 位就保留了高低位的信息 然后再和( 数组大小 - 1 )与( &amp; )，拿到低位作为数组下标 而数组大小建议是 2 的幂次方，这样减 1 后低位就是 000…1111，和已经扰动的 hash 值与( &amp; )一下就拿到低位 这样这个低位就有很大的随机性，这个低位来充当数组下标，能更有效的避免哈希碰撞 2、插入如果这个下标没有元素，就直接赋值 如果有元素 且 key 相同而且 hash 相同，就替换嘛 如果 key 不同或者 hash 不同，那就类型判断( instanceof )，看看原来这个位置的节点是不是红黑树( TreeNode ) 如果是红黑树就执行红黑树的插入 如果不是，那就是执行链表的插入 如果 next 为空，直接new节点( newNode方法 )，尾插法( jdk 1.8 ) 而且它有一个计数的变量( binCount )，如果个数超过了设置的红黑树阈值( TREEIFY_THRESHOLD )( 默认 8 )，就执行链表转红黑树方法( treeifyBin ) 如果 next 不为空 但 key 不同或者 hash 不同，就继续迭代链表 且 hash 相同，key 也相同，这时候就看 put 方法的参数有没有说如果遇到 key 和 hash 一样的，是否要保留原值，再进行操作 插入结束后，会自增 map 的 size，如果实际大小超过临界值( threshold )，就会进行扩容( threshold &#x3D; 负载因子 * 容量 )，执行 resize 方法 3、尾插法1.8 之前插入元素是使用头插法，可能觉得新来的被访问的可能性高。 但是1.8 及以后却使用尾插法。 简单来说：头插法，多线程 插入时，会在扩容的时候造成 Infinite Loop( 无限循环、死循环 ) ，形成 环形链表，即 A 指向 B，B 指向 A 扩容或初始化1、初始化如果是第一次插入，那么需要进行初始化，而初始化是在 resize 方法里面 在 resize 方法里面，因为 HashMap new 的时候只是初始化了负载因子，是 0.75f，而 resize 方法会对容量和临界值( threshold )赋值 如果在构造函数里已经有具体的容量参数，就直接用 如果没有，就用默认的 2、扩容如果已经初始化 如果目前现在的的容量大于最大容量的上限( MAXIMUM_CAPACITY )，则不会进行扩容，并且设置临界值( threshold )为最大( Integer.MAX_VALUE ) 如果现在的容量没到达上限，就会对容量进行 两倍扩容( &lt;&lt; 1 ) 而且再扩大两倍还没超过上限，并且原来的容量大于默认的容量( DEFAULT_INITIAL_CAPACITY 16 ) 就会对临界值( threshold )也进行 两倍扩容( &lt;&lt; 1 ) 完成后，再进行元素的重新放置 它会开一个新容量的数组，按照老数组的下标来遍历，把元素都拷进去 如果元素 next 为 null，表示此元素是单个的，直接根据 hash &amp; ( 容量 - 1 ) 得到新的位置进行赋值 如果元素 next 不为 null，再判断是不是红黑树节点 如果是，就按红黑树转 如果不是，那就是链表了 新的链表头的下标不是根据 hash &amp; ( 容量 - 1 ) 得到新的位置 而是根据判断( e.hash &amp; oldCap )是不是等于 0，来决定是 采用( 原始位置 + 原始容量 )得到 新的位置，还是位置不变 它会维护两个链表，一个存着位置不变的元素链，一个存着位置为( 原始位置 + 原始容量 )的元素链 至于为什么根据( e.hash &amp; oldCap )来判断 看上面的 扩容后链表元素的位置 其他常用的易忘的1234public V getOrDefault(Object key, V defaultValue) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? defaultValue : e.value;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"集合","slug":"集合","permalink":"https://kebabshellgithub.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"Java 集合简述","slug":"Java-集合简述","date":"2020-12-09T22:40:26.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/09/Java-集合简述/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/09/Java-%E9%9B%86%E5%90%88%E7%AE%80%E8%BF%B0/","excerpt":"","text":"Java 的集合由两个接口实现：Map 和 Collection Collection 和 Map 最大的区别就是： Map 存 key-value 键值对 Collection 只存放一个 Map key-value 键值对，不重复 Map 接口本身定义了很多方法，一些基本的不多说 容易忽略的是 compute merge merge： merge 方法是 1.8 才加进来的。 第三个参数是 BiFunction 函数式接口，用来定义规则 1234567891011121314default V merge(K key, V value, BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction) &#123; Objects.requireNonNull(remappingFunction); Objects.requireNonNull(value); V oldValue = get(key); V newValue = (oldValue == null) ? value : remappingFunction.apply(oldValue, value); if(newValue == null) &#123; remove(key); &#125; else &#123; put(key, newValue); &#125; return newValue;&#125; 使用： 123456789Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;();map.put(&quot;k&quot;, 1);map.put(&quot;k1&quot;, 1);map.merge(&quot;k1&quot;, 1, (oldValue, newValue) -&gt; &#123; return oldValue + newValue; &#125;);/* * 这里的 merge 就是 当 k1 存在，map的value = 旧值 + 新值(第二个参数) * 如果 k1 不存在，value = 第二个参数 */ compute： 12345678910Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;();map.put(&quot;k&quot;, 1);map.put(&quot;k1&quot;, 1);Integer k = map.compute(&quot;k&quot;, (key, oldValue) -&gt; oldValue + 1);System.out.println(k); // 2Integer kk = map.compute(&quot;k&quot;, (key, oldValue) -&gt; oldValue * 2);System.out.println(kk); // 4Integer k2 = map.compute(&quot;k2&quot;, (key, oldValue) -&gt; oldValue);System.out.println(k2); // null HashMap HashMap 确定下标 插入 扩容&#x2F;初始化 Collections.SynchronizedMap线程安全 内部维护了一个普通对象 Map，还有排它锁 mutex 操作 map 的时候，就会对方法上锁 1234private static class SynchronizedMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Serializable &#123; private final Map&lt;K,V&gt; m; // Backing Map final Object mutex; // Object on which to synchronize&#125; 1234public int size() &#123; synchronized (mutex) &#123;return m.size();&#125; &#125;public boolean isEmpty() &#123; synchronized (mutex) &#123;return m.isEmpty();&#125; &#125;public boolean containsKey(Object key) &#123; synchronized (mutex) &#123;return m.containsKey(key);&#125; &#125;// ... Hashtable Hashtable 继承了 Dictionary，而 HashMap 继承的是 AbstractMap HashMap 的初始容量为 16，Hashtable 初始容量为 11，负载因子默认都是 0.75f 当现有容量大于总容量 * 负载因子时，HashMap 扩容规则为当前容量翻倍，Hashtable 扩容规则为当前容量翻倍 + 1 线程安全 123public synchronized V get(Object key) &#123; // ...&#125; Hashtable 是不允许键或值为 null 的，HashMap 的键值则都可以为 null Hashtable 在 put 空值的时候会直接抛空指针异常 123456789public synchronized V put(K key, V value) &#123; // Make sure the value is not null if (value == null) &#123; throw new NullPointerException(); &#125; // ... int hash = key.hashCode(); // null 时也会抛 NullPointerException // ...&#125; HashMap 做了特殊处理 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; ConcurrentHashmap 和 Hashtable 都是支持并发的，这样会有一个问题，当你通过 get(k) 获取对应的 value 时，如果获取到的是 null 时，你无法判断，它是 put(k,v) 的时候 value 为 null，还是这个 key 从来没有做过映射 HashMap 是非并发的，可以通过 contains(key) 来做这个判断 而支持并发的 Map 在调用 m.contains(key) 和 m.get(key)，m 可能已经不同了 contains(key) 也是可以使用 synchronized 进行同步的，所以调用 contains(key) 得到的就是该线程本时刻 map 的状态，本身不存在歧义 问题的关键在于多线程情况下，即便通过 contains(key) 知晓了是否包含 null，下一步当你使用这个结果去做一些事情时可能其他线程已经改变了这种状态，这在单线程下是不可能发生的 并发环境下，如果 contains(key)了，得到的结果之后，再利用这个结果进行逻辑处理，可能由于其他并发线程的执行，导致该条件不成立 摘自stackoverflow: Hashtable 是较古老的类，通常不鼓励使用它。 在之后的使用中，设计人员发现开发中通常需要一个空键或者空值，于是就在HashMap中增加了对null的支持。 HashMap作为HashTable之后实现的类，具有更高级的功能，这基本上只是对Hashtable功能的改进。 创建HashMap时，它专门设计为将空值作为键处理并将其作为特殊情况处理。 补充：JDK源码中作者的注释： To successfully store and retrieve objects from a Hashtable, the objects used as keys must implement the hashCode method and the equals method 要从Hashtable成功存储和检索对象，用作键的对象必须实现hashCode方法和equals方法。 由于null不是对象，因此不能在其上调用.equals（）或.hashCode（），因此Hashtable无法将其计算哈希值以用作键 ConcurrentHashMap ConcurrentHashMap CollectionColletion 接口定义了方法，无非就是 CRUD，好像也没有 U 注意还有一些 api： isEmpty：判断集合是否为空 size：集合大小 toArray：集合 &#x3D;&gt; 数组 ListList 是 有序 的、可重复 的 实现常用的有：ArrayList 和 LinkedList，从字面意思就能知道它们底层的数据结构 void replaceAll(UnaryOperator&lt;E&gt; operator) &#96;&#96;&#96;javaArrayList list &#x3D; new ArrayList&lt;&gt;();list.add(1);list.add(2);list.add(3); list.replaceAll(t -&gt; t + 1); list.forEach(System.out::print); &#x2F;&#x2F; 234 12345678910111213141516171819202122232425262728293031 ### Set![/集合/Collection-Set1.png](https://i.loli.net/2020/12/09/QgOlsDKH5b69ukV.png)`Set` 的特点是 **无序**、**不重复**底层即是 Map，只是值字段不用`AbstactSet` 定义了一些共有的方法：![/集合/Collection-Set2.png](https://i.loli.net/2020/12/09/ELM9C6zUPBto1FX.png)实现主要是 `TreeSet`、`HashSet`、`LinkedHashSet`- `HashSet`: 底层就是 `HashMap` - ```java private transient HashMap&lt;E,Object&gt; map; /** * Constructs a new, empty set; the backing &lt;tt&gt;HashMap&lt;/tt&gt; instance has * default initial capacity (16) and load factor (0.75). */ public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; TreeSet：底层TreeMap，红黑树，实现了 NavigableSet 接口，NavigableSet 实现了 SortedSet 接口，SortedSet 使得他有序，SortedSet 的实现也就他一个 LinkedHashSet：在 HashSet 的基础上，每个元素都额外带了一个链记住下一个添加的元素，以此来维护顺序 快速失败在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了增加、删除、修改操作，则会抛出 ConcurrentModificationException 迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变 modCount 的值。每当迭代器使用 hashNext()&#x2F;next() 遍历下一个元素之前，都会检测 modCount 变量是否为 expectedmodCount 值，是的话就返回遍历；否则抛出 ConcurrentModificationException 异常，终止遍历 这里异常的抛出条件是检测到 modCount !&#x3D; expectedmodCount 这个条件 如果集合发生变化时修改 modCount 值刚好又设置为了 expectedmodCount 值，则异常不会抛出。因此，不能依赖于这个异常是否抛出而进行并发操作的编程，这个异常只建议用于检测并发修改的 bug java.util 包下的集合类都是快速失败的，不能在多线程下发生并发修改( 迭代过程中被修改 ) 失败安全采用失败安全机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历 由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发 ConcurrentModificationException 基于拷贝内容的优点是避免了 ConcurrentModificationException，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。这也就是他的缺点，同时，由于是需要拷贝的，所以比较吃内存 java.util.concurrent 包下的容器都是安全失败，可以在多线程下并发使用，并发修改 参考","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"集合","slug":"集合","permalink":"https://kebabshellgithub.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"TCP","slug":"TCP","date":"2020-12-07T22:57:21.000Z","updated":"2023-04-06T11:06:55.030Z","comments":true,"path":"2020/12/07/TCP/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/07/TCP/","excerpt":"","text":"参考 ( TCP 可以被描述为“一种带累积正向确认的滑动窗口协议” ) 头部重要的东西 P418 序列号 确认号 TCP Flag：包的类型，即 SYN、FIN、ACK那些 RST：重置连接 窗口大小 Window Size：也叫 Advertised-Window 校验和 紧急指针：设置 URG 才有效 TCP 选项 最常见的就是“最大段大小”( MSS )，MSS 只是 数据部分 的大小，不包含 TCP 首部，默认 536 字节( 最大 1460 )，刚好组成一个 576 字节( 20 + 20 + 536 )的 IPv4 数据报 一般在发送的第一个报文段( 即 SYN 那个 )上指定这个选项 要和 MTU ( 最大传输单元 )区分，只是 MSS 的设置要根据 MTU 来设置。链路层 1500 的 MTU，而去掉 TCP&#x2F;IP 首部 40，就是 1460 了( 光纤是 1440 ) SACK 选择确认选项 窗口缩放：WSCALE&#x2F;WSOPT 能将上面的 16 位窗口大小增加到 32 位 只在 SYN 报文段中，每个方向都可不一样 时间戳 要求发送方在每个报文段添加 2 个 4 字节的时间戳数值，接收方会在确认中反映这些数值，允许发送方针对每个接收到的 ACK ( TCP 用一个 ACK 确认多个报文段 ) 14章 能防回绕 连接控制三次握手、四次挥手、半关闭、同时打开与关闭 三次握手建立都可能带选项 发送方 SYN + ISN(c) ( ISN：初始序列号 ) 接收方 SYN + ISN(s) + ACK ( 此 ACK &#x3D; ISN(c) + 1 ) 发送方 ACK( 此 ACK &#x3D; ISN(s) + 1 ) 初始序列号 ISN 随时间改变 可视为一个 32 位的计数器，每 4 微秒 + 1，防止重叠 可用于抵御伪造的 TCP 现代系统采用半随机，详见协议 P428 四次挥手终止close() 主动关闭者 FIN + K( 当前序列号 ) + ACK( 用于确认对方最近一次发来的数据 L ) 被动关闭者 L( 序列号 ) + ACK( K + 1 ) 被动-&gt;主动，FIN + L( 序列号 ) + ACK( K + 1 ) 主动关闭者 K( 序列号 ) + ACK( L + 1 ) 半关闭shutdown() 我已经完成数据的发送工作，并发送一个 FIN 给对方，但我仍希望接收来自对方的数据直到对方发送 FIN 给我 过程和四次挥手一样，只是被动关闭者没有发送 FIN 之前，主动关闭者还是能接收数据 同时打开与关闭同时打开两方同时发送 SYN 都返回 SYN + ACK 同时关闭同时发送 FIN + ACK 都返回 ACK 和正常关闭一样，只是是交叉的 重点ARQ 和 重传Automatic Repeat-reQuest 自动重传请求 简单地“尝试重新发送”，直到信息最终被接收 确认号( 也可以叫 ACK ) 只有 ACK 位字段被启用才有效( 连接建立后一般都是启用的 ) TCP 的 ACK 是 累积 的，即是累积确认的，发送方发了几个相同数据包，只会收到一个确认 确认号代表的是这个 ACK 的发送方期待接收的下一个序列号( 即最后被成功接收的序列号 + 1 ) 校验和 计算方法和 UDP、IP、ICMP 一样( UDP校验和 ) 序列号( 32位 ) 标识了发送方到接收方的数据流的一个字节，这个字节就是该报文段( segement )中的数据的第一个字节 但是一个一个发效率太低 序列号和 ACK 是以字节数为单位，所以 ACK 的时候，不能跳着确认，只能确认最大的连续收到的包，不然，发送端就以为之前的都收到了 窗口分组窗口和滑动窗口 这样的窗口结构发送方和接收方都有 发送方：记录哪些分组可被释放，哪些正在等待 ACK，哪些还不能发送 接收方：记录哪些分组已经被接收和确认，哪些分组是下一步期望的( 和已经分配多少内存来保存它们 )，以及哪些即使被接收也将会因内存限制而被丢弃 SACK 因为接收的数据是无序的，窗口会出现空洞 发送方要了解接收方有哪些空洞，就能重传这个分组 要在 SYN 报文段开启“允许选择确认”选项 要 两方都支持 SACK 保存在选项中，包含接收方已经成功接收的数据块的序列号范围，每个范围被称作 SACK 块，由一对 32 位序列号( 一共 32 位 )表示，因此，一个 SACK 选项 &#x3D; n 个 SACK 块 &#x3D; 8 * n + 2 字节( 多的 2 个字节保存 SACK 选项的种类和长度 ) 一般一个报文段最多 3 个 SACK 块（ 已使用时间戳选项 ） 变量窗口( 用于流量控制和拥塞控制 ) ( 窗口大小会变 ) ( 一个窗口只会设置一个定时器 ) 为了处理接收方相对于发送方太慢的问题 有两种方式 基于速率 给发送方指定某个速率，确保数据不会超过这个速率 适合流应用程序，可被用于广播和组播发现 基于窗口 窗口大小不是固定的，而是允许时间而变动的 逻辑上，窗口更新的告知是与 ACK 分离的，但实际上两个是由 同一个分组 携带的，意味着发送方往往会在它的窗口滑动到右边的 同时 调整它的大小 重传 基于时间( 计时器超时 ) 基于确认信息( 更有效 )( 快速重传 ) 两者都有用到 重传超时RTO - Timeout P465 根据平均往返时间 RTT（一个数据包从发出去到回来的时间） 来设置 RTO，RTTs( RTT样本：RTT sample )，推荐的 α 值为 1&#x2F;8 其他算法：Karn &#x2F; Partridge 算法、Jacobson &#x2F; Karels 算法等 根据 时间戳 来设置 TSOPT 协议P468 快速重传推测 丢包 不以时间驱动，而以数据驱动重传 累积确认 无法返回新的 ACK 当 ACK 包含的 SACK 表明有 失序报文段 如果发送方连续三次 ( 一般来说是 3 次 ) 收到重复的 ACK，得知哪的没传到 ( 在没 SACK 的情况下，每个 RTT 内只能至多知道一个空缺 )，就会重传对应包，而不需要等到计时器超时，如果有采用 SACK，重复的 ACK 也会包含 SACK 信息 SACK(上面也有补充) ACK 还是快速重传的 ACK，SACK 则是汇报收到的数据碎版 SACK 包含的是最近接收到的报文段的序列号范围 一个 ACK 包含三四个 SACK 信息 每个 SACK 包含 32 位的序列号，代表接收端存储的失序数据的 起始 到 最后 一个序列号 包含 SACK 块的 ACK 也简单称为“SACK” SR(选择重传selective repeat)对支持 SACK 的发送方来说 合理利用 SACK 携带的信息，来重传丢失的报文段，这也叫 SR ( 选择重传 selective repeat ) SR 也是 ARQ 的一种实现 ( 除了SR，还有一个叫 GBN 回退 N 步 ) TCP 有两者的特性，更偏向 SR ( 选择重传 selective repeat ) 一般不叫 SR，会与另一个 SR 混淆 D-SACK使用 SACK 来告诉发送方有哪些数据被重复接收了 D-SACK 使用了 SACK 的第一个段来做标志 如果 SACK 的第一个段的范围被 ACK 所覆盖，那么就是 D-SACK 如果 SACK 的第一个段的范围被 SACK 的第二个段覆盖，那么就是 D-SACK 引入了 D-SACK，有这么几个好处，可以更好的做网络上的流控 可以让发送方知道，是发出去的包丢了，还是回来的 ACK 包丢了 是不是自己的 timeout 太小了，导致重传 网络上出现了先发的包后到的情况（又称 reordering ） 网络上是不是把我的数据包给复制了 伪超时和重传这种伪重传主要原因是 伪超时，当然也包括失序与重复 出现延迟高峰 超过了计时器 触发重传 触发 GBN 接收到重复 ACK，即失序。还有重复( 协议P486-487 ) 触发快速重传 拥塞控制拥塞控制 主要包括： 慢启动 拥塞避免 快重传 快恢复 cwnd：Congestion Window ssthresh：slow start threshold 假设当前发送方 拥塞窗口 cwnd 为 1 个( 拥塞窗口 cwnd 的值是几，就能发送几个数据报文段，实际上书里就是设置为 1 个 MSS，具体看系统 ) 接收方收到报文段后回复一个确认，发送方首次收到确认后将 cwnd 设为 2，接下来，cwnd 4、8、16……以 指数增长，这就是 慢启动 当达到 慢启动阈值 ssthresh 时，TCP 会谨慎增加 cwnd，即进入 拥塞避免 阶段，每次 cwnd 增加 1，然后分两种版本： 如果发生 超时重传，就 重新进入慢启动，即将 ssthresh 设置为 cwnd 的一半，新的 cwnd 设置为 1( TCP Tahoe版本 )( 已废弃 ) 如果 连续有三个冗余的ACK 时，就是出现 丢包，就将相应的报文段重传( 快速重传 )，开始执行 快恢复，即将 ssthresh 设置为 cwnd 的一半，新的 cwnd 设置为新的 ssthresh ( TCP Reno 版本 )，然后拥塞避免，每次 + 1 新的 cwnd 也可以设置为 ssthresh + 3 也有的 快恢复 实现是将新的 cwnd 设置为 新的 ssthresh + 1","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://kebabshellgithub.github.io/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"LeetCode-Learn","slug":"LeetCode-Learn","date":"2020-12-03T17:05:41.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/12/03/LeetCode-Learn/","link":"","permalink":"https://kebabshellgithub.github.io/2020/12/03/LeetCode-Learn/","excerpt":"","text":"Easy01TwoSum 方法一： 暴力求解 方法二： 哈希表 因为暴力解法的时间复杂度是 O(N^2)，所以要追求时间复杂度小一点，而哈希表找的时间复杂度是 O(1) 把nums的值作为hashmap的key “最佳”答案： 12345678910public int[] twoSum(int[] nums, int target) &#123; HashMap&lt;Integer, Integer&gt; hashMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; if (hashMap.containsKey(target - nums[i]))&#123; return new int[]&#123;hashMap.get(target - nums[i]), i&#125;; &#125; hashMap.put(nums[i], i); &#125; return new int[0];&#125; 07ReverseInteger 方法： 取余取整 要考虑的是溢出的问题 以下取自 LeetCode评论区 12345678910111213141516171819202122public int reverse(int x) &#123; int last, num = 0; while (x != 0)&#123; last = x % 10; if (num &gt; Integer.MAX_VALUE / 10 || (num == Integer.MAX_VALUE / 10) &amp;&amp; last &gt; 7) return 0; if (num &lt; Integer.MIN_VALUE / 10 || (num == Integer.MIN_VALUE / 10) &amp;&amp; last &lt; -8) return 0; num *= 10; num += last; x /= 10; &#125; return num;&#125; 09PalindromeNumber 方法1 转数组，从头遍历和从后遍历，判断 方法2 直接数学取余取整，判断 方法3 把数后半部分反转，和前半部分比较 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public boolean isPalindrome(int x) &#123; //方法1 /*if (x &lt; 0) return false; String s = String.valueOf(x); int length = s.length(); int middle = length / 2; char[] chars = s.toCharArray(); //System.out.println(s); for (int a = 0, b = length - 1; a &lt; middle &amp;&amp; b &gt;= middle; a++, b--)&#123; if (chars[a] != chars[b])&#123; return false; &#125; &#125; return true;*/ //方法2 if (x &lt; 0) return false; // 除数 int div = 1; while (x / div &gt;= 10)&#123; div *= 10; &#125; while (x &gt; 0)&#123; // 拿到高位低位 int high = x / div; int low = x % 10; if (high != low) return false; // 截掉高位低位 x = (x % div) / 10; div /= 100; &#125; return true; //方法3 /*if (x &lt; 0 || (x % 10 == 0 &amp;&amp; x != 0)) return false; int revertedNumber = 0; while (x &gt; revertedNumber) &#123; revertedNumber = revertedNumber * 10 + x % 10; x /= 10; &#125; return x == revertedNumber || x == revertedNumber / 10;*/&#125; 13RomanToInteger要理解题意，并不是两两结合来算，而是直接看前一个是不是比后一个小，小就减，大就加 这里数据量太少，用 hashMap 体现不出，直接用 switch-case 123456789101112131415161718192021222324252627282930public int romanToInt(String s) &#123; //I 1 //V 5 //X 10 //L 50 //C 100 //D 500 //M 1000 HashMap&lt;Character, Integer&gt; hashMap = new HashMap&lt;&gt;(); hashMap.put(&#x27;I&#x27;, 1); hashMap.put(&#x27;V&#x27;, 5); hashMap.put(&#x27;X&#x27;, 10); hashMap.put(&#x27;L&#x27;, 50); hashMap.put(&#x27;C&#x27;, 100); hashMap.put(&#x27;D&#x27;, 500); hashMap.put(&#x27;M&#x27;, 1000); int sum = 0; int pre = hashMap.get(s.charAt(0)); for (int i = 1; i &lt; s.length(); i++) &#123; if (pre &lt; hashMap.get(s.charAt(i)))&#123; sum -= pre; &#125;else &#123; sum += pre; &#125; pre = hashMap.get(s.charAt(i)); &#125; sum += pre; return sum;&#125; 14LongestCommonPrefix做的时候想的是：设置一个n，代表最后的相同字符的index，然后从0开始，循环数组，每次取每个字符串第n个字符，看相不相等。 1234567891011121314151617181920212223242526272829303132public String longestCommonPrefix(String[] strs) &#123; String res = &quot;&quot;; if (strs == null || strs.length == 0)&#123; return res; &#125; if (strs.length == 1)&#123; return strs[0]; &#125; // 代表最后的相同字符的index int n = 0; while (true)&#123; int i; for (i = 1; i &lt; strs.length; i++) &#123; if (strs[i - 1].isEmpty() || strs[i].isEmpty())&#123; return res; &#125; if (strs[i - 1].length() &gt; n &amp;&amp; strs[i].length() &gt; n)&#123; if (strs[i - 1].charAt(n) != strs[i].charAt(n)) break; &#125;else &#123; break; &#125; &#125; if (i == strs.length)&#123; n++; &#125;else &#123; break; &#125; &#125; res += strs[0].substring(0, n); return res;&#125; 答案是用分治，分左半部分和右半部分： 1234567891011121314151617181920212223242526272829303132public String longestCommonPrefix(String[] strs) &#123; if (strs == null || strs.length == 0) &#123; return &quot;&quot;; &#125; else &#123; return longestCommonPrefix(strs, 0, strs.length - 1); &#125;&#125;public String longestCommonPrefix(String[] strs, int start, int end) &#123; if (start == end) &#123; return strs[start]; &#125; else &#123; // 分治开始 int mid = (end - start) / 2 + start; // 左半 String lcpLeft = longestCommonPrefix(strs, start, mid); // 右半 String lcpRight = longestCommonPrefix(strs, mid + 1, end); // 小问题解决 return commonPrefix(lcpLeft, lcpRight); &#125;&#125;// 小问题解决public String commonPrefix(String lcpLeft, String lcpRight) &#123; int minLength = Math.min(lcpLeft.length(), lcpRight.length()); for (int i = 0; i &lt; minLength; i++) &#123; if (lcpLeft.charAt(i) != lcpRight.charAt(i)) &#123; return lcpLeft.substring(0, i); &#125; &#125; return lcpLeft.substring(0, minLength);&#125; 20ValidParentheses看答案了。。。 后遇到的要先闭合 所以用栈来存储左半部分，一遇到右半部分的字符，就检查最晚入栈的栈顶字符是不是对应的前半部分的字符 如果是，就出栈，然后继续检查下一个… 12345678910111213141516171819202122232425262728293031323334public boolean isValid(String s) &#123; int length = s.length(); if (length % 2 != 0) return false; Stack&lt;Character&gt; stack = new Stack&lt;&gt;(); HashMap&lt;Character, Character&gt; hashMap = new HashMap&lt;&gt;(); hashMap.put(&#x27;)&#x27;, &#x27;(&#x27;); hashMap.put(&#x27;]&#x27;, &#x27;[&#x27;); hashMap.put(&#x27;&#125;&#x27;, &#x27;&#123;&#x27;); // 从头一个一个找 for (int i = 0; i &lt; length; i++) &#123; char c = s.charAt(i); if (!hashMap.containsKey(c))&#123; // 如果不是后半部分（即是前半部分），就入栈 stack.push(c); &#125;else if (stack.isEmpty() || stack.peek() != hashMap.get(c))&#123; // 如果是后半部分 // 栈里已经没元素了，说明 无法匹配 // 栈顶元素和后半部分 不匹配 return false; &#125;else&#123; // 栈顶元素和后半部分 匹配，出栈，下一个 stack.pop(); &#125; &#125; // 都匹配一定是 空栈 if (!stack.isEmpty()) return false; return true;&#125; 21MergeTwoSortedLists用递归，先看两个链表头节点哪个小，先“吃掉”一个，然后继续让剩下的节点比较。 LeetCode的解释 12345678910111213public ListNode mergeTwoLists(ListNode l1, ListNode l2) &#123; if (l1 == null) return l2; else if (l2 == null) return l1; else if (l1.val &lt; l2.val)&#123; l1.next = mergeTwoLists(l1.next, l2); return l1; &#125;else &#123; l2.next = mergeTwoLists(l1, l2.next); return l2; &#125;&#125; 26RemoveDuplicatesFromSortedArray直接用双指针i、j，i决定无重复数组最后一个元素的索引，j来遍历数组 如果i元素与j元素相等，即重复，就继续往后遍历 如果不等，即不重复，i、j均往后移一位 123456789101112131415public int removeDuplicates(int[] nums) &#123; int length = nums.length; int i, j; for (i = 0, j = 1; i &lt; length &amp;&amp; j &lt; length;) &#123; if (nums[j] == nums[i])&#123; j++; &#125;else &#123; nums[i + 1] = nums[j]; i++; j++; &#125; &#125; return i + 1;&#125; 27RemoveElement拷贝覆盖 设置一个i，代表不一样的元素下标。直接遍历，遇到不一样的就把nums[i]替换成当前num： nums[i] = num，然后 i++ 1234567891011public int removeElement(int[] nums, int val) &#123; int i = 0; for (int num : nums) &#123; if (num != val)&#123; nums[i] = num; i++; &#125; &#125; return i;&#125; Stack20ValidParentheses(E)155MinStack(E)我的方法是在插入和弹出时就计算最小值 12345678910111213141516171819202122232425262728293031323334353637class MinStack &#123; private LinkedList&lt;Integer&gt; stack; private int min = Integer.MAX_VALUE; public MinStack() &#123; stack = new LinkedList&lt;&gt;(); &#125; public void push(int x) &#123; stack.push(x); if (x &lt; min) min = x; &#125; public void pop() &#123; if (top() == min)&#123; stack.pop(); int big_min = Integer.MAX_VALUE; for (Integer integer : stack) &#123; if (integer &lt; big_min) big_min = integer; &#125; min = big_min; &#125;else &#123; stack.pop(); &#125; &#125; public int top() &#123; return stack.peek(); &#125; public int getMin() &#123; return min; &#125;&#125; 而官方是使用辅助栈，和主栈同步，储存每个元素作为栈顶时的最小值 因为只要栈顶元素不变，其他元素就不变，当前的最小值就不变 12345678910111213141516171819202122232425262728class MinStack &#123; Deque&lt;Integer&gt; xStack; Deque&lt;Integer&gt; minStack; public MinStack() &#123; xStack = new LinkedList&lt;Integer&gt;(); minStack = new LinkedList&lt;Integer&gt;(); minStack.push(Integer.MAX_VALUE); &#125; public void push(int x) &#123; xStack.push(x); minStack.push(Math.min(minStack.peek(), x)); &#125; public void pop() &#123; xStack.pop(); minStack.pop(); &#125; public int top() &#123; return xStack.peek(); &#125; public int getMin() &#123; return minStack.peek(); &#125;&#125; 71SimplifyPath(M)我起初是打算一个一个判断，搞个栈，遇到非 / 、 .. 和 . 就跳过……但是 .. 就不好判断了。想了半天。然后就想到一个api split ，我直接就mlgb了，我tm直接我tm。接着看了答案，确实可以这样 直接 split(&quot;/&quot;) 把各个部分组成一个数组 因为两个 / 中间只存在 . 或者 .. ， . 、 .. 才有效。所以 遇到 .. ，且栈不为空，就弹出 遇到不是 . 的，且不是空串，就push 最后balabala输出 123456789101112131415161718192021public String simplifyPath(String path) &#123; String[] paths = path.split(&quot;/&quot;); LinkedList&lt;String&gt; stack = new LinkedList&lt;&gt;(); for (String p : paths) &#123; if (&quot;..&quot;.equals(p)) &#123; if (!stack.isEmpty()) stack.pop(); &#125; else if (!&quot;.&quot;.equals(p) &amp;&amp; !p.isEmpty()) &#123; stack.push(p); &#125; &#125; if (stack.isEmpty()) return &quot;/&quot;; StringBuilder res = new StringBuilder(); while (!stack.isEmpty())&#123; res.insert(0, stack.pop()); res.insert(0, &quot;/&quot;); &#125; return res.toString();&#125; 94BinaryTreeInorderTraversal(M)中序遍历，就是根节点放中间。 我就是直接递归： 1234567891011121314151617181920212223242526272829303132333435/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode() &#123;&#125; * TreeNode(int val) &#123; this.val = val; &#125; * TreeNode(int val, TreeNode left, TreeNode right) &#123; * this.val = val; * this.left = left; * this.right = right; * &#125; * &#125; */class Solution &#123; public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; all = new LinkedList&lt;&gt;(); if (root == null) return all; if (root.left != null)&#123; List&lt;Integer&gt; left = inorderTraversal(root.left); all.addAll(left); &#125; all.add(root.val); if (root.right != null)&#123; List&lt;Integer&gt; right = inorderTraversal(root.right); all.addAll(right); &#125; return all; &#125;&#125; 但是时间和空间都很难看。。我想原因应该是每个递归都new了一个List。 然后实参为引用，改进： 123456789101112131415161718192021class Solution &#123; public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; LinkedList&lt;Integer&gt; res = new LinkedList&lt;&gt;(); myInorderTraversal(root, res); return res; &#125; private void myInorderTraversal(TreeNode root, List&lt;Integer&gt; res)&#123; if (root == null) return; TreeNode left = root.left; TreeNode right = root.right; if (left != null) myInorderTraversal(left, res); res.add(root.val); if (right != null) myInorderTraversal(right, res); &#125;&#125; 然后看答案，还有栈的解法，用迭代表示递归。看得懂，但我写不出来。。。 1234567891011121314public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;Integer&gt;(); Deque&lt;TreeNode&gt; stk = new LinkedList&lt;TreeNode&gt;(); while (root != null || !stk.isEmpty()) &#123; while (root != null) &#123; stk.push(root); root = root.left; &#125; root = stk.pop(); res.add(root.val); root = root.right; &#125; return res;&#125; 103BinaryTreeZigzagLevelOrderTraversal(M)我也不知道为啥官方为啥归到Stack里面。答案也没用栈 蛇形输出二叉树 我的思路是双端队列，然后每层弹出和插入都变一个方向，插入时收集数据放入list 比如二叉树是1 23 4567 89 第一趟遍历1，从first弹出，即弹出1，从last插入1的右左(32)，此时queue为32 第二趟遍历32，从last弹出，即先弹2再3，从first依次插入2的左右(45)和3的左右(67)，此时queue为7654 第三趟遍历7654，从first弹出，即先弹7再654，从last依次插入98，此时queue为98 第四趟遍历98，从last弹出，即先弹8再9，从first依次…没了 写的时候乱得厉害，一下first一下last，一下左右一下右左 事实证明我想复杂了… 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public List&lt;List&lt;Integer&gt;&gt; zigzagLevelOrder(TreeNode root) &#123; Deque&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); boolean flag = true; if (root != null) &#123; queue.addLast(root); //System.out.print(root.val); ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(root.val); res.add(list); &#125; while (!queue.isEmpty()) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); int size = queue.size(); for (int i = 0; i &lt; size; i++) &#123; if (flag) &#123; TreeNode first = queue.pollFirst(); TreeNode right = first.right; if (right != null) &#123; queue.addLast(right); //System.out.print(first.right.val); list.add(right.val); &#125; TreeNode left = first.left; if (left != null) &#123; queue.addLast(left); //System.out.print(first.left.val); list.add(left.val); &#125; &#125; else &#123; TreeNode last = queue.pollLast(); if (last.left != null) &#123; TreeNode left = last.left; queue.addFirst(left); //System.out.print(last.left.val); list.add(left.val); &#125; if (last.right != null) &#123; TreeNode right = last.right; queue.addFirst(right); //System.out.print(right.val); list.add(right.val); &#125; &#125; &#125; flag = !flag; if (!list.isEmpty()) res.add(list); &#125; return res;&#125; 答案比我简洁多了，通过一个null来分隔每一层，遇到null就把得到的level_list存进res 维护一个顺序标志is_order_left，过一层就变，决定元素插入level_list是头插还是尾插 元素 level_list queue is_order_left res 1 1 null,2,3 true null 2,3,null false 1 2 2(addFirst) 3,null,4,5 false 1 3 3,2(addFirst) null,4,5,6,7 false 1 null 4,5,6,7,null true 1,32 4 4(addLast) 5,6,7,null,8 true 1,32 5 4,5(addLast) 5,6,7,null,8,9 true 1,32 … 12345678910111213141516171819202122232425262728293031323334353637383940public List&lt;List&lt;Integer&gt;&gt; zigzagLevelOrder(TreeNode root) &#123; if (root == null) &#123; return new ArrayList&lt;List&lt;Integer&gt;&gt;(); &#125; List&lt;List&lt;Integer&gt;&gt; results = new ArrayList&lt;List&lt;Integer&gt;&gt;(); // add the root element with a delimiter to kick off the BFS loop LinkedList&lt;TreeNode&gt; node_queue = new LinkedList&lt;TreeNode&gt;(); node_queue.addLast(root); node_queue.addLast(null); LinkedList&lt;Integer&gt; level_list = new LinkedList&lt;Integer&gt;(); boolean is_order_left = true; while (node_queue.size() &gt; 0) &#123; TreeNode curr_node = node_queue.pollFirst(); if (curr_node != null) &#123; if (is_order_left) level_list.addLast(curr_node.val); else level_list.addFirst(curr_node.val); if (curr_node.left != null) node_queue.addLast(curr_node.left); if (curr_node.right != null) node_queue.addLast(curr_node.right); &#125; else &#123; // we finish the scan of one level results.add(level_list); level_list = new LinkedList&lt;Integer&gt;(); // prepare for the next level if (node_queue.size() &gt; 0) node_queue.addLast(null); is_order_left = !is_order_left; &#125; &#125; return results;&#125; 144BinaryTreePreorderTraversal(M)用迭代，前序遍历 123456789101112131415public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); Deque&lt;TreeNode&gt; stk = new LinkedList&lt;&gt;(); while (root != null || !stk.isEmpty()) &#123; while (root != null) &#123; stk.push(root); res.add(root.val); root = root.left; &#125; root = stk.pop(); //res.add(root.val); root = root.right; &#125; return res;&#125; ★145BinaryTreePostorderTraversal(M)用迭代，后序遍历 这里要用一个变量来判断这个节点的右子节点是否已经入res 为什么只存一个? 因为子节点存完下一个就到它自己了，只需要存之前的那个 1234567891011121314151617181920212223242526272829303132333435public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if (root == null) return res; Deque&lt;TreeNode&gt; stack = new LinkedList&lt;&gt;(); TreeNode prev = null; while (root != null || !stack.isEmpty()) &#123; while (root != null) &#123; stack.push(root); root = root.left; &#125; root = stack.pop(); //if (root.right != null) &#123; // stack.push(root); // root = root.right; //&#125; else &#123; // res.add(root.val); //&#125; 这是错的 // 如果这个节点的右子节点为空或不为空但已经入res // 为什么只存一个? 因为子节点存完下一个就到它自己了，只需要存之前的那个 if (root.right == null || root.right == prev) &#123; res.add(root.val); prev = root; root = null; &#125; else &#123; // 如果这个节点的右子节点不为空且没入res stack.push(root); root = root.right; &#125; &#125; return res;&#125; 150EvaluateReversePolishNotation(M)逆波兰表示式 就那样，用栈实现 1234567891011121314151617181920212223242526272829303132333435363738public int evalRPN(String[] tokens) &#123; Deque&lt;Integer&gt; stack = new LinkedList&lt;&gt;(); for (String token : tokens) &#123; // +, -, *, / if (token.isEmpty()) continue; Integer first, sec; switch (token)&#123; case &quot;+&quot;: first = stack.pop(); sec = stack.pop(); stack.push(sec + first); break; case &quot;-&quot;: first = stack.pop(); sec = stack.pop(); stack.push(sec - first); break; case &quot;*&quot;: first = stack.pop(); sec = stack.pop(); stack.push(sec * first); break; case &quot;/&quot;: first = stack.pop(); sec = stack.pop(); stack.push(sec / first); break; default: stack.push(Integer.valueof(token)); &#125; &#125; return stack.poll();&#125; 看了评论，也可以用数组实现栈，快一点 123456789101112131415161718192021222324252627282930313233343536373839404142434445public int evalRPN(String[] tokens) &#123; //Deque&lt;Integer&gt; stack = new LinkedList&lt;&gt;(); int[] stack = new int[tokens.length]; int index = -1; for (String token : tokens) &#123; // +, -, *, / if (token.isEmpty()) continue; int first, sec; switch (token)&#123; case &quot;+&quot;: first = stack[index]; sec = stack[index - 1]; index--; stack[index] = sec + first; break; case &quot;-&quot;: first = stack[index]; sec = stack[index - 1]; index--; stack[index] = sec - first; break; case &quot;*&quot;: first = stack[index]; sec = stack[index - 1]; index--; stack[index] = sec * first; break; case &quot;/&quot;: first = stack[index]; sec = stack[index - 1]; index--; stack[index] = sec / first; break; default: index++; stack[index] = Integer.parseInt(token); &#125; &#125; return stack[0];&#125; 173BinarySearchTreeIterator(M)二叉搜索树迭代器 因为二叉搜索树是左小右大的，直接中序遍历生成的序列就是从小到大的 1234567891011121314151617181920212223242526272829303132class BSTIterator &#123; ArrayList&lt;Integer&gt; res; int i = 0; public BSTIterator(TreeNode root) &#123; res = new ArrayList&lt;&gt;(); myInorderTraversal(root, res); &#125; public int next() &#123; return res.get(i++); &#125; public boolean hasNext() &#123; if (i &lt; res.size()) return true; return false; &#125; private void myInorderTraversal(TreeNode root, List&lt;Integer&gt; res)&#123; if (root == null) return; TreeNode left = root.left; TreeNode right = root.right; if (left != null) myInorderTraversal(left, res); res.add(root.val); if (right != null) myInorderTraversal(right, res); &#125;&#125; 227BasicCalculatorIi(M)基本计算器（没有括号） 想到之前的逆波兰表示，整蒙圈了 看了评论 用一个char来存储一个数之前的符号，等拿到这个数(如果当前字符是非数字，那就是这个数已经拿到)，就能根据这个char来判断 如果是加减，就直接入栈 如果是乘除，就把栈顶弹出，和已经拿到的这个数做运算 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public int calculate(String s) &#123; Deque&lt;Integer&gt; stack = new LinkedList&lt;&gt;(); char[] nums = (s).toCharArray(); int num = 0; char oprt = &#x27;+&#x27;; for (int i = 0; i &lt; nums.length; i++) &#123; // 如果是数字，就拿数 if (Character.isDigit(nums[i])) &#123; num = num * 10 + (nums[i] - &#x27;0&#x27;); &#125; // 如果不是数字，也不是空格，或者这时候已经是最后一个字符了，就要操作了 if (!Character.isDigit(nums[i]) &amp;&amp; nums[i] != &#x27; &#x27; || i == nums.length - 1) &#123; // 乘除的时候弹出的栈顶 int pre; // 这个数num之前的符号 switch (oprt)&#123; case &#x27;+&#x27;: // 如果是加减，就直接入栈 stack.push(num); break; case &#x27;-&#x27;: stack.push(-num); break; case &#x27;*&#x27;: // 乘除就拿栈顶来运算 pre = stack.pop(); stack.push(num * pre); break; case &#x27;/&#x27;: pre = stack.pop(); stack.push(pre / num); break; &#125; // 记得把操作变为当前字符 oprt = nums[i]; // 重新拿数字 num = 0; &#125; &#125; // 直接连加 int sum = 0; while (!stack.isEmpty())&#123; sum += stack.pop(); &#125; return sum;&#125; 232ImplementQueueUsingStacks(E)栈实现队列 就这样 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class MyQueue &#123; Deque&lt;Integer&gt; left_stack; Deque&lt;Integer&gt; right_stack; public MyQueue() &#123; left_stack = new LinkedList&lt;&gt;(); right_stack = new LinkedList&lt;&gt;(); &#125; public void push(int x) &#123; left_stack.push(x); &#125; public int pop() &#123; moveToRight(); Integer pop = right_stack.pop(); moveToLeft(); return pop; &#125; public int peek() &#123; moveToRight(); Integer peek = right_stack.peek(); moveToLeft(); return peek; &#125; public boolean empty() &#123; return left_stack.isEmpty(); &#125; private void moveToRight()&#123; while (!left_stack.isEmpty())&#123; right_stack.push(left_stack.pop()); &#125; &#125; private void moveToLeft()&#123; while (!right_stack.isEmpty())&#123; left_stack.push(right_stack.pop()); &#125; &#125;&#125; 316RemoveDuplicateLetters(M)去除重复元素，并保持字典序 第一次字典序理解错了，完全瞎做 第二次还是理解不到位，忘了一个条件 当当前元素小于栈底元素，但字符串后面已经没有栈底这个元素了，就不能移除 第三个是参考答案 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public String removeDuplicateLetters(String s) &#123; // first //StringBuilder builder = new StringBuilder(&quot;&quot;); // //LinkedHashSet&lt;Character&gt; hashSet = new LinkedHashSet&lt;&gt;(); // // //char min = &#x27;z&#x27;; // //char[] chars = s.toCharArray(); //for (char c : chars) &#123; // if (c - min &lt; 0) &#123; // min = c; // &#125; // hashSet.add(c); //&#125; //builder.append(min); //for (Character character : hashSet) &#123; // if (min != character) // builder.append(character); //&#125; // //return builder.toString(); /*==================*/ // second //StringBuilder builder = new StringBuilder(&quot;&quot;); // //Deque&lt;Character&gt; list = new LinkedList&lt;&gt;(); // //for (int i = 0; i &lt; s.length(); i++) &#123; // char now = s.charAt(i); // if (list.isEmpty())&#123; // list.addLast(now); // &#125;else if (!list.contains(now) &amp;&amp; list.getFirst() &gt; now)&#123; // while (!list.isEmpty() &amp;&amp; list.getFirst() &gt; now)&#123; // list.removeFirst(); // &#125; // list.addFirst(now); // &#125;else if (!list.contains(now))&#123; // list.addLast(now); // &#125; //&#125; // //while (!list.isEmpty())&#123; // builder.append(list.pop()); //&#125; //return builder.toString(); // third Stack&lt;Character&gt; stack = new Stack&lt;&gt;(); // this lets us keep track of what&#x27;s in our solution in O(1) time HashSet&lt;Character&gt; seen = new HashSet&lt;&gt;(); // this will let us know if there are any more instances of s[i] left in s HashMap&lt;Character, Integer&gt; last_occurrence = new HashMap&lt;&gt;(); for (int i = 0; i &lt; s.length(); i++) last_occurrence.put(s.charAt(i), i); for (int i = 0; i &lt; s.length(); i++) &#123; char c = s.charAt(i); // we can only try to add c if it&#x27;s not already in our solution // this is to maintain only one of each character if (!seen.contains(c)) &#123; // if the last letter in our solution: // 1. exists // 2. is greater than c so removing it will make the string smaller // 3. it&#x27;s not the last occurrence // we remove it from the solution to keep the solution optimal while (!stack.isEmpty() &amp;&amp; c &lt; stack.peek() &amp;&amp; last_occurrence.get(stack.peek()) &gt; i) &#123; seen.remove(stack.pop()); &#125; seen.add(c); stack.push(c); &#125; &#125; StringBuilder sb = new StringBuilder(stack.size()); for (Character c : stack) sb.append(c.charValue()); return sb.toString();&#125; 331VerifyPreorderSerializationOfABinaryTree(M)验证二叉树的前序序列化 不会。。。 答案真简单，但想想也应该是这样： 我们可以定义一个概念，叫做槽位，二叉树中任意一个节点或者空孩子节点都要占据一个槽位。二叉树的建立也伴随着槽位数量的变化。开始时只有一个槽位，如果根节点是空节点，就只消耗掉一个槽位，如果根节点不是空节点，除了消耗一个槽位，还要为孩子节点增加两个新的槽位。之后的节点也是同理。 有了上面的讨论，方法就很简单了。依次遍历前序序列化，根据节点是否为空，按照规则消耗&#x2F;增加槽位。如果最后可以将所有的槽位消耗完，那么这个前序序列化就是合法的。 开始时只有一个可用槽位。 空节点和非空节点都消耗一个槽位。 空节点不增加槽位，非空节点增加两个槽位。 1234567891011121314151617public boolean isValidSerialization(String preorder) &#123; int slots = 1; for (String node : preorder.split(&quot;,&quot;)) &#123; --slots; if (slots &lt; 0) return false; if (!node.equals(&quot;#&quot;)) slots += 2; &#125; return slots == 0;&#125; 341FlattenNestedListIterator(M)扁平化嵌套列表迭代器 直接初始化就递归 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// This is the interface that allows for creating nested lists.// You should not implement it, or speculate about its implementationpublic interface NestedInteger &#123; // @return true if this NestedInteger holds a single integer, rather than a nested list. public boolean isInteger(); // @return the single integer that this NestedInteger holds, if it holds a single integer // Return null if this NestedInteger holds a nested list public Integer getInteger(); // @return the nested list that this NestedInteger holds, if it holds a nested list // Return null if this NestedInteger holds a single integer public List&lt;NestedInteger&gt; getList();&#125;public class NestedIterator implements Iterator&lt;Integer&gt; &#123; private Deque&lt;Integer&gt; list; public NestedIterator(List&lt;NestedInteger&gt; nestedList) &#123; list = new LinkedList&lt;&gt;(); listPush(nestedList); &#125; private void listPush(List&lt;NestedInteger&gt; nestedList)&#123; for (NestedInteger nestedInteger : nestedList) &#123; if (nestedInteger.isInteger()) list.push(nestedInteger.getInteger()); else &#123; listPush(nestedInteger.getList()); &#125; &#125; &#125; @Override public Integer next() &#123; return list.pollLast(); &#125; @Override public boolean hasNext() &#123; return !list.isEmpty(); &#125;&#125; 从头开始2AddTwoNumbers(M)两数相加 我是用递归的，因为试着直接循环链表感觉太乱了，变量太多，脑子转不过来 因为每位都是个位十进制，只要处理好进位就行 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class ListNode &#123; int val; ListNode next; ListNode() &#123; &#125; ListNode(int val) &#123; this.val = val; &#125; ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125;&#125;/* ==================================== */public ListNode addTwoNumbers(ListNode l1, ListNode l2) &#123; // 根节点 ListNode res = new ListNode(); // 先算出第一位的和，包括进位 if (l1 != null) res.val += l1.val; if (l2 != null) res.val += l2.val; // 拿到进位 int more = res.val / 10; // 拿到个位数 res.val %= 10; // 拿到下一个节点 res.next = myAddTwoNumbers(l1 == null ? null : l1.next, l2 == null ? null : l2.next, more); return res;&#125;public ListNode myAddTwoNumbers(ListNode l1, ListNode l2, int more) &#123; // 递归结束 if (l1 == null &amp;&amp; l2 == null)&#123; // 如果还有进位，就再加一个节点，结束 if (more != 0)&#123; return new ListNode(more); &#125; return null; &#125; // 构建新节点 ListNode res = new ListNode(); // 拿和 if (l1 != null) res.val += l1.val; if (l2 != null) res.val += l2.val; // 加上前一位的进位 res.val += more; // 拿到这次的进位 more = res.val / 10; // 拿到个位 res.val %= 10; // 拿到下一位 res.next = myAddTwoNumbers(l1 == null ? null : l1.next, l2 == null ? null : l2.next, more); return res;&#125; 3LongestSubstringWithoutRepeatingCharacters(M)无重复字符的最长子串 我的解法就是那样，但做了重复的判断，因为不知道map怎么删掉前i个元素 123456789101112131415161718192021222324252627public int lengthOfLongestSubstring(String s) &#123; int length = s.length(); if (length == 0) return 0; if (length == 1) return 1; HashMap&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); int count = 0, max = 0; for (int i = 0; i &lt; length; i++) &#123; char now = s.charAt(i); if (map.get(now) == null)&#123; map.put(now, i); count++; if (count &gt; max) max = count; &#125;else &#123; i = map.get(now); count = 0; map.clear(); &#125; &#125; return max;&#125; 答案： 依次递增地枚举子串的起始位置，那么子串的结束位置也是递增的 假设我们选择字符串中的第 kk 个字符作为起始位置，并且得到了不包含重复字符的最长子串的结束位置为 r_k 。那么当我们选择第 k+1个字符作为起始位置时，首先从 k+1 到 r_k 的字符显然是不重复的，并且由于少了原本的第 k 个字符，我们可以尝试继续增大 r_k，直到右侧出现了重复字符为止 1234567891011121314151617181920public int lengthOfLongestSubstring(String s) &#123; Set&lt;Character&gt; occ = new HashSet&lt;&gt;(); int n = s.length(); int rk = -1, ans = 0; // i 是指子串的第一个下标 for (int i = 0; i &lt; n; ++i) &#123; if (i != 0) &#123; // 每过一个子串，就从set中移除前一个子串的头字符 occ.remove(s.charAt(i - 1)); &#125; // 从这个rk开始，继续往后走，这里避免了重复判断 while (rk + 1 &lt; n &amp;&amp; !occ.contains(s.charAt(rk + 1))) &#123; occ.add(s.charAt(rk + 1)); ++rk; &#125; ans = Math.max(ans, rk - i + 1); &#125; return ans;&#125; 5LongestPalindromicSubstring最长回文子串 不会，看了答案，用动态规划，因为回文串首尾去掉还是回文串，所以有状态转移，即求出边界(一个字符、两个字符)，就能往上推 1234567891011121314151617181920212223242526272829303132public String longestPalindrome(String s) &#123; int l = s.length(); boolean[][] dp = new boolean[l][l]; String res = &quot;&quot;; // 从子串长度为 1 开始 for (int subLength = 0; subLength &lt; l; subLength++)&#123; for (int left = 0; left + subLength &lt; l; left++)&#123; // 拿到左右索引 int right = left + subLength; // 当只有一个元素时，边界① if (subLength == 0)&#123; dp[left][right] = true; &#125;else if (subLength == 1)&#123; // 当有两个元素时，边界② if (s.charAt(left) == s.charAt(right))&#123; dp[left][right] = true; &#125; &#125;else &#123; // 从下往上 dp[left][right] = dp[left + 1][right - 1] &amp;&amp; (s.charAt(left) == s.charAt(right)); &#125; if (dp[left][right] &amp;&amp; subLength + 1 &gt; res.length())&#123; // 拿到子串，注意 subLength 要 + 1 res = s.substring(left, left + 1 + subLength); &#125; &#125; &#125; return res;&#125; 6ZigzagConversionZ 字形变换 直接暴力 构造一个 numRows 个字符串的数组，然后一个一个字符遍历s，用 r 来控制加到哪一行，用一个 flag 来控制行的遍历顺序，遇到边界就反转 flag 123456789101112131415161718192021222324252627282930313233343536373839public String convert(String s, int numRows) &#123; if (s == null) return &quot;&quot;; int length; if ((length = s.length()) == 0) return &quot;&quot;; if (length &lt;= numRows || numRows == 1) return s; //String[] res = new String[numRows]; // 改成 StringBuilder 也没啥卵用 StringBuilder[] res = new StringBuilder[numRows]; boolean flag = true; for (int i = 0, r = 0; i &lt; length; i++) &#123; String c = s.substring(i, i + 1); //res[r] = (res[r] == null) ? c : (res[r] + c); if (res[r] == null) res[r] = new StringBuilder(c); else res[r].append(c); if (flag) r++; else r--; if (r == numRows - 1 || r == 0) flag = !flag; &#125; StringBuilder builder = new StringBuilder(); //for (String row : res) &#123; // builder.append(row); //&#125; for (StringBuilder row : res) &#123; builder.append(row); &#125; return builder.toString();&#125; 然后看了答案，乖乖，跟我一样的思维。。。。不贴出来了 每日一题217ContainsDuplicate(E)存在重复元素 1234567891011121314151617181920212223242526272829303132333435public boolean containsDuplicate(int[] nums) &#123; // 我是直接存hash表，然后判断是否存在 //HashSet&lt;Integer&gt; hashSet = new HashSet&lt;&gt;(); // //for (int num : nums) &#123; // if (hashSet.contains(num))&#123; // return true; // &#125;else &#123; // hashSet.add(num); // &#125; //&#125; //return false; // 答案。。。add直接判断 //HashSet&lt;Integer&gt; hashSet = new HashSet&lt;&gt;(); // //for (int num : nums) &#123; // if (!hashSet.add(num))&#123; // return true; // &#125; //&#125; //return false; // 也可先排序，排完序相同的一定在相邻 Arrays.sort(nums); int n = nums.length; for (int i = 0; i &lt; n - 1; i++) &#123; if (nums[i] == nums[i + 1]) &#123; return true; &#125; &#125; return false;&#125; 49GroupAnagrams字母异位词分组 利用哈希表的特性 12345678910111213141516171819202122public List&lt;List&lt;String&gt;&gt; groupAnagrams(String[] strs) &#123; // map 存放有相同”公共串“的 List HashMap&lt;String, List&lt;String&gt;&gt; hashMap = new HashMap&lt;&gt;(); for (String str : strs) &#123; // 先排序，拿到“公共串” char[] chars = str.toCharArray(); Arrays.sort(chars); String s = String.valueOf(chars); List&lt;String&gt; list; // 如果 map 没有，就 new 一个放进去 if ((list = hashMap.get(s)) == null)&#123; list = new LinkedList&lt;&gt;(); &#125; list.add(str); hashMap.put(s, list); &#125; return new LinkedList&lt;&gt;(hashMap.values());&#125; 遍历，顺便把字符串的字符排个序，看看 HashMap 里有没有，要没有就 new 一个 List ，把没排序的 add 进 List，再把 List 放回去 看了答案，居然有 api: 1234public V getOrDefault(Object key, V defaultValue) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? defaultValue : e.value;&#125; 还有一种方法，用质数： 用质数表示26个字母，把字符串的各个字母相乘，这样可保证字母异位词的乘积必定是相等的 738MonotoneIncreasingDigitscnm，集合类用多了，惯性就用了集合，即使方法对了，也是慢 只要下一位比之前的首位大，就要把之前的都变成 9，记得记录此时的索引，免得下一次再算一次 我的： 123456789101112131415161718192021222324252627282930313233public int monotoneIncreasingDigits(int N) &#123; LinkedList&lt;Integer&gt; list = new LinkedList&lt;&gt;(); int point = 0; while (N != 0) &#123; int low = N % 10; if (list.isEmpty()) list.addLast(low); else if (low &gt; list.getLast()) &#123; int size = list.size(); for (int i = size - 1; i &gt;= point; i--) list.set(i, 9); list.addLast(low - 1); point = size; &#125;else &#123; list.addLast(low); &#125; N /= 10; &#125; int mult = 1, sum = 0; Iterator&lt;Integer&gt; itr = list.iterator(); while (itr.hasNext()) &#123; Integer next = itr.next(); sum += next * mult; mult *= 10; &#125; return sum;&#125; 官方的： 1234567891011121314151617public int monotoneIncreasingDigits(int N) &#123; char[] strN = Integer.toString(N).toCharArray(); int i = 1; while (i &lt; strN.length &amp;&amp; strN[i - 1] &lt;= strN[i]) &#123; i += 1; &#125; if (i &lt; strN.length) &#123; while (i &gt; 0 &amp;&amp; strN[i - 1] &gt; strN[i]) &#123; strN[i - 1] -= 1; i -= 1; &#125; for (i += 1; i &lt; strN.length; ++i) &#123; strN[i] = &#x27;9&#x27;; &#125; &#125; return Integer.parseInt(new String(strN));&#125; 先看看有几位是递增的，就不用重复判断了 290WordPattern一位一位同时遍历，组成键值对插入 HashMap 如果 key 不存在，且不存在相同的 value，就插入 key 存在，value 也相同，跳过 其他情况都 false 123456789101112131415161718192021public boolean wordPattern(String pattern, String s) &#123; String[] two = s.split(&quot; &quot;); if (pattern.length() != two.length) return false; HashMap&lt;Character, String&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; pattern.length(); i++) &#123; char c = pattern.charAt(i); if (map.containsKey(c)) &#123; if (!map.get(c).equals(two[i])) // key 相同，value 又不同 return false; &#125;else if (map.containsValue(two[i]))&#123; // key 不同，value 又相同 return false; &#125;else map.put(c, two[i]); &#125; return true;&#125; 714BestTimeToBuyAndSellStockWithTransactionFee买卖股票的最佳时机含手续费 很明显是 DP 找状态，从第 n 天开始 设 为第 i 天交易结束后，dp[i][0] 表示手上没有股票的收益，dp[i][1] 为有股票的收益，price( i ) 表示第 i 天的股价，fee 表示手续费 dp[i][0] 代表： 前一天，有两种情况： dp[i - 1][0] 和 dp[i - 1][1]，则有 dp[i][0] &#x3D; dp[i - 1][0] dp[i][0] &#x3D; dp[i - 1][1] + price( i ) + fee 有状态转移：dp[i][0] &#x3D; max( dp[i - 1][0], dp[i - 1][1] + price( i ) + fee ) dp[i][1] 代表： 前一天，有两种情况： dp[i - 1][1] 和 dp[i - 1][0]，则有 dp[i][1] &#x3D; dp[i - 1][1] dp[i][1] &#x3D; dp[i - 1][0] - price( i ) 有状态转移：dp[i][1] &#x3D; max( dp[i - 1][1], dp[i - 1][0] - price( i ) ) 而假设 i 是最后一天，dp[i][0] 肯定比 dp[i][1] 大 最后返回 dp[i][0] 就好了 1234567891011121314151617181920212223public int maxProfit(int[] prices, int fee) &#123; int n = prices.length; int[][] dp = new int[n][2]; dp[0][0] = 0; dp[0][1] = -prices[0]; for (int i = 1; i &lt; n; ++i) &#123; dp[i][0] = Math.max(dp[i - 1][0], dp[i - 1][1] + prices[i] - fee); dp[i][1] = Math.max(dp[i - 1][1], dp[i - 1][0] - prices[i]); &#125; return dp[n - 1][0];&#125;// 简化// 都是从前往后，只保留两个变量即可public int maxProfit(int[] prices, int fee) &#123; int n = prices.length; int sell = 0, buy = -prices[0]; for (int i = 1; i &lt; n; ++i) &#123; sell = Math.max(sell, buy + prices[i] - fee); buy = Math.max(buy, sell - prices[i]); &#125; return sell;&#125; 48RotateImage旋转图像 n * n 图像顺时针旋转 90° 12345678910111213141516171819public void rotate(int[][] matrix) &#123; int n = matrix.length; // 水平翻转 for (int i = 0; i &lt; n / 2; ++i) &#123; for (int j = 0; j &lt; n; ++j) &#123; int temp = matrix[i][j]; matrix[i][j] = matrix[n - i - 1][j]; matrix[n - i - 1][j] = temp; &#125; &#125; // 主对角线翻转 for (int i = 0; i &lt; n; ++i) &#123; for (int j = 0; j &lt; i; ++j) &#123; int temp = matrix[i][j]; matrix[i][j] = matrix[j][i]; matrix[j][i] = temp; &#125; &#125;&#125; 746MinCostClimbingStairs使用最小花费爬楼梯 123456789public int minCostClimbingStairs(int[] cost) &#123; int n = cost.length; int[] dp = new int[n + 1]; dp[0] = dp[1] = 0; for (int i = 2; i &lt;= n; i++) &#123; dp[i] = Math.min(dp[i - 1] + cost[i - 1], dp[i - 2] + cost[i - 2]); &#125; return dp[n];&#125; 假设数组 cost 的长度为 n，则 n 个阶梯分别对应下标 0 到 n-1，楼层顶部对应下标 n，问题等价于计算达到下标 n 的最小花费。可以通过动态规划求解。 创建长度为 n + 1 的数组 dp，其中 dp[i] 表示达到下标 i 的最小花费。 由于可以选择下标 0 或 1 作为初始阶梯，因此有 dp[0] &#x3D; dp[1] &#x3D; 0 387FirstUniqueCharacterInAString( E )字符串中的第一个唯一字符 12345678910111213141516171819202122232425262728293031323334public int firstUniqChar(String s) &#123; //HashMap&lt;Character, Integer&gt; times = new HashMap&lt;&gt;(); //for (int i = 0; i &lt; s.length(); i++) &#123; // char now = s.charAt(i); // times.put(now, times.getOrDefault(now, 0) + 1); //&#125; //for (int i = 0; i &lt; s.length(); i++) &#123; // if (times.get(s.charAt(i)) == 1)&#123; // return i; // &#125; //&#125; //return -1; HashMap&lt;Character, Integer&gt; first = new HashMap&lt;&gt;(); for (int i = 0; i &lt; s.length(); i++) &#123; char now = s.charAt(i); if (first.containsKey(now))&#123; first.put(now, -1); &#125;else &#123; first.put(now, i); &#125; &#125; int minIndex = Integer.MAX_VALUE; for (Map.Entry&lt;Character, Integer&gt; entry : first.entrySet()) &#123; Integer index = entry.getValue(); if (index != -1 &amp;&amp; index &lt; minIndex) minIndex = index; &#125; if (minIndex == Integer.MAX_VALUE) return -1; return minIndex; &#125; 455AssignCookies( E )先排个序，然后就那样，没啥说的。。 贪心 12345678910111213141516public int findContentChildren(int[] g, int[] s) &#123; Arrays.sort(g); Arrays.sort(s); int res = 0, i = 0, j = 0; while (i &lt; g.length &amp;&amp; j &lt; s.length)&#123; if (g[i] &lt;= s[j])&#123; i++; j++; res++; &#125;else &#123; j++; &#125; &#125; return res;&#125; 85MaximalRectangle( H )看了 答案，艰难地敲了出来，暴力解法 12345678910111213141516171819202122232425262728293031323334public int maximalRectangle(char[][] matrix) &#123; if (matrix == null || matrix.length == 0) return 0; int row = matrix.length; int col = matrix[0].length; int[][] length = new int[row][col]; for (int i = 0; i &lt; row; i++) &#123; length[i][0] = Character.getNumericValue(matrix[i][0]); for (int j = 1; j &lt; col; j++) &#123; if (matrix[i][j] == &#x27;1&#x27;)&#123; length[i][j] = length[i][j - 1] + 1; &#125; &#125; &#125; int max = 0; for (int i = 0; i &lt; row; i++) &#123; for (int j = 0; j &lt; col; j++) &#123; if (length[i][j] == &#x27;0&#x27;) continue; int width = length[i][j]; max = Math.max(max, length[i][j]); for (int k = i - 1; k &gt;= 0; k--)&#123; width = Math.min(width, length[k][j]); max = Math.max(max, width * (i - k + 1)); &#125; &#125; &#125; return max;&#125; 单调栈，类比 84LargestRectangleInHistogram 123456789101112131415161718192021222324252627282930313233public int maximalRectangle(char[][] matrix) &#123; int m = matrix.length; if (m == 0) &#123; return 0; &#125; int n = matrix[0].length; int[][] left = new int[m][n]; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if (matrix[i][j] == &#x27;1&#x27;) &#123; left[i][j] = (j == 0 ? 0 : left[i][j - 1]) + 1; &#125; &#125; &#125; int ret = 0; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if (matrix[i][j] == &#x27;0&#x27;) &#123; continue; &#125; int width = left[i][j]; int area = width; for (int k = i - 1; k &gt;= 0; k--) &#123; width = Math.min(width, left[k][j]); area = Math.max(area, (i - k + 1) * width); &#125; ret = Math.max(ret, area); &#125; &#125; return ret; &#125; 84LargestRectangleInHistogramCV 答案 遍历高，采用单调栈，拿到左右边界 1234567891011121314151617181920212223242526272829public int largestRectangleArea(int[] heights) &#123; int n = heights.length; int[] left = new int[n]; int[] right = new int[n]; Stack&lt;Integer&gt; mono_stack = new Stack&lt;Integer&gt;(); for (int i = 0; i &lt; n; ++i) &#123; while (!mono_stack.isEmpty() &amp;&amp; heights[mono_stack.peek()] &gt;= heights[i]) &#123; mono_stack.pop(); &#125; left[i] = (mono_stack.isEmpty() ? -1 : mono_stack.peek()); mono_stack.push(i); &#125; mono_stack.clear(); for (int i = n - 1; i &gt;= 0; --i) &#123; while (!mono_stack.isEmpty() &amp;&amp; heights[mono_stack.peek()] &gt;= heights[i]) &#123; mono_stack.pop(); &#125; right[i] = (mono_stack.isEmpty() ? n : mono_stack.peek()); mono_stack.push(i); &#125; int ans = 0; for (int i = 0; i &lt; n; ++i) &#123; ans = Math.max(ans, (right[i] - left[i] - 1) * heights[i]); &#125; return ans;&#125; 188BestTimeToBuyAndSellStockIv( H )买卖股票的最佳时机 IV 淦，做了 中等的买卖股票，没有限制买卖次数，这道题有限制买卖次数，还是做不出来呜呜呜。。。 ！！！注意 buy 数组是进行恰好 j 笔交易，并且当前手上持有一支股票，这种情况下的最大利润 sell 表示恰好进行 j 笔交易，并且当前手上不持有股票，这种情况下的最大利润 1234567891011121314151617181920212223242526public int maxProfit(int k, int[] prices) &#123; if (prices.length == 0) &#123; return 0; &#125; int n = prices.length; k = Math.min(k, n / 2); int[][] buy = new int[n][k + 1]; int[][] sell = new int[n][k + 1]; buy[0][0] = -prices[0]; sell[0][0] = 0; for (int i = 1; i &lt;= k; ++i) &#123; buy[0][i] = sell[0][i] = Integer.MIN_VALUE / 2; &#125; for (int i = 1; i &lt; n; ++i) &#123; buy[i][0] = Math.max(buy[i - 1][0], sell[i - 1][0] - prices[i]); for (int j = 1; j &lt;= k; ++j) &#123; buy[i][j] = Math.max(buy[i - 1][j], sell[i - 1][j] - prices[i]); sell[i][j] = Math.max(sell[i - 1][j], buy[i - 1][j - 1] + prices[i]); &#125; &#125; return Arrays.stream(sell[n - 1]).max().getAsInt();&#125; 简化： 1234567891011121314151617181920212223242526public int maxProfit(int k, int[] prices) &#123; if (prices.length == 0) &#123; return 0; &#125; int n = prices.length; k = Math.min(k, n / 2); int[] buy = new int[k + 1]; int[] sell = new int[k + 1]; buy[0] = -prices[0]; sell[0] = 0; for (int i = 1; i &lt;= k; ++i) &#123; buy[i] = sell[i] = Integer.MIN_VALUE / 2; &#125; for (int i = 1; i &lt; n; ++i) &#123; buy[0] = Math.max(buy[0], sell[0] - prices[i]); for (int j = 1; j &lt;= k; ++j) &#123; buy[j] = Math.max(buy[j], sell[j] - prices[i]); sell[j] = Math.max(sell[j], buy[j - 1] + prices[i]); &#125; &#125; return Arrays.stream(sell).max().getAsInt();&#125; 121BestTimeToBuyAndSellStock( E )每次看看这个价格是不是最低值，如果是那就替换，如果不是那就和把自己当成卖出的价格，看看利润有没有最大利润大 1234567891011public int maxProfit(int[] prices) &#123; int maxGot = 0, min = Integer.MAX_VALUE; for (int i = 0; i &lt; prices.length; i++) &#123; int now = prices[i]; if (now &lt; min) min = now; else if (now - min &gt; maxGot) maxGot = now - min; &#125; return maxGot;&#125; 330PatchingArray( H )按要求补齐数组 不会。。。 对于任意 1 ≤ y &lt; x，y 已经被覆盖，x 在数组中，因此 y + x 也被覆盖，区间 [x + 1,2x - 1]（即区间 [1,x - 1][1,x − 1] 内的每个数字加上 x 之后得到的区间）内的所有数字也被覆盖，由此可得区间 [1,2x - 1] 内的所有数字都被覆盖 每次找到未被数组 nums 覆盖的最小的整数 x，在数组中补充 x，然后寻找下一个未被覆盖的最小的整数，重复上述步骤直到区间 [1,n] 中的所有数字都被覆盖 123456789101112131415public int minPatches(int[] nums, int n) &#123; int res = 0; long x = 1; int length = nums.length, index = 0; while (x &lt;= n) &#123; if (index &lt; length &amp;&amp; nums[index] &lt;= x) &#123; x += nums[index]; index++; &#125; else &#123; x *= 2; res++; &#125; &#125; return res;&#125; 239SlidingWindowMaximum( H )滑动窗口最大值 我的做法是最大堆，但是超时了。。。 官方 第一个题解也是最大堆，还有其他更“高级”的解法 123456789101112131415161718192021222324252627282930313233343536373839public int[] maxSlidingWindow(int[] nums, int k) &#123; int n = nums.length; PriorityQueue&lt;int[]&gt; pq = new PriorityQueue&lt;int[]&gt;(new Comparator&lt;int[]&gt;() &#123; public int compare(int[] pair1, int[] pair2) &#123; return pair1[0] != pair2[0] ? pair2[0] - pair1[0] : pair2[1] - pair1[1]; &#125; &#125;); for (int i = 0; i &lt; k; ++i) &#123; pq.offer(new int[]&#123;nums[i], i&#125;); &#125; int[] ans = new int[n - k + 1]; ans[0] = pq.peek()[0]; for (int i = k; i &lt; n; ++i) &#123; pq.offer(new int[]&#123;nums[i], i&#125;); while (pq.peek()[1] &lt;= i - k) &#123; pq.poll(); &#125; ans[i - k + 1] = pq.peek()[0]; &#125; return ans; // 我的最大堆超时了 //PriorityQueue&lt;Integer&gt; maxHeap = new PriorityQueue&lt;&gt;((a, b) -&gt; b - a); // //int[] res = new int[nums.length - k + 1]; // //for (int i = 0; i &lt; k; i++) &#123; // maxHeap.add(nums[i]); //&#125; //res[0] = maxHeap.peek(); // //for (int i = k, j = 1; i &lt; nums.length; i++, j++) &#123; // maxHeap.remove(nums[j - 1]); // maxHeap.add(nums[i]); // res[j] = maxHeap.peek(); //&#125; // //return res;&#125; 509FibonacciNumber( E )斐波那契数 直接动态规划 1202SmallestStringWithSwaps( M )交换字符串中的元素 并查集！！！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586class Solution &#123; public String smallestStringWithSwaps(String s, List&lt;List&lt;Integer&gt;&gt; pairs) &#123; if (pairs.size() == 0) &#123; return s; &#125; // 第 1 步：将任意交换的结点对输入并查集 int len = s.length(); UnionFind unionFind = new UnionFind(len); for (List&lt;Integer&gt; pair : pairs) &#123; int index1 = pair.get(0); int index2 = pair.get(1); unionFind.union(index1, index2); &#125; // 第 2 步：构建映射关系 char[] charArray = s.toCharArray(); // key：连通分量的代表元，value：同一个连通分量的字符集合（保存在一个优先队列中） Map&lt;Integer, PriorityQueue&lt;Character&gt;&gt; hashMap = new HashMap&lt;&gt;(len); for (int i = 0; i &lt; len; i++) &#123; int root = unionFind.find(i); // if (hashMap.containsKey(root)) &#123; // hashMap.get(root).offer(charArray[i]); // &#125; else &#123; // PriorityQueue&lt;Character&gt; minHeap = new PriorityQueue&lt;&gt;(); // minHeap.offer(charArray[i]); // hashMap.put(root, minHeap); // &#125; // 上面六行代码等价于下面一行代码，JDK 1.8 以及以后支持下面的写法 hashMap.computeIfAbsent(root, key -&gt; new PriorityQueue&lt;&gt;()).offer(charArray[i]); &#125; // 第 3 步：重组字符串 StringBuilder stringBuilder = new StringBuilder(); for (int i = 0; i &lt; len; i++) &#123; int root = unionFind.find(i); stringBuilder.append(hashMap.get(root).poll()); &#125; return stringBuilder.toString(); &#125; private class UnionFind &#123; private int[] parent; /** * 以 i 为根结点的子树的高度（引入了路径压缩以后该定义并不准确） */ private int[] rank; public UnionFind(int n) &#123; this.parent = new int[n]; this.rank = new int[n]; for (int i = 0; i &lt; n; i++) &#123; this.parent[i] = i; this.rank[i] = 1; &#125; &#125; public void union(int x, int y) &#123; int rootX = find(x); int rootY = find(y); if (rootX == rootY) &#123; return; &#125; if (rank[rootX] == rank[rootY]) &#123; parent[rootX] = rootY; // 此时以 rootY 为根结点的树的高度仅加了 1 rank[rootY]++; &#125; else if (rank[rootX] &lt; rank[rootY]) &#123; parent[rootX] = rootY; // 此时以 rootY 为根结点的树的高度不变 &#125; else &#123; // 同理，此时以 rootX 为根结点的树的高度不变 parent[rootY] = rootX; &#125; &#125; public int find(int x) &#123; if (x != parent[x]) &#123; parent[x] = find(parent[x]); &#125; return parent[x]; &#125; &#125;&#125; 523ContinuousSubarraySum动归超时，数组过大 我的： 1234567891011121314public boolean checkSubarraySum(int[] nums, int k) &#123; int[] cav = new int[nums.length]; for (int i = 0; i &lt; nums.length; i++) &#123; cav[i] = nums[i]; &#125; for (int count = 2; count &lt;= nums.length; count++) &#123; for (int i = 0; i + count - 1 &lt; nums.length; i++) &#123; cav[i] += nums[i + count - 1]; if (cav[i] % k == 0) return true; &#125; &#125; return false;&#125; 答案：同余定理 。。。 123456789101112131415161718192021public boolean checkSubarraySum(int[] nums, int k) &#123; int m = nums.length; if (m &lt; 2) &#123; return false; &#125; Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); map.put(0, -1); int remainder = 0; for (int i = 0; i &lt; m; i++) &#123; remainder = (remainder + nums[i]) % k; if (map.containsKey(remainder)) &#123; int prevIndex = map.get(remainder); if (i - prevIndex &gt;= 2) &#123; return true; &#125; &#125; else &#123; map.put(remainder, i); &#125; &#125; return false;&#125; 没想到，暴力还更快： 123456789101112131415161718192021222324public boolean checkSubarraySum(int[] nums, int k) &#123; // 当出现两个连续的0时，直接返回true，因为 0 % k = 0 for (int i = 0; i &lt; nums.length - 1; i++) &#123; if (nums[i] == 0 &amp;&amp; nums[i + 1] == 0) &#123; return true; &#125; &#125; // 其中i为左端点，j为右端点，遍历每种情况 for (int i = 0; i &lt; nums.length; i++) &#123; int sum = nums[i]; for (int j = i + 1; j &lt; nums.length; j++) &#123; sum += nums[j]; if (sum % k == 0) &#123; return true; &#125; &#125; // 加到一起之后发现都没k大，后面的也不会再比k大了，跳过 if (sum &lt; k) &#123; break; &#125; &#125; return false;&#125; 剑指 Offer15二进制中1的个数123456789public int hammingWeight(int n) &#123; int res = 0; while (n != 0)&#123; res += (n &amp; 1); n &gt;&gt;&gt;= 1; &#125; return res;&#125; 17打印从1到最大的n位数考虑大数，用 String 存放 递归生成 具体解释：LeetCode 评论 1234567891011121314151617181920212223242526StringBuilder res;int nine = 0, count = 0, start, n;char[] num, loop = &#123;&#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;, &#x27;8&#x27;, &#x27;9&#x27;&#125;;public String printNumbers(int n) &#123; this.n = n; res = new StringBuilder(); num = new char[n]; start = n - 1; dfs(0); res.deleteCharAt(res.length() - 1); return res.toString();&#125;void dfs(int x) &#123; if(x == n) &#123; String s = String.valueOf(num).substring(start); if(!s.equals(&quot;0&quot;)) res.append(s + &quot;,&quot;); if(n - start == nine) start--; return; &#125; for(char i : loop) &#123; if(i == &#x27;9&#x27;) nine++; num[x] = i; dfs(x + 1); &#125; nine--;&#125; 21调整数组顺序使奇数位于偶数前面我用了三种方法，觉得最后一种最装逼，但是时间只击败了 30%，看了评论，可能是数据量少的原因 搞个 list，偶数加后面，奇数加前面 搞个数组，两个指针，奇数放前面，左指针++，偶数放后面，右指针– 两个指针，分别从左右开始，当左偶右奇，交换 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public int[] exchange(int[] nums) &#123; // first //LinkedList&lt;Integer&gt; list = new LinkedList&lt;&gt;(); //for (int num : nums) &#123; // if (num % 2 == 0) // list.addLast(num); // else // list.addFirst(num); //&#125; //int[] res = new int[nums.length]; //for (int i = 0; i &lt; nums.length; i++) &#123; // res[i] = list.removeFirst(); //&#125; //return res; // second //int length = nums.length; //int[] res = new int[length]; //int left = 0, right = length - 1; // //for (int i = 0; i &lt; length; i++) &#123; // if (nums[i] % 2 != 0) // res[left++] = nums[i]; // else // res[right--] = nums[i]; //&#125; // //return res; int length = nums.length; int left = 0, right = length - 1; while (left &lt; right)&#123; // 左偶右奇 if (nums[left] % 2 == 0 &amp;&amp; nums[right] % 2 != 0)&#123; int temp = nums[left]; nums[left] = nums[right]; nums[right] = temp; left++; right--; &#125;else if (nums[left] % 2 != 0 &amp;&amp; nums[right] % 2 == 0)&#123; // 左奇右偶 left++; right--; &#125;else if (nums[left] % 2 != 0)&#123; // 左奇右奇 left++; &#125;else if (nums[right] % 2 == 0)&#123; // 左偶右偶 right--; &#125; &#125; return nums;&#125; 22链表中倒数第k个节点先让 temp &#x3D; head 往后跑 k 个，如果空，就直接返回 head 如果不空，就开始迭代，temp 每往后走一个，head 就往后走一个，直到 temp 为空，这时候 head 就是结果 123456789101112131415161718192021222324public class ListNode &#123; int val; ListNode next; ListNode(int x) &#123; val = x; &#125;&#125;public ListNode getKthFromEnd(ListNode head, int k) &#123; int i = k; ListNode temp = head; ListNode res = head; while (i != 0)&#123; temp = temp.next; i--; &#125; if (temp == null) return res; while (temp != null)&#123; temp = temp.next; res = res.next; &#125; return res;&#125; 24反转链表指针太多，脑子差点转不过来 要记录三个，一个之前的，一个现在的，一个 next 从第二个开始遍历，遍历到的是 现在的 记录 next，替换 现在的 next 为 之前的，把 现在的 设为 之前的 再把 next 赋值给 现在的 继续循环 只可意会不可言传… 12345678910111213141516171819202122232425public class ListNode &#123; int val; ListNode next; ListNode(int x) &#123; val = x; &#125;&#125;public ListNode reverseList(ListNode head) &#123; if (head == null) return null; ListNode pre = head; head = head.next; pre.next = null; while (head != null)&#123; ListNode next = head.next; head.next = pre; pre = head; head = next; &#125; return pre;&#125; 25合并两个排序的链表双指针 注意是引用！！！ 1234567891011121314151617181920212223242526272829303132public class ListNode &#123; int val; ListNode next; ListNode(int x) &#123; val = x; &#125;&#125;class Solution &#123; private ListNode root = new ListNode(0); private ListNode now = root; public ListNode mergeTwoLists(ListNode l1, ListNode l2) &#123; while (l1 != null &amp;&amp; l2 != null)&#123; if (l1.val &gt; l2.val)&#123; now.next = l2; l2 = l2.next; &#125;else &#123; now.next = l1; l1 = l1.next; &#125; now = now.next; &#125; if (l1 == null) now.next = l2; if (l2 == null) now.next = l1; return root.next; &#125;&#125; 27二叉树的镜像没啥说的，直接递归交换左右 1234567891011121314151617181920212223public class TreeNode &#123; int val; TreeNode left; TreeNode right; TreeNode(int x) &#123; val = x; &#125;&#125;class Solution &#123; public TreeNode mirrorTree(TreeNode root) &#123; // 递归终点 if (root == null) return null; // 交换左右 TreeNode left = root.left; root.left = mirrorTree(root.right); root.right = mirrorTree(left); return root; &#125;&#125; 28对称的二叉树想歪了，想不出来 12345678910111213141516171819public class TreeNode &#123; int val; TreeNode left; TreeNode right; TreeNode(int x) &#123; val = x; &#125;&#125;class Solution &#123; public boolean isSymmetric(TreeNode root) &#123; return root == null ? true : recur(root.left, root.right); &#125; boolean recur(TreeNode L, TreeNode R) &#123; if(L == null &amp;&amp; R == null) return true; if(L == null || R == null || L.val != R.val) return false; return recur(L.left, R.right) &amp;&amp; recur(L.right, R.left); &#125;&#125; 14- I cuttingRope动态规划 用 dp[i] 表示 i 分成 2 个或以上数的最大乘积 j 表示第一个乘数 当 i ≥ 2 时，假设对正整数 i 拆分出的第一个正整数是 j（1 ≤ j &lt; i），则有以下两种方案： 将 i 拆分成 j 和 i − j 的和，且 i − j 不再拆分成多个正整数，此时的乘积是 j × (i − j) 将 i 拆分成 j 和 i − j 的和，且 i − j 继续拆分成多个正整数，此时的乘积是 j × dp[i−j] 当到下一个 i 时，就让 j 从 1 开始，比较 j * ( i - j ) 和 j * dp[i - j] 哪个大，再和之前记录的 dp[i] 比较，直到 j 到达 i 的一半( 这里的一半因为：比如5 &#x3D; 2 + 3，而 j 表示第一个乘数，如果 j 遍历到 3，那就是 3 + 2，重复了 ) 123456789public int cuttingRope(int n) &#123; int[] dp = new int[n + 1]; for (int i = 2; i &lt;= n; i++) &#123; for (int j = 1; j &lt; i / 2 + 1; j++) &#123; dp[i]= Math.max(dp[i], Math.max(j * (i - j), j * dp[i - j])); &#125; &#125; return dp[n];&#125; 16数值的整数次方 1234567891011121314151617public double myPow(double x, int n) &#123; if (x == 0) return 0; long b = n; double res = 1.0; if (b &lt; 0) &#123; x = 1 / x; b = -b; &#125; while (b &gt; 0) &#123; if ((b &amp; 1) == 1) res *= x; x *= x; b &gt;&gt;= 1; &#125; return res;&#125; 18删除链表的节点1234567891011121314151617public ListNode deleteNode(ListNode head, int val) &#123; if (head.val == val) return head.next; ListNode temp = head; ListNode pre = head; while (temp != null)&#123; if (temp.val == val)&#123; pre.next = temp.next; &#125; pre = temp; temp = temp.next; &#125; return head;&#125; 26树的子结构没做出来… 解析 讲的很明白 12345678public boolean isSubStructure(TreeNode A, TreeNode B) &#123; return (A != null &amp;&amp; B != null) &amp;&amp; (recur(A, B) || isSubStructure(A.left, B) || isSubStructure(A.right, B));&#125;boolean recur(TreeNode A, TreeNode B) &#123; if(B == null) return true; if(A == null || A.val != B.val) return false; return recur(A.left, B.left) &amp;&amp; recur(A.right, B.right);&#125; 29顺时针打印矩阵 解析 12345678910111213141516171819202122232425262728293031public int[] spiralOrder(int[][] matrix) &#123; if (matrix.length == 0) return new int[0]; int left = 0, right = matrix[0].length - 1, top = 0, bottom = matrix.length - 1, res_i = 0; int[] res = new int[(right + 1) * (bottom + 1)]; while (true) &#123; for (int i = left; i &lt;= right; i++) res[res_i++] = matrix[top][i]; // left to right. if (++top &gt; bottom) break; for (int i = top; i &lt;= bottom; i++) res[res_i++] = matrix[i][right]; // top to bottom. if (left &gt; --right) break; for (int i = right; i &gt;= left; i--) res[res_i++] = matrix[bottom][i]; // right to left. if (top &gt; --bottom) break; for (int i = bottom; i &gt;= top; i--) res[res_i++] = matrix[i][left]; // bottom to top. if (++left &gt; right) break; &#125; return res;&#125; 30包含min函数的栈辅助栈存非严格递减的元素 1234567891011121314151617181920212223242526class MinStack &#123; /** * initialize your data structure here. */ Stack&lt;Integer&gt; A, B; public MinStack() &#123; A = new Stack&lt;&gt;(); B = new Stack&lt;&gt;(); &#125; public void push(int x) &#123; A.add(x); if(B.empty() || B.peek() &gt;= x) B.add(x); &#125; public void pop() &#123; if(A.pop().equals(B.peek())) B.pop(); &#125; public int top() &#123; return A.peek(); &#125; public int min() &#123; return B.peek(); &#125;&#125; 31栈的压入、弹出序列123456789101112public boolean validateStackSequences(int[] pushed, int[] popped) &#123; Deque&lt;Integer&gt; stack = new LinkedList&lt;&gt;(); int i = 0; for (int num : pushed) &#123; stack.push(num); // num 入栈 while (!stack.isEmpty() &amp;&amp; stack.peek() == popped[i]) &#123; // 循环判断与出栈 stack.pop(); i++; &#125; &#125; return stack.isEmpty();&#125; 32-I从上到下打印二叉树层序遍历，因为不用按层来存，所以比下面的一题简单 1234567891011121314151617181920212223242526272829public int[] levelOrder(TreeNode root) &#123; if (root == null)&#123; return new int[0]; &#125; List&lt;TreeNode&gt; order = new ArrayList&lt;&gt;(); int count = 1; order.add(root); for (int i = 0; i &lt; order.size(); i++) &#123; TreeNode now = order.get(i); if (now.left != null)&#123; order.add(now.left); count++; &#125; if (now.right != null)&#123; order.add(now.right); count++; &#125; &#125; int[] res = new int[count]; int i = 0; for (TreeNode node : order) &#123; res[i++] = node.val; &#125; return res;&#125; 32-II从上到下打印二叉树 II要按层来存，即 List&lt;List&lt;Integer&gt;&gt; 123456789101112131415161718192021222324public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; List&lt;List&lt;Integer&gt;&gt; res = new LinkedList&lt;&gt;(); if (root == null)&#123; return res; &#125; Deque&lt;TreeNode&gt; order = new LinkedList&lt;&gt;(); order.addLast(root); while (!order.isEmpty())&#123; LinkedList&lt;Integer&gt; line = new LinkedList&lt;&gt;(); // 要记录每层的数量 for (int i = order.size(); i &gt; 0; i--)&#123; TreeNode now = order.poll(); if (now.left != null) order.addLast(now.left); if (now.right != null) order.addLast(now.right); line.addLast(now.val); &#125; res.add(line); &#125; return res;&#125; 32-III从上到下打印二叉树 III这题在上面的基础上添加了蛇形打印 只要多一个判断 flag 即可 123456789101112131415161718192021222324252627282930313233public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; List&lt;List&lt;Integer&gt;&gt; res = new LinkedList&lt;&gt;(); if (root == null) return res; Deque&lt;TreeNode&gt; order = new LinkedList&lt;&gt;(); order.addLast(root); // 正向打印 boolean flag = true; while (!order.isEmpty())&#123; LinkedList&lt;Integer&gt; line = new LinkedList&lt;&gt;(); for (int i = order.size(); i &gt; 0; i--)&#123; TreeNode now = order.poll(); if (now.left != null)&#123; order.addLast(now.left); &#125; if (now.right != null)&#123; order.addLast(now.right); &#125; if (flag)&#123; line.addLast(now.val); &#125;else &#123; line.addFirst(now.val); &#125; &#125; // 改变方向 flag = !flag; res.add(line); &#125; return res;&#125; 33二叉搜索树的后序遍历序列后序遍历，最后一个是根节点 递归，终点是数组只剩下最多两个数 找到左子树和右子树，继续递归分治 12345678910111213141516public boolean verifyPostorder(int[] postorder) &#123; return myVerifyPostorder(postorder, 0, postorder.length - 1);&#125;private boolean myVerifyPostorder(int[] postorder, int start, int end)&#123; // 任意两个数都可构成后序 if (start &gt;= end - 1) return true; int temp = start; while(postorder[temp] &lt; postorder[end]) temp++; // 找到右子树第一个数 int middle = temp; // 因为右子树都大于根，所以看看根前面一个是不是大于根 while(postorder[temp] &gt; postorder[end]) temp++; // 如果都大于，那就继续，小于意味着这不是合法的二叉搜索树 return temp == end &amp;&amp; myVerifyPostorder(postorder, start, middle - 1) &amp;&amp; myVerifyPostorder(postorder, middle, end - 1);&#125; 34二叉树中和为某一值的路径1234567891011121314151617181920class Solution &#123; LinkedList&lt;List&lt;Integer&gt;&gt; res = new LinkedList&lt;&gt;(); LinkedList&lt;Integer&gt; path = new LinkedList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root, int sum) &#123; recur(root, sum); return res; &#125; void recur(TreeNode root, int tar) &#123; if (root == null) return; path.add(root.val); tar -= root.val; if (tar == 0 &amp;&amp; root.left == null &amp;&amp; root.right == null) res.add(new LinkedList(path)); recur(root.left, tar); recur(root.right, tar); path.removeLast(); &#125;&#125; 35复杂链表的复制自己做，也是用哈希表，但用的是递归，结果直接栈溢出。。。 1234567891011121314151617181920class Solution &#123; public Node copyRandomList(Node head) &#123; HashMap&lt;Node, Node&gt; map = new HashMap&lt;&gt;(); Node cur = head; //复制结点值 while (cur != null) &#123; map.put(cur, new Node(cur.val)); cur = cur.next; &#125; //复制结点指向 cur = head; while (cur != null) &#123; map.get(cur).next = map.get(cur.next); map.get(cur).random = map.get(cur.random); cur = cur.next; &#125; //返回复制的链表 return map.get(head); &#125;&#125; 36二叉搜索树与双向链表想到了中序遍历，但是没想到怎么转换引用 题解 12345678910111213141516171819202122232425262728class Solution &#123; Node pre, head; public Node treeToDoublyList(Node root) &#123; if (root == null) return null; dfs(root); head.left = pre; pre.right = head; return head; &#125; void dfs(Node cur) &#123; // 终止 if (cur == null) return; // 中序遍历，到底就是最左边的 head dfs(cur.left); if (pre != null) pre.right = cur; else // 如果 pre 为空，即此节点为 head head = cur; // 把此节点设为 pre cur.left = pre; pre = cur; dfs(cur.right); &#125;&#125; 37序列化二叉树12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Codec &#123; // Encodes a tree to a single string. public String serialize(TreeNode root) &#123; if (root == null) &#123; return &quot;[]&quot;; &#125; StringBuilder res = new StringBuilder(&quot;[&quot;); Deque&lt;TreeNode&gt; list = new LinkedList&lt;&gt;(); list.addLast(root); while (!list.isEmpty()) &#123; TreeNode now = list.poll(); if (now != null)&#123; list.addLast(now.left); list.addLast(now.right); res.append(now.val).append(&quot;,&quot;); &#125; else &#123; res.append(&quot;null,&quot;); &#125; &#125; res.deleteCharAt(res.length() - 1).append(&quot;]&quot;); return res.toString(); &#125; // Decodes your encoded data to tree. public TreeNode deserialize(String data) &#123; if (data.equals(&quot;[]&quot;))&#123; return null; &#125; String[] myData = data.substring(1, data.length() - 1).split(&quot;,&quot;); TreeNode root = new TreeNode(Integer.parseInt(myData[0])); Deque&lt;TreeNode&gt; list = new LinkedList&lt;&gt;(); list.addLast(root); int i = 1; while (!list.isEmpty())&#123; TreeNode now = list.poll(); if (!myData[i].equals(&quot;null&quot;))&#123; now.left = new TreeNode(Integer.parseInt(myData[i])); list.addLast(now.left); &#125; i++; if (!myData[i].equals(&quot;null&quot;))&#123; now.right = new TreeNode(Integer.parseInt(myData[i])); list.addLast(now.right); &#125; i++; &#125; return root; &#125;&#125; 38字符串的排列使用回溯，采用交换 12345678910111213141516171819202122232425262728293031class Solution &#123; List&lt;String&gt; res = new LinkedList&lt;&gt;(); char[] c; public String[] permutation(String s) &#123; c = s.toCharArray(); dfs(0); return res.toArray(new String[res.size()]); &#125; void dfs(int x) &#123; if (x == c.length - 1) &#123; res.add(String.valueOf(c)); // 添加排列方案 return; &#125; HashSet&lt;Character&gt; set = new HashSet&lt;&gt;(); for (int i = x; i &lt; c.length; i++) &#123; if (set.contains(c[i])) continue; // 重复，因此剪枝 set.add(c[i]); swap(i, x); // 交换，将 c[i] 固定在第 x 位 dfs(x + 1); // 开启固定第 x + 1 位字符 swap(i, x); // 恢复交换 &#125; &#125; void swap(int a, int b) &#123; char tmp = c[a]; c[a] = c[b]; c[b] = tmp; &#125;&#125; 39数组中出现次数超过一半的数字12345678910111213141516171819202122public int majorityElement(int[] nums) &#123; // HashMap 版本 //Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); //int length = nums.length / 2; //for(int num : nums) &#123; // map.put(num, map.getOrDefault(num, 0) + 1); // if(map.get(num) &gt; length) &#123; // return num; // &#125; //&#125; //return 0; // 数组排序版本 //Arrays.sort(nums); //return nums[nums.length / 2]; //摩尔投票法 int x = 0, votes = 0; for(int num : nums)&#123; if(votes == 0) x = num; votes += num == x ? 1 : -1; &#125; return x;&#125; 40最小的k个数(TopK)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172class Solution &#123; //public int[] getLeastNumbers(int[] arr, int k) &#123; //Arrays.sort(arr); //int[] res = new int[k]; //for (int i = 0; i &lt; k; i++) &#123; // res[i] = arr[i]; //&#125; //return res; //int[] res = new int[k]; //PriorityQueue&lt;Integer&gt; stack = new PriorityQueue&lt;&gt;(); //for (int i : arr) &#123; // stack.add(i); //&#125; //for (int i = 0; i &lt; k; i++) &#123; // res[i] = stack.poll(); //&#125; //return res; //&#125; public int[] getLeastNumbers(int[] arr, int k) &#123; randomizedSelected(arr, 0, arr.length - 1, k); int[] vec = new int[k]; for (int i = 0; i &lt; k; ++i) &#123; vec[i] = arr[i]; &#125; return vec; &#125; public void randomizedSelected(int[] arr, int l, int r, int k) &#123; if (l &gt;= r) &#123; return; &#125; int pos = randomizedPartition(arr, l, r); int num = pos - l + 1; if (k == num) &#123; return; &#125; else if (k &lt; num) &#123; randomizedSelected(arr, l, pos - 1, k); &#125; else &#123; randomizedSelected(arr, pos + 1, r, k - num); &#125; &#125; // 基于随机的划分 public int randomizedPartition(int[] nums, int l, int r) &#123; int i = new Random().nextInt(r - l + 1) + l; swap(nums, r, i); return partition(nums, l, r); &#125; public int partition(int[] nums, int l, int r) &#123; int pivot = nums[r]; int i = l - 1; for (int j = l; j &lt;= r - 1; ++j) &#123; if (nums[j] &lt;= pivot) &#123; i = i + 1; swap(nums, i, j); &#125; &#125; swap(nums, i + 1, r); return i + 1; &#125; private void swap(int[] nums, int i, int j) &#123; int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; &#125;&#125; 41数据流中的中位数1234567891011121314151617181920212223242526class MedianFinder &#123; PriorityQueue&lt;Integer&gt; right; PriorityQueue&lt;Integer&gt; left; /** * initialize your data structure here. */ public MedianFinder() &#123; right = new PriorityQueue&lt;&gt;(); left = new PriorityQueue&lt;&gt;((a, b) -&gt; b - a); &#125; public void addNum(int num) &#123; if (left.size() == right.size())&#123; left.add(num); right.add(left.poll()); &#125;else &#123; right.add(num); left.add(right.poll()); &#125; &#125; public double findMedian() &#123; return left.size() == right.size() ? (left.peek() + right.peek()) / 2.0 : right.peek(); &#125;&#125; 42连续子数组的最大和123456789101112131415161718public int maxSubArray(int[] nums) &#123; //int res = nums[0]; //for (int i = 1; i &lt; nums.length; i++) &#123; // nums[i] += Math.max(nums[i - 1], 0); // res = Math.max(res, nums[i]); //&#125; //return res; int max = nums[0]; int former = 0;//用于记录dp[i-1]的值，对于dp[0]而言，其前面的dp[-1]=0 int cur = nums[0];//用于记录dp[i]的值 for (int num : nums) &#123; cur = num; if (former &gt; 0) cur += former; if (cur &gt; max) max = cur; former = cur; &#125; return max;&#125; 45把数组排成最小的数123456789101112131415161718192021222324252627282930313233public String minNumber(int[] nums) &#123; int length = nums.length; String[] strs = new String[length]; StringBuilder builder = new StringBuilder(); for (int i = 0; i &lt; length; i++) &#123; strs[i] = String.valueOf(nums[i]); &#125; myQuickSort(strs, 0, length - 1); for (String str : strs) &#123; builder.append(str); &#125; return builder.toString();&#125;public void myQuickSort(String[] strs, int left, int right) &#123; if (left &gt;= right) return; int i = left, j = right; String temp = strs[i]; while (i &lt; j) &#123; while ((strs[j] + strs[left]).compareTo(strs[left] + strs[j]) &gt;= 0 &amp;&amp; i &lt; j) j--; while ((strs[i] + strs[left]).compareTo(strs[left] + strs[i]) &lt;= 0 &amp;&amp; i &lt; j) i++; temp = strs[i]; strs[i] = strs[j]; strs[j] = temp; &#125; strs[i] = strs[left]; strs[left] = temp; myQuickSort(strs, left, i - 1); myQuickSort(strs, i + 1, right);&#125; 46把数字翻译成字符串DP + 空间优化 解析 1234567891011121314151617181920public int translateNum(int num) &#123; String s = String.valueOf(num); // x1 x2 x3...xi // dp[i] 表示以xi结尾的翻译数量 // dp[i] = dp[i - 1] + dp[i - 2], 前两个组合在字母表里 // dp[i] = dp[i - 1], 前两个组合不在字母表里 // dp[0] = dp[1] = 1, 即无数字和第一个数组的翻译数量为 1 // a:dp[i], b:dp[i - 1] int a = 1, b = 1; for (int i = 2; i &lt;= s.length(); i++) &#123; String tmp = s.substring(i - 2, i); int c = tmp.compareTo(&quot;10&quot;) &gt;= 0 &amp;&amp; tmp.compareTo(&quot;25&quot;) &lt;= 0 ? a + b : a; b = a; a = c; &#125; return a;&#125; 47礼物的最大价值DP，有手就行 可把顶边和左边的先算一遍，就减少了 &gt; 0 的判断 123456789101112131415161718public int maxValue(int[][] grid) &#123; int row = grid.length; // 行 int col = grid[0].length; // 列 for(int i = 0; i &lt; row; ++i)&#123; for(int j = 0; j &lt; col; ++j)&#123; int up = 0, left = 0; if(i &gt; 0)&#123; up = grid[i - 1][j]; &#125; if(j &gt; 0)&#123; left = grid[i][j - 1]; &#125; grid[i][j] = Math.max(grid[i][j] + left, grid[i][j] + up); &#125; &#125; return grid[row - 1][col - 1];&#125; 48最长不含重复字符的子字符串12345678910111213141516public int lengthOfLongestSubstring(String s) &#123; int r = -1, res = 0; HashSet&lt;Character&gt; set = new HashSet&lt;&gt;(); int length = s.length(); for (int l = 0; l &lt; length; l++) &#123; if (l != 0) set.remove(s.charAt(l - 1)); while (r + 1 &lt; length &amp;&amp; !set.contains(s.charAt(r + 1)))&#123; set.add(s.charAt(r + 1)); r++; &#125; res = Math.max(res, r - l + 1); &#125; return res;&#125; 50第一个只出现一次的字符123456789101112131415161718192021public char firstUniqChar(String s) &#123; //Map&lt;Character, Boolean&gt; dic = new LinkedHashMap&lt;&gt;(); //char[] sc = s.toCharArray(); //for (char c : sc) // dic.put(c, !dic.containsKey(c)); //for (Map.Entry&lt;Character, Boolean&gt; d : dic.entrySet()) &#123; // if (d.getValue()) return d.getKey(); //&#125; //return &#x27; &#x27;; int[] map = new int[26]; int length = s.length(); char[] ch = s.toCharArray(); for (int i = 0; i &lt; length; ++i) &#123; map[ch[i] - &#x27;a&#x27;]++; &#125; for (int i = 0; i &lt; length; ++i) &#123; if (map[ch[i] - &#x27;a&#x27;] == 1) return ch[i]; &#125; return &#x27; &#x27;;&#125; 51数组中的逆序对难。 题解 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788class Solution &#123; public int reversePairs(int[] nums) &#123; int length = nums.length; // 0 个 1 个的序列不存在逆序对 if (length &lt; 2) return 0; // 拷贝数组 int[] copy = new int[length]; for (int i = 0; i &lt; length; i++) &#123; copy[i] = nums[i]; &#125; // 存放排序元素 int[] tmp = new int[length]; return reversePairs(copy, 0, length - 1, tmp); &#125; /** * nums[left..right] 计算逆序对个数并排序 * * @param nums * @param left * @param right * @param tmp * @return */ private int reversePairs(int[] nums, int left, int right, int[] tmp) &#123; // 只有一个元素的时候，不存在逆序对，返回 0 if (left == right) return 0; // 分割点 int mid = left + (right - left) / 2; int leftPairs = reversePairs(nums, left, mid, tmp); int rightPairs = reversePairs(nums, mid + 1, right, tmp); // 如果两个序列已经有序，直接返回 if (nums[mid] &lt;= nums[mid + 1]) return leftPairs + rightPairs; int crossPairs = mergeAndCount(nums, left, mid, right, tmp); return leftPairs + rightPairs + crossPairs; &#125; /** * nums[left..mid] 有序, nums[mid + 1..right] 有序 * * @param nums * @param left * @param mid * @param right * @param tmp * @return */ private int mergeAndCount(int[] nums, int left, int mid, int right, int[] tmp) &#123; for (int i = left; i &lt;= right; i++) &#123; tmp[i] = nums[i]; &#125; int i = left; int j = mid + 1; int count = 0; for (int k = left; k &lt;= right; k++) &#123; if (i == mid + 1) &#123; nums[k] = tmp[j]; j++; &#125; else if (j == right + 1) &#123; nums[k] = tmp[i]; i++; &#125; else if (tmp[i] &lt;= tmp[j]) &#123; nums[k] = tmp[i]; i++; &#125; else &#123; nums[k] = tmp[j]; j++; // 计算逆序对个数 count += (mid - i + 1); &#125; &#125; return count; &#125;&#125; 52两个链表的第一个公共节点太渣了，暴力解法来着 精选解法太妙了 12345678910111213141516171819202122public ListNode getIntersectionNode(ListNode headA, ListNode headB) &#123; //HashSet&lt;ListNode&gt; set = new HashSet&lt;&gt;(); //while (headA != null)&#123; // set.add(headA); // headA = headA.next; //&#125; //while (headB != null)&#123; // if (set.contains(headB)) // return headB; // headB = headB.next; //&#125; //return null; ListNode ATmp = headA; ListNode BTmp = headB; while (ATmp != BTmp)&#123; ATmp = ATmp != null ? ATmp.next : headB; BTmp = BTmp != null ? BTmp.next : headA; &#125; return ATmp;&#125; 53-I在排序数组中查找数字 I12345678910111213141516171819202122class Solution &#123; public int search(int[] nums, int target) &#123; return helper(nums, target) - helper(nums, target - 1); &#125; /** * @param nums * @param tar * @return 右边界，开 */ int helper(int[] nums, int tar) &#123; int i = 0, j = nums.length - 1; while (i &lt;= j) &#123; int m = (i + j) / 2; if (nums[m] &lt;= tar) i = m + 1; else j = m - 1; &#125; return i; &#125;&#125; 53-II 0～n-1中缺失的数字1234567891011public int missingNumber(int[] nums) &#123; int i = 0, j = nums.length - 1; while (i &lt;= j) &#123; int m = (i + j) / 2; if (nums[m] == m) i = m + 1; else j = m - 1; &#125; return i;&#125; 54二叉搜索树的第k大节点123456789101112131415161718192021class Solution &#123; int res, k; public int kthLargest(TreeNode root, int k) &#123; this.k = k; myKthLargest(root); return res; &#125; private void myKthLargest(TreeNode root) &#123; if (root == null) return; myKthLargest(root.right); if (k == 0) return; if (--k == 0) res = root.val; myKthLargest(root.left); &#125;&#125; 55-I二叉树的深度123456789101112131415161718192021222324252627//public int maxDepth(TreeNode root) &#123;// return myMaxDepth(root, 1);//&#125;//private int myMaxDepth(TreeNode root, int depth)&#123;// if (root == null)// return depth - 1;// return Math.max(myMaxDepth(root.left, depth + 1), myMaxDepth(root.right, depth + 1));//&#125;// 层序遍历public int maxDepth(TreeNode root) &#123; if (root == null) return 0; List&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;() &#123;&#123; add(root); &#125;&#125;, tmp; int res = 0; while (!queue.isEmpty()) &#123; tmp = new LinkedList&lt;&gt;(); for (TreeNode node : queue) &#123; if (node.left != null) tmp.add(node.left); if (node.right != null) tmp.add(node.right); &#125; queue = tmp; res++; &#125; return res;&#125; 56-I数组中数字出现的次数 I这tm才是位运算。。。 12345678910111213141516171819public int[] singleNumbers(int[] nums) &#123; int ret = 0; for (int n : nums) &#123; ret ^= n; &#125; int div = 1; while ((div &amp; ret) == 0) &#123; div &lt;&lt;= 1; &#125; int a = 0, b = 0; for (int n : nums) &#123; if ((div &amp; n) != 0) &#123; a ^= n; &#125; else &#123; b ^= n; &#125; &#125; return new int[]&#123;a, b&#125;;&#125; 56-II数组中数字出现的次数 II12345678public int singleNumber(int[] nums) &#123; int ones = 0, twos = 0; for (int num : nums) &#123; ones = ones ^ num &amp; ~twos; twos = twos ^ num &amp; ~ones; &#125; return ones;&#125; 57 和为s的两个数字傻了，我就直接遍历 + 二分了，淦 优解：对撞双指针( 排序数组，可先考虑双指针 ) 题解 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Solution &#123; //public int[] twoSum(int[] nums, int target) &#123; // int length = nums.length; // for (int i = 0; i &lt; length; i++) &#123; // int now = nums[i]; // int next = target - now; // if (next &lt; now) // continue; // int next1 = searchNext(nums, i + 1, length - 1, next); // if (next1 != -1) // return new int[]&#123;now, next1&#125;; // &#125; // // return new int[0]; //&#125; //private int searchNext(int[] nums, int start, int end, int target)&#123; // if (nums[start] &gt; target) // return -1; // while (start &lt;= end)&#123; // int mid = (start + end) / 2; // if (nums[mid] == target) // return nums[mid]; // else if (nums[mid] &gt; target)&#123; // end = mid - 1; // &#125;else &#123; // start = mid + 1; // &#125; // &#125; // return -1; //&#125; // 对撞双指针 public int[] twoSum(int[] nums, int target) &#123; int i = 0, j = nums.length - 1; while (i &lt; j) &#123; int s = nums[i] + nums[j]; if (s &lt; target) i++; else if (s &gt; target) j--; else return new int[]&#123;nums[i], nums[j]&#125;; &#125; return new int[0]; &#125;&#125; 57-II 和为s的连续正数序列还是双指针，但不是对撞了 123456789101112131415161718192021public int[][] findContinuousSequence(int target) &#123; int start = 1, end = 2; LinkedList&lt;int[]&gt; res = new LinkedList&lt;&gt;(); while (start &lt; end)&#123; int sum = (start + end) * (end - start + 1) / 2; if (sum == target)&#123; int[] sub = new int[end - start + 1]; for (int i = 0; i &lt; (end - start + 1); i++)&#123; sub[i] = start + i; &#125; res.add(sub); start++; &#125;else if (sum &lt; target)&#123; end++; &#125;else &#123; start++; &#125; &#125; return res.toArray(new int[res.size()][]);&#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://kebabshellgithub.github.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"算法","slug":"算法","permalink":"https://kebabshellgithub.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"计算机网络","slug":"计算机网络","date":"2020-07-22T14:00:32.000Z","updated":"2023-04-06T11:06:55.042Z","comments":true,"path":"2020/07/22/计算机网络/","link":"","permalink":"https://kebabshellgithub.github.io/2020/07/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","excerpt":"","text":"以下多数来自《TCP&#x2F;IP 详解 卷1：协议》及《计算机网络 自顶向下方法》 TCP 那块很乱，看这篇 HTTPS 那块不知道说对了没有。。。 基本概念HTTP 或者 DNS 协议封包的时候，在其上层已经封装了 TCP 协议，TCP 协议封装中包含了对应的目的端口和源端口，TCP 之前又封装了 IP 协议，IP 协议中包含了源 IP 地址和目的 IP 地址，以此类推… 基本分层重点主要是 TCP&#x2F;IP 协议栈 TCP&#x2F;IP 协议体系的认知 物理层( 比特 bit ) 数据链路层( 帧 frame ) 以太网帧的格式 MTU 的概念 ARP 协议、RARP 协议( ARP 查询原理、ARP 缓存 ) 网络层( 数据报 datagram ) IP 分片：IP 首部格式，如 16 位分片标识、DF 不分片标志、MF 更多分片标志、13 位片偏移、8 位生存时间TTL、16 位首部校验和等等 IP 选路 大概是路由表 ICMP 协议，报文格式、报文的两大分类：查询和差错、2 种查询报文 + 5 种差错报文 传输层( 报文段 segment ) UDP 协议：特点 + 首部各个字段 TCP 协议：特点 + 首部字段 + 可靠机制 TCP 连接控制：三次握手、四次挥手、同时打开、同时关闭、半关闭 TCP 流量控制机制：滑动窗口、慢启动、拥塞避免、快速重传、快速恢复 TCP 超时重传机制：各种定时器( 4 个 ) 以上大部分隐藏封装于内核中 应用层( 报文 message ) DNS 协议：名字空间、DNS 指针查询( 反向查找或逆向解析 )基本原理、DNS 缓存 FTP 协议：两条连接(控制连接+数据连接)、两种工作模式( PASV + PORT )、各种 FTP 指令和响应码、FTP 断点续传、匿名 FTP HTTP 协议：报文格式(请求报文、响应报文、请求头各种字段、响应头各种字段)、HTTP 状态码 HTTPS 协议：https 的详细握手过程、摘要算法、数字签名、数字证书的原理和过程 DNSDNS 名称空间DNS 中使用的所有的名称集合构成了 DNS 名称空间( name space ) 这个名称空间和计算机系统的文件夹和文件类似，都是划分为层次且 大小写不敏感 的。整个 DNS 域结构称为 DNS 命名空间 域名结构是树状结构，树的最顶端代表根服务器，根的下一层就是由我们所熟知的 .com、.net、.cn 等通用域和 .cn、.uk 等国家域组成，称为顶级域。网上注册的域名基本都是二级域名，比如 http://baidu.com、http://taobao.com 等等二级域名，它们基本上是归企业和运维人员管理。接下来是三级或者四级域名 DNS 缓存一条域名的 DNS 记录会在本地有两种缓存：浏览器缓存 和 操作系统( OS )缓存 在浏览器中访问的时候，会优先访问浏览器缓存，如果未命中则访问 OS 缓存，最后再访问 DNS 服务器 DNS 记录会有一个 TTL OS 缓存会参考 TTL 值，但是不完全等于 TTL 值 而浏览器 DNS 缓存的时间跟 TTL 值无关，每种浏览器都使用一个固定值 缓存同时适用于成功的解析和不成功的解析( 称为否定缓存( negative caching )) 如果一个特定域名的请求无法返回一个记录，该事实也会被缓存 当一再请求不存在的域名时，就能帮助降低互联网流量 反向 DNS 查询 建议“每个可访问 Internet 的主机都应该有一个名称”，并且“对于每个 IP 地址，应该有一个匹配的 PTR 记录”，但这不是 Internet 标准的要求，并非所有 IP 地址都有反向条目 DNS 服务器里有 两个区域，即“正向查找区域”和“反向查找区域” 反向查找区域 即是这里所说的 IP 反向解析，它的作用就是通过查询 IP 地址的 PTR 记录 来得到该 IP 地址 指向的域名( 要成功得到域名就 必需要有该 IP 地址的 PTR 记录 ) 消息格式 DNS 消息格式有一个固定的 12 字节头部。通常在 UDP&#x2F;IPv4 传输，且限制于 512 字节( 特殊的可扩展 ) DNS 消息以固定的 12 字节头部开始，随后跟着 4 个 可变长度 的区段( section )： 查询( 或区域 )、回答、授权记录和额外记录 除了第一个区段，其他都包含一个或多个 资源记录(Resource Record, RR) 查询区段 包含一个数据项，结构和 RR 相近，而 RR 可以被缓存，问题不可以 反向 DNS 查询需要的 PTR 就在 RR 中 PTR RR 类型以一种特殊的方式使用了 特殊的域： in-addr.arpa( IPv6 中为 ip6.arpa )域。考虑一个 IPv4 地址，128.32.112.208，这个地址来自 128.32 的B类地址空间 为了确定对应到这个地址的名称，首先将该地址 反转，然后添加 特殊的域： 1208.112.32.128.in-addr.arpa. 进行 PTR 记录的查询，实际上是在查询 域 208.112.32.128.in-addr.arpa. 中的 “主机” 208 例子参考 《TCP&#x2F;IP 详解 卷1：协议》P381 参考文章、百度百科、阿里、cnblogs “那么IP反向解析是怎么被应用到邮件服务器中来阻拦垃圾邮件的呢？我们来看看下面一个例子： 某天，阿Q到A公司拜访，他递上一张名片，名片上写着他来自“黑道杀人俱乐部”以及电话号码等信息，A公司觉得应该对阿Q的来历做个简单调查，于是打电话到阿Q名片上的电话号码所属电信局进行查实，如果电信局告诉A公司其电话号码不属于“黑道杀人俱乐部”，则A公司将拒绝阿Q的拜访，如果其电话号码的确属于“黑道杀人俱乐部”，A公司可能接受阿Q的拜访也可能进一步查实，于是就打电话到“黑道杀人俱乐部”所属注册机构查询，如果得到的答复确认该俱乐部确有此电话号码，则A公司将接受阿Q的拜访，否则仍将拒绝阿Q的拜访。 这个例子中，阿Q好比是我们的邮件服务器，A公司是对方邮件服务器，“黑道杀人俱乐部”就是我们邮件服务器与对方邮件服务器通信时所使用的HELO域名（不是邮件地址@后的域名），名片上的电话号码就是我们邮件服务器出口的公网IP地址。A公司对阿Q进行调查的过程就相当于一个反向解析验证过程。由此看出，反向解析验证其实是对方服务器在进行的，如果我们没有做反向解析，那么对方服务器的反向解析验证就会失败，这样对方服务器就会以我们是不明发送方而拒收我们发往的邮件，这也就是我们排除其它原因后（如被对方列入黑名单、没有MX记录、使用的是动态IP地址等等）在没做反向解析时无法向sina.com、homail.com发信的原因。” FTP FTP：文件传输协议 用户首先提供远程主机的主机名，使本地主机的 FTP 客户端进程建立一个到远程主机 FTP 服务器进程的 TCP 连接 该用户接着提供用户标识和口令，作为 FTP 命令的一部分在该 TCP 连接上传送 一旦该服务器向该用户授权，用户就可以将存放在本地文件系统中的一个或者多个文件复制到远程文件系统( 反之亦然 ) FTP 有状态！ 控制端口是 21，数据端口可能是 20，port 是 20，pasv 需要客户端服务端商定 两条连接FTP使用了两条并行的 TCP 连接 来传输文件 一个是控制连接，一个是数据连接 控制连接 用于在两主机之间 传输控制信息，如用户标识、口令、改变远程目录的命令以及“存放( put )”和“获取( get )”文件的命令 数据连接 用于 实际发送文件 也称 FTP 的 控制信息 是 带外 ( out-of-band )传送的 HTTP 是在传输文件的 同一个 TCP 发送请求和响应首部行的，因此 HTTP 是 带内 ( in-band )发送控制信息的 建立过程当用户主机与远程主机开始一个 FTP会话 时，FTP 的 客户端 首先与 服务器( 21 号端口 ) 发起一个 用于控制 的 TCP 连接 客户端通过 该控制连接发送命令 ( 用户的标识、口令和改变远程目录 ) 当 FTP 的服务端从该连接上 收到 一个文件传输的命令后( 无论是发向还是来自远程主机 )，就 发起 一个到客户端的 TCP数据连接 FTP 在该数据连接上准确地传送一个文件，然后 关闭该连接 ！！！如果 还需要传输 另一个文件，FTP就 打开另一个 数据连接 ！！！因此对FTP来说，控制连接 贯穿了整个用户会话期间，但是对会话中的每一次文件传输都需要建立 一个新的数据连接 ( 即数据连接是非持续性的 ) FTP 服务器 必须在整个会话期间 保留用户的状态 ( state ) 服务器必须把 **特定的 **用户账户 与 控制连接 联系起来，随着用户在远程目录树上徘徊，服务器必须追踪用户在远程目录树上的当前位置。对每个进行中的用户会话的状态信息进行追踪，大大限制了 FTP 同时维持的会话总数 而HTTP是 无状态 的，即不必对任何用户状态进行追踪 两种工作模式( PASV + PORT )百度百科 FTP 支持两种模式，一种方式叫做 Standard ( 也就是 PORT 方式，主动方式 )，一种是 Passive ( 也就是 PASV，被动方式 ) Port FTP 客户端 首先和 FTP 服务器 的 TCP 20 端口 建立连接，通过这个通道发送命令，客户端 需要接收数据的时候在这个通道上 发送 PORT 命令 PORT 命令包含了客户端用什么端口接收数据。在传送数据的时候，服务器端 通过自己的 TCP 20 端口 连接至 客户端 的 指定端口 发送数据 Passive 在建立控制通道的时候和 Port 模式类似，但建立连接后发送的不是 Port 命令，而是 Pasv 命令 FTP 服务器 收到 Pasv 命令后，随机 打开一个高端端口( 端口号 大于 1024 )，并且 通知客户端 在这个端口上传送数据的请求，客户端连接 FTP 服务器此端口，通过 三次握手 建立通道，然后 FTP 服务器将通过 这个端口 进行数据的传送 总的来说，主动就是客户端给出端口号让服务端主动来连，被动就是服务端打开端口号让客户端来连 主被动是针对服务端来说的 很多防火墙在设置的时候都是不允许接受外部发起的连接的，所以许多位于防火墙后或内网的 FTP 服务器不支持 PASV 模式，因为客户端无法穿过防火墙打开 FTP 服务器的高端端口 而许多内网的客户端不能用 PORT 模式登陆 FTP 服务器，因为从服务器的 TCP 20 端口无法和内部网络的客户端建立一个新的连接，造成无法工作 选择用PASV方式还是PORT方式登录FTP服务器，选择权在FTP客户端，而不是在FTP服务器。 一、客户端只有内网IP，没有公网IP 从上面的FTP基础知识可知，如果用PORT方式，因为客户端没有公网IP，FTP将无法连接客户端建立数据链路。因此，在这种情况下，客户端必须要用PASV方式，才能连接FTP服务器。大部分FTP站长发现自己的服务器有人能登录上，有人登录不上，典型的错误原因就是因为客户端没有公网IP，但用了IE作为FTP客户端来登录（IE默认使用PORT方式）。 作为FTP站长，有必要掌握FTP的基础知识，然后指导您的朋友如何正确登录您的FTP。 二、客户端有公网IP，但安装了防火墙 如果用PASV方式登录FTP服务器，因为建立数据链路的时候，是由客户端向服务器发送连接请求，没有问题。反过来，如果用PORT方式登录FTP服务器，因为建立数据链路的时候，是由服务器向客户端发送连接请求，此时连接请求会被防火墙拦截。如果要用PORT方式登录FTP服务器，请在防火墙上打开1024以上的高端端口。 https://developer.aliyun.com/article/234007 FTP指令和响应码为了区分连续的命令，每个命令后跟 回车换行符 每个命令由 4 个大写字母ASCII字符组成 USER username：用于向服务器发送用户标识。user PASS password：用户口令。pass LIST：用于请求服务器回送当前远程目录中的所有文件列表。这个列表是数据连接传送的。list RETR filename：检索( 即 get )文件。该命令引起远程主机发起一个数据连接。retr STOR filename：存放( 即 put )文件。stor put 或 send：上传 mput：批量上传 get 或 recv：下载 mget：批量下载 size：查看服务器端已接收文件的大小 restart：设置断点位置( 已接收文件的大小 ) 响应码 331 Username OK，Password required 125 Data connection already open; transfer starting 425 Can’t open data connection 452 Error writing file 详细 FTP 传输模式ASCII &#x2F; 二进制 使用 TYPE 命令设置 FTP断点续传使用 REST 命令 参考 最重要的一点，断点续传 需要服务器的支持，这个是必要条件 其次，客户端要知道使用 REST 等一系列指令来作断点续传 下载： 首先使用 TYPE I 命令告诉 FTP 服务器使用 BINARY ( 二进制 )模式传送文件 然后使用 PASV 命令告诉 FTP 服务器 使用 被动打开 模式来传送文件 接着使用 REST 187392 指令告诉 FTP服务器 要 从 文件的 187392 字节 开始 传送( 用 SIZE 获取 ) 使用 RETR + 文件名 来下载文件 REST 0 表示从文件 最开始处 下载 上传： 用 APPE 或 STOR，都是追加数据 获取服务器上和本地要上传文件的同名文件大小 向服务器发送 “APPE ＋ 文件名”，通知服务器，接下来从数据通道发送给你的数据要附加到这个文件末尾 定位本地文件指针 从文件指针处读数据并发送( restart ) 匿名FTP只适用于那些 提供了这项服务的主机 百度百科 匿名 FTP 的机制：用户可通过它连接到远程主机上，并从其下载文件，而 无需成为其注册用户 系统管理员建立了一个特殊的用户 ID，名为 anonymous， Internet 上的任何人在任何地方都可使用该用户 ID 通过 FTP 程序连接匿名 FTP 主机的方式同连接普通 FTP 主机的方式差不多，只是在要求提供用户标识 ID 时 必须输入 anonymous(&#x2F;əˈnɑː.nə.məs&#x2F;)，该用户 ID 的 口令( pass ) 可以是 任意的字符串 一般用自己的 E-mail地址 作为口令，使系统维护程序能够记录下来谁在存取这些文件 匿名 FTP 不适用于所有 Internet 主机，它只适用于那些 提供了这项服务的主机 关羽跨域 https://www.ruanyifeng.com/blog/2016/04/cors.html HTTP超文本传输协议 B&#x2F;S、请求&#x2F;响应 传输的类型由 Content-Type 决定 无连接 服务器处理完请求，并收到客户的应答后，即断开连接 为了保持会话连接，有了 Cookie 和 Session 无状态 不保留之前的状态 URI 和 URL URI 是标识符( Identifier ) URL 是定位符( Location ) 参考文章 https://www.zhihu.com/question/21950864/answer/154309494 报文格式 参考文章 https://www.jianshu.com/p/eb3e5ec98a66 ( 请求报文、响应报文、请求头各种字段、响应头各种字段 ) 通用首部字段 Connection: close ( 搞完就关闭连接 )&#x2F; keep-alive HTTP&#x2F;1.1 默认都是持久连接，使用 close 后会明确断开连接 HTTP&#x2F;1.1 之前的版本默认都是非持久连接，使用 keep-alive 可以维持持久连接 Transfer-Encoding：传输报文主体时采用的编码方式 通用缓存首部字段 Cache-Control：管理缓存信息，HTTP&#x2F;1.1引入 请求报文 请求行( 第一行 )：包括请求方法、URL、协议&#x2F;版本( 三者之间用空格分隔 ) 请求头( Request Header ) Host：服务器的主机名和端口号 其他 空行 请求正文 请求方法 GET( 数据放 url 后面，且有长度限制，具体由浏览器决定 ) POST( 比 GET 多了 body，没有长度限制 ) PUT、DELETE…… HEAD：类似 GET，只返回响应报头，不返回响应主体 响应报文 状态行：HTTP 版本、状态码、原因短语 响应头 Location：客户端应重定向到指定 URI，基本配合 3** 响应出现 Server：HTTP 服务器的应用程序信息 空行 响应正文 实体首部字段实体首部字段是在请求报文和响应报文中的实体部分所使用的首部，用于补充内容的更新时间等与实体相关的信息 Content-Encoding 告诉客户端实体的主体部分选用的内容编码方式 Content-Language 告诉客户端实体主体使用的自然语言( 中文、英文等 ) Content-Length 表明实体主体部分的大小( 单位：字节 )。对实体主体进行内容编码传输时，不能再使用该首部字段 Content-Type 响应报文中对象的媒体类型 HTTP 状态码 1XX- 信息型，服务器收到请求，需要请求者继续操作 2XX- 成功型，请求成功收到，理解并处理 3XX - 重定向，需要进一步的操作以完成请求 4XX - 客户端错误，请求包含语法错误或无法完成请求 5XX - 服务器错误，服务器在处理请求的过程中发生了错误 常见 200 OK - 客户端请求成功 301 - 永久性重定向。资源( 网页等 )被永久转移到其它 URL 302 - 临时跳转，常见应用场景是通过 302 跳转将所有的 HTTP 流量重定向到 HTTPS 303：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源 400 Bad Request - 客户端请求有语法错误，不能被服务器所理解 401 Unauthorized - 未认证（没有登录）请求未经授权，这个状态代码和 请求报头 Authorization、响应报头 WWW-Authenticate 一起使用 403 Forbidden：没有权限（登录了但没有权限） 404 - 请求资源不存在，可能是输入了错误的 URL 500 - 服务器内部发生了不可预期的错误 503 Server Unavailable - 服务器当前不能处理客户端的请求，一段时间后可能恢复正常 HTTPS 非对称加密 加密、解密使用不同的密钥 一把作为公开的公钥，另一把作为私钥 公钥加密的信息，只有私钥才能解密 反之，私钥加密的信息，只有公钥才能解密 缺点：加密和解密花费时间长、速度慢，只适合对少量数据进行加密 基本介绍HTTPS 简单来说就是 非对称加密 + 对称加密 实现的具体步骤 某网站拥有用于非对称加密的公钥 A、私钥 A’ 浏览器向网站服务器请求，服务器把公钥 A 传输给浏览器 浏览器随机生成一个用于对称加密的密钥 X，用公钥 A 加密后传给服务器 服务器拿到后用私钥 A’ 解密得到密钥 X 这样双方就都拥有密钥 X 了，且别人无法知道它 之后双方所有数据都用密钥 X 加密解密 非对称加密的是证书的数据( 非对称更适合用于认证对方的合法性 )，对称加密的是实际传输的数据 如何证明浏览器收到的公钥一定是该网站的公钥？ 使用数字证书 对于为什么不用CA证书的公钥： CA证书公钥只为了浏览器解密证书验证真伪。不用于加密数据。加密数据使用协商的加密算法 CA 证书 CA 生成 明文数字证书，然后将 明文数字证书 运行 Hash 算法，生成 Message Digest，用 CA 的私钥加密 Message Digest，生成 数字签名( Digital Signature )，这样 明文数字证书 + 数字签名 就是用户拿到的 数字证书( Certificate ) 客户端&#x2F;个体得到 明文数字证书 + 数字签名，然后将 明文数字证书 运行相同的 Hash 算法，得到本地的 Message Digest ( A ) 客户端&#x2F;个体用 CA 公钥解开在服务端被私钥加密过的 数字签名，得到绝对正确的 Message Digest ( B ) 比较 A 和 B，如果一样，那就安全可信，认证通过 详细说明 详细握手过程 参考文章 两张图解释清楚 上面的是 RSA 加密，下面的是 DH 加密 访问 百度，通过 大白鲨 wireshark 抓包( 下面用的是 DH )： Client Hello 一个客户端可用的版本号( 版本是向下兼容的 ) 一个随机数 一个加密套件( 客户端支持的所有的加密套件，在这里包含 16 个 ) Server Hello 一个版本号( 版本向下兼容 ) 一个随机数 一个从客户端发送的加密套件中选用的双方都支持的加密套件 选用不同的套件会对后续的交互产生不一样的动作 此时客户端和服务端就已经协商好了版本号，密码套件，并且客户端和服务端都拥有了两个随机数 Server Certificate服务端会立刻发送一个 Server Certificate 信息，该信息包含了一个很重要的东西：CA 证书，即数字证书 Certificates -&gt; [CA 证书](#CA 证书)，包括 明文数字证书 + 数字签名，还有服务器公钥 证书的作用： 一个是身份验证 一个是证书中包含服务器的公钥( 不关 CA 的事 )，该公钥结合密码套件的密钥协商算法协商出预备主密钥 pre-master Server Key Exchange该消息是有条件才发送的，刚刚在 [Server Hello](#Server Hello) 中说的，选择不同的密码套件会有不同的动作产生，该信息的发送就是属于不同的动作 它发送的条件是，如果证书包含的信息不足以进行密钥交换，那么必须发送该信息。通常协商的加密套件属于下面的类型，就会发送： DHE_DSS DHE_RSA ECDHE_ECDSA ECDHE_RSA 之前协商的密码套件就是 ECDHE_RSA： 所以这里我们可以看到该信息的发送，并且该信息是紧跟着 Server Certificate 信息的 RSA 与 DH 加密：RSA&#x2F;DH 身份验证&#x2F;数字签名：RSA 最上面的时序图中展示的密钥协商方式就是 RSA，该方式较为简单： 客户端生成一个随机数作为 pre-master 从证书中获取服务端的 RSA 公钥，加密 pre-master，传给服务端 服务端使用自己的 RSA 私钥解密，得到 pre-master 由于传递时，pre-master 经过 RSA 公钥加密，只有掌握着 RSA 私钥的服务端才能解开获得内容，满足密钥协商的条件 与RSA方式中 pre-master 完全由客户端生成不同，在DH算法中，pre-master 是客户端和服务器端共同计算出来的，只有经过消息互换才能计算出预备主密钥，流程如下： 服务端内部：生成 DH 参数和 DH 密钥对 服务端( [Server Key Exchange](#Server Key Exchange) )发送给客户端 用自己的 RSA 私钥、签名、DH 参数 和 DH 公钥，最后将签名值、DH 参数、DH 公钥全部发送给客户端 客户端内部：使用服务器 RSA 的公钥( 从证书获取 )校验签名，确保获取到的 DH 参数和 DH 公钥是由服务端签发的 客户端( [Client Key Exchange](#Client Key Exchange) )发送给服务端 通过 DH 参数生成客户端的 DH 密钥对，并将客户端 DH 公钥发送给服务端 客户端( [Change Cipher Spec](#Change Cipher Spec) )告知服务端准备好了 通过客户端DH私钥和服务器端 DH 公钥计算出预备主密钥，并告知服务端准备好了 服务端内部：接收到客户端的 DH 公钥，结合服务器的 DH 私钥计算出预备主密钥 pre-master 最终客户端和服务器端计算出的预备主密钥 pre-master 能够保持一致 客户端每次连接服务器的时候，服务器都会发送动态 DH 信息( DH 参数和 DH 公钥，DH 公钥并不是证书上的那个公钥 )，这些信息不存在证书中，需要通过 [Server Key Exchange](Server Key Exchange) 来进行信息传递，并且传递的 DH 信息需要使用服务器的私钥进行签名 DH 公钥就是 Pubkey，签名就是 Signatrue，DH 参数由 Curve Type、Named Curve、Pubkey 组成的 该信息是用于密钥交换 HTTPS 在真正的通信阶段，是通过对称加密来对内容进行加密的，那么对称加密的密钥交换的安全性就显得非常重要，如果安全的保证客户端和服务端都能获得这个对称加密的密钥就是该信息需要做的事情了 Server Hello Done 服务器发送完上述信息之后，会立刻发送该信息，然后等到客户端的响应 接下来可以和客户端一起协商出预备主密钥 Client Key Exchange一般有两种方式： 客户端通过 RSA&#x2F;ECDSA 算法加密预备主密钥，然后发送给服务器 通过服务器发送的 DH 参数计算出客户端的 DH 公钥，并传递给服务器 这里使用的是第二种方式 Change Cipher Spec该信息用于告诉对方，我已经计算好需要使用的对称密钥了，我们接下来的通信都需要使用该密钥进行加密之后再发送 Encrypted Handshake Message即加密的握手信息 运输层的多路复用和多路分解 将运输层报文段的数据交付到正确的套接字的工作称为 多路分解 在源主机从不同套接字中收集数据块，并为每个数据块封装上首部信息( 这将在以后用于分解 )从而产生报文段，然后将报文段传递到网络层，所有这些工作称为 多路复用 UDP 参考文章 UDP( 用户数据报协议 ) 在发送报文段之前，发送方和接收方的运输层实体之间没有握手。所以 UDP 被称为无连接的 无须执行任何与运行在目的端系统中的 UDP 实体之间的握手，主机端的 UDP 为此报文添加首部字段，然后将形成的报文段交给网络层 网络层将此 UDP 报文段封装进一个 IP 数据报中，然后将其发送给一个名字服务器…… UDP 首部开销小，仅有 8 字节 UDP首部UDP首部只有 4 个字段，每个字段由 2 个字节组成，即首部 8 个字节 长度字节 -&gt; UDP 报文段中的字节数( 首部 + 数据 ) UDP校验和把报文段的所有 16 比特字求和( 溢出要回卷 )，然后 取反，得到 校验和( 回卷就是进位加到末位 ) 接收方将全部 16 比特之和 + 校验和，若都为 1，就没有出错 特点 提供无连接服务 在传送数据之前不需要先建立连接 传送的数据单位协议是 UDP 报文或用户数据报 对方的运输层在收到 UDP 报文后，不需要给出任何确认 虽然 UDP 不提供可靠交付，但在某些情况下 UDP 是一种最有效的工作方式 UDP 支持一对一、一对多、多对一和多对多的交互通信 UDP 的首部开销小，只有 8 个字节，比 TCP 的 20 个字节的首部要短 UDP 对应用层交下来的报文，既不合并，也不拆分，而是 保留这些报文的边界 应用层交给 UDP 多长的报文，UDP 就照样发送，即一次发送一个报文 TCP ！！！看这篇，下面都很乱，且有错！！！ 就是类似“打电话” TCP ( 传输控制协议 )：面向连接 TCP 是可靠的 可靠传输、流量控制、避免网络拥塞 TCP 连接提供的是 全双工服务：有A到B的一条TCP连接，那么数据能从A到B，也能B到A(同时)。 也是 点对点 TCP 是面向字节流的，就是一个文件，TCP 先把数据块拿到 TCP 发送缓存，然后发送到接收方的接收缓存，然后再到文件系统 TCP是如何实现可靠传输的校验和序列号确认应答超时重传连接管理流量控制拥塞控制停止等待协议 （超时重传在下面） （RTT：往返时间） 确认丢失和确认迟到 总结就是：只要你没告诉我收到，我就认为你没收到，就要重发 使用上述的确认和重传机制，就能在不可靠的传输网络上实现可靠的通信 这种可靠传输协议称为 自动重传请求(Automatic RepeatQuest) (《计算机网络自顶向下》P138) ARQARQ 表明重传的请求是 自动 进行的。接收方不需要请求发送方重传 Td是发的时间，Ta是收的时间，RTT是往返时间，大部分时间在等…… 信道利用率： 提高信道利用率，因为RTT和Ta几乎不变，就要提高Td，即发送的时间，即数据进入链路的时间： 这就是 流水线传输就不等它确认了，那是怎么保证可靠呢？ GBN (回退N步)协议连续ARQ协议，也就是 滑动窗口，也称为 GBN (回退N步)协议 发送窗口5就是5个可以连续发送开始等确认，如果1确认窗口往右移1 2确认，右移1，以此类推……已经确定的就能从缓存清掉 但是这样每个数据都要确认，效率还是低然后就有了 累计确认 上面是接收方，下面是发送方 发送方累计确认123后，证明123都收到了，就滑动3个 如果3丢了，4确认了 会认为发送方累积确认到2，就会重传3，接收方会丢弃后面的失序分组。 丢了又可惜，就有了 SACK(选择确认选项) SACK当接收方接收到乱序的数据时，能提供一个SACK来描述 SACK 包含了不连续块的第一个数据的序列号和不连续块的最后一个数据的序列号之后的序列号 TCP报文段首部 选项一般为空，使用首部一般为20字节(UDP首部8个) 序号：因为TCP是面向字节流的，序号就是建立在字节流之上，而不是建立在传送的报文段的序列之上，因此一个报文段的序号是这个报文段首字节的字节流编码 确认号：因为 全双工，主机A发送的报文段的确认号就是A期望从主机B收到的下一个字节的序号。假设主机A已经收到了来自B的编号为0-535的所有字节，同时假设A 打算 发一个报文段给B。如果A期望B的字节流中的536及以后的字节，就会在A发往B的报文段的 确认号 中填上 536 数据偏移4位，1111，十进制15，也就是说选项部分最多40个字节(这里我也不懂是啥意思)记录TCP报文段的第多少个字节后就是数据，数据偏移 也叫 首部长度 标记位就是 ACK什么的那些，有这些就能在缓存中不用排队，直接优先注意：ACK、SYN(三次握手) PSH 是 push，123发过去，接收方按顺序读123，如果3的标记位PSH 为 1，就是312，就是急着交作业 RST 是 reset，严重错误，需要重新来建立连接 URG urgent，为1时，假设紧急指针为50，就代表TCP数据部分前50(包括50)字节需要紧急处理 窗口用于指示接收方愿意接受的字节数量，常用于 流量控制 MSS 最大报文段长度 TCP连接控制传输连接有三个阶段：连接建立、数据传输、连接释放 三次握手、四次挥手三次握手 say hello：SYN 为 1 代表这是用于连接的报文段，不包含应用层数据1、客户端发送 SYN 报文段，即 SYN 置为1、ACK 0、序号随机 x (client_isn)、确认号 02、服务端收到了 客户端的SYN报文段，发送 SYN 1、确认号 x + 1、ACK 1、序号 y(server_isn)3、客户端 收到了，发送 ACK 1、确认号 y + 1、SYN 0、序号 x + 1 SYN_SENT、ESTAB_LISHEDLISTEN、SYN_RCVD(receive)、ESTAB_LISHED ACK 0 -&gt; 确认号无效ACK 1 -&gt; 确认号有效 SYN 常被用来 SYN 洪泛攻击，频繁请求会话 四次挥手 say goodbye： 1、发送方：我要结束了；2、接收方：好的3、接收方：我也要关掉了；4、发送方：好的即：1、发送方发送一个FIN，希望接收方看到自己的序号Seq(K)，还包含了一个ACK(L)用于确认对方最近一次发来的数据2、接收方设置响应的ACK为K+1，表明它已经成功收到了发送方主动关闭的FIN，并设置序号Seq(L)3、接收方再次发送自己的FIN，且序号Seq为L，ACK为K+14、发送方为了完成连接的关闭，要发送一个确认，包含ACK (L+1)(确认上一个FIN)、Seq (K)。如果出现FIN丢失的情况，那么发送方会一直发，直到收到ACK为止 同时打开、同时关闭、半关闭半关闭 (渣？)：我发送了一个FIN给对方，但是我仍然希望接收对方的数据，直到对方发送一个FIN给我当第二个FIN被确认后，整个连接才完全关闭。 同时打开 and 同时关闭： 注意：同时打开只是建立一条TCP连接。同时关闭和正常关闭类似，只是顺序是交叉的 TCP实现可靠传输以字节单位的滑动窗口就是上面的 TCP实现可靠传输 TCP流量控制机制就是滑动窗口(连续ARQ)，调节 窗口的大小 来控制 参考：https://zhuanlan.zhihu.com/p/37379780 这里如果 死锁 呢？死锁：当发送者收到了一个窗口为0的应答，发送者便停止发送，等待接收者的下一个应答。但是如果下一个窗口不为0的应答在传输过程丢失，发送者一直等待下去，而接收者以为发送者已经收到该应答，等待接收新数据，这样双方就相互等待，从而产生死锁。为了避免流量控制引发的死锁，TCP使用了持续计时器。每当发送者收到一个零窗口的应答后就启动该计时器。时间一到便主动发送报文询问接收者的窗口大小。若接收者仍然返回零窗口，则重置该计时器继续等待；若窗口不为0，则表示应答报文丢失了，此时重置发送窗口后开始发送，这样就避免了死锁的产生。 TCP超时重传机制基于计时器的重传(RTO)TCP发送数据时会设置计时器 设置时间超时重传的时间应略大于下面得出的加权平均往返时间RTTs 推荐的 α 值为 1&#x2F;8 每个数据包都有相应的计时器，一旦超过 RTO 而没有收到 ACK，就重发该数据包。没收到 ACK 的数据包都会存在重传缓冲区里，等到 ACK 后，就从缓冲区里删除。 快速重传服务器如果收到乱序的包，也给客户端回复 ACK，只不过是重复的 ACK。收到乱序的包 6,7,8,9 时，服务器全都发 ACK &#x3D; 5。这样，客户端就知道 5 发生了空缺。一般来说，如果客户端连续三次收到重复的 ACK，就会重传对应包，而不需要等到计时器超时。 但快速重传仍然没有解决：到底该重传多少个包？ 带选择确认的重传(SACK)参考：https://zhuanlan.zhihu.com/p/101702312 在快速重传的基础上，返回最近收到的报文段的序列号范围，这样客户端就知道，哪些数据包已经到达服务器了。Left Edge，Right Edge 就是这些乱序包的左右边界。 拥塞控制拥塞控制 主要包括：1、慢启动；2、拥塞避免；3、快重传；4、快恢复 MSS：最大报文段长度，典型值就是1460，拨号光纤好像是1440 假设当前发送方 拥塞窗口cwnd 为1个(拥塞窗口cwnd的值是几，就能发送几个数据报文段，实际上书里就是设置为1个MSS，具体看系统)，接收方收到报文段后回复一个确认，发送方首次收到确认后将cwnd设为2，接下来，cwnd 4、8、16……以指数增长，这就是 慢启动 当达到 慢启动阈值 ssthresh 时，TCP会谨慎增加cwnd，即进入 拥塞避免 阶段，每次cwnd增加1，然后分两种版本： 如果发生 超时重传，就 重新进入慢启动，ssthresh设置为cwnd的一半，新的cwnd设置为1(TCP Tahoe版本) 如果 连续有三个冗余的ACK 时，就是出现丢包，就将相应的报文段重传(快速重传)，开始执行 快恢复，将ssthresh设置为cwnd的一半，新的cwnd设置为新的ssthresh(TCP Reno版本)，然后每次+1。新的cwnd也可以设置为ssthresh + 3 参考：《自顶向下》P186 网络层 负责在不同网络之间尽力转发数据包 基于数据包的 IP 地址转发 不负责丢失重传 不负责顺序 发送数据的过程： IPIPv4数据报格式： 标识、标志、片偏移。和[ IP 分片](#IP 分片) 有关 偏移字段表示： 该分片负载字节中的第一个字节在原始 IPv4 数据中的偏移量( 以 8 字节为单位 ) MF 字段表明： 该数据报后面是否还有更多的分组，只有最后一个才被设置为 0 IP 分片一个链路层帧能承载的最大数据量叫 最大传输单元(MTU) 最后一个片的标志位 MF 被设置为 0，其他所有片被设置为 1 IP 选路 参考文章 ICMP 协议ICMP（Internet Control Message Protocol：Internet 控制报文协议）用来记录诊断信息 ICMP 报文是在 IP 数据报内被封装的 类型字段保留了 42 个不同的值，用于确定特定的报文。只有大概 8 个是经常使用的 许多类型的 ICMP 报文也使用不同的代码字段进一步指定报文的含义 校验和时段覆盖整个 ICMPv4 报文 ICMP 数据报可以分为两大类： 有关 IP 数据报传递的 ICMP 报文( 称为 差错报文 ) 有关信息采集和配置的 ICMP 报文( 称为 查询或信息类报文 ) 信息类报文包括回显请求( 类型 8 )和回显应答( 类型 0 )，以及路由器通告( 类型 9 )和路由器请求( 类型 10 )( 9 和 10 统称为路由器发现 ) 常见的差错报文包括目的不可达( 类型 3 )、重定向( 类型 5 )、超时( 类型 11 )和参数问题( 类型 12 ) 以太网帧 FCS( 帧检验序列 )常用 CRC( 循环冗余检验 ) 《协议》P59 PPP 协议点到点协议 PPP里面还包含： 链路控制协议( LCP ) 网络控制协议( NCP ) 高级数据链路控制协议( HDLC ) …… PPP协议的六个阶段: 链路不可用阶段： 初始阶段 链路建立阶段： LCP 协商，( 协商认证方式等 ) 验证阶段： PAP&#x2F;CHAP 验证 网络层协议阶段：NCP 协商 PPP 会话维持阶段： 维持 PPP 会话， 定时发送 Echo Request 报文，并等待 Echo Reply 报文 网络终止阶段： 终止PPP 会话，回到链路不可用阶段 详见：《协议》P89 MTU以太网的最大传输单元 &#x3D; 1500字节 ARP协议 ARP：地址解析协议 在 OSI 中，ARP 是属于链路层，在 TCP&#x2F;IP 中，ARP 属于 网络层。我觉得都有。。。 ARP 几乎用于 IPv4 和以太网 MAC 地址之间的映射，简单说就是能通过 IP 找到 MAC 地址 ARP 正常模式下，仅适用于广播网络 链路层广播：在一个共享的链路层网段上，ARP 向所有主机发送一个称为 ARP 请求 的以太网帧 同一广播域中的所有系统都能接收 ARP 请求 响应一个 ARP 应答，告诉发送 ARP 请求的主机“我的 IP 和 MAC” 这个应答不是广播，而是直接发给发送请求的主机 之后发送方就能将数据报封装在以太网帧中 直接 发给目的主机( 同一域 )，不需要经过路由器 ARP缓存在内存 RARP：逆向ARP，通过 MAC 能知道 IP，已经很少使用","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://kebabshellgithub.github.io/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"Redis","slug":"Redis","date":"2020-07-17T20:19:55.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/07/17/Redis/","link":"","permalink":"https://kebabshellgithub.github.io/2020/07/17/Redis/","excerpt":"","text":"Redis 大全 部分原理 Redis 五种数据类型：string、hash、list、set、zset 配置详解 daemonize：守护线程。默认为 no port：默认 6379 bind：绑定 IP 地址 databases：数据库数量，默认 16 save &lt;second&gt; &lt;changes&gt;：指定多少时间、有多少次更新操作，就将数据同步到 数据文件 redis 默认配置有三个条件，满足一个即进行 持久化 save 900 1 900 s 有 1 个更改 save 300 10 300 s 有 10 个更改 save 60 10000 60 s 有 10000 更改 dbfilename：指定本地数据库的文件名，默认 dump.rdb dir：指定本地数据库的存放目录，默认为 .&#x2F; 当前文件夹 requirepass：设置密码，默认关闭 远程：redis-cli -h &lt;host&gt; -p &lt;port&gt; -a &lt;password&gt; Redis 关闭 使用 kill 命令( 非正常关闭，数据易丢失 )ps -ef|grep -i rediskill -9 PID 正常关闭redis-cli shutdown 公用命令 DEL key DUMP key：序列化给定 key，返回被序列化的值 EXISTS key：检查 key 是否存在 EXPIRE key second：为 key 设定 过期时间 TTL key：返回 key 剩余时间 PERSIST key：移除 key 的过期时间，key 将持久保存 KEY pattern：查询所有符号给定模式的 key RANDOM key：随机返回一个 key RANAME key newkey：修改 key 的名称 MOVE key db：移动 key 至指定数据库中 TYPE key：返回 key 所储存的值的类型 EXPIRE key second 的使用场景 限时的优惠活动 网站数据缓存 手机验证码 限制网站访客频率 key 的命名建议 key 不要太长，尽量不要超过 1024 字节( 不仅消耗内存，也会降低查找的效率 ) key 不要太短，太短可读性会降低 在一个项目中，key 最好使用统一的命名模式，如 user:123:password key 区分大小写 String（简单动态字符串 simple dynamic string SDS） set key_name value：命令不区分大小写，但是 key_name 区分大小写 SETNX key value：当 key 不存在时设置 key 的值( SET if Not eXists ) get key_name GETRANGE key start end：获取 key 中字符串的子字符串，从 start 开始，end 结束 MGET key1 [key2 …]：获取多个 key GETSET KEY_NAME VALUE：设定 key 的值，并返回 key 的旧值。当 key 不存在，返回 nil STRLEN key：返回 key 所存储的字符串的长度 INCR KEY_NAME ：INCR 命令 key 中存储的值 + 1，如果不存在 key，则 key 中的值话先被初始化为 0 再加 1 INCRBY KEY_NAME a：增加 a DECR KEY_NAME：key 中的值自减一 DECRBY KEY_NAME a：减 a append key_name value：字符串拼接，追加至末尾，如果不存在，为其赋值 String 的实际应用场景 缓存功能：String 字符串是最常用的数据类型，不仅仅是 Redis，各个语言都是最基本类型，因此，利用 Redis 作为缓存，配合其它数据库作为存储层，利用 Redis 支持高并发的特点，可以大大加快系统的读写速度、以及降低后端数据库的压力。 计数器：许多系统都会使用 Redis 作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。 共享用户 Session：用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存 Cookie，但是可以利用 Redis 将用户的 Session 集中管理，在这种模式只需要保证 Redis 的高可用，每次用户 Session 的更新和获取都可以快速完成。大大提高效率。 Hash 这个是类似 Map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象( 前提是这个对象没嵌套其他的对象 )给缓存在 Redis 里，然后每次读写缓存的时候，可以就操作 Hash 里的某个字段。 但是这个的场景其实还是多少单一了一些，因为现在很多对象都是比较复杂的，比如你的商品对象可能里面就包含了很多属性，其中也有对象 HSET key_name field value：为指定的 key 设定 field 和 value hmset key field value[field1,value1] hget key field hmget key field[field1] hgetall key：返回 hash 表中所有字段和值 hkeys key：获取 hash 表所有字段 hlen key：获取 hash 表中的字段数量 hdel key field [field1]：删除一个或多个 hash 表的字段 如果 hash 的属性值被删除完，那么 hash 的 key 也会被 redis 删除 List有序、双向链表 12345typedef struct listNode&#123; struct listNode *prev; struct listNode *next; void *value; &#125; lpush key value1 [value2] rpush key value1 [value2] lpushx key value：从左侧插入值，如果list不存在，则不操作 rpushx key value：从右侧插入值，如果list不存在，则不操作 llen key：获取列表长度 lindex key index：获取指定索引的元素 lrange key start stop：获取列表指定范围的元素 lpop key ：从左侧移除第一个元素 prop key：移除列表最后一个元素 blpop key [key1] timeout：移除并获取列表第一个元素，如果列表没有元素会阻塞列表到等待超时或发现可弹出元素为止 brpop key [key1] timeout：移除并获取列表最后一个元素，如果列表没有元素会阻塞列表到等待超时或发现可弹出元素为止 ltrim key start stop ：对列表进行修改，让列表只保留指定区间的元素，不在指定区间的元素就会被删除 lset key index value ：指定索引的值 linsert key before|after world value：在列表元素前或则后插入元素 rpop lpush list1 list2：移除 list1 最后一个元素，并将该元素添加到 list2 并返回此元素 用此命令可以实现订单下单流程、用户系统登录注册短信等。 应用 可以通过 List 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。 可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 List 实现分页查询，基于 Redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。 消息队列：Redis的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过 Lpush 命令从左边插入数据，多个数据消费者，可以使用 BRpop 命令阻塞的“抢”列表尾部的数据。 文章列表或者数据分页展示的应用。 博客网站的文章列表，当用户量越来越多时，而且每一个用户都有自己的文章列表，而且当文章多时，都需要分页展示，这时可以考虑使用 Redis 的列表，列表不但有序同时还支持按照范围内获取元素，可以完美解决分页查询功能。大大提高查询效率。 rpop lpush list1 list2 用此命令可以实现订单下单流程、用户系统登录注册短信等。 Set Set 是无序集合，会自动去重的那种。 直接基于 Set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 JVM 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于Redis进行全局的 Set 去重。 可以基于 Set 玩儿交集、并集、差集的操作，比如交集吧，我们可以把两个人的好友列表整一个交集，看看俩人的共同好友是谁？对吧。 反正这些场景比较多，因为对比很快，操作也简单，两个查询一个Set搞定。 sadd key value1[value2]：向集合添加成员 scard key：返回集合成员数 smembers key：返回集合中所有成员 sismember key member：判断memeber元素是否是集合key成员的成员 srandmember key [count]：返回集合中一个或多个随机数 srem key member1 [member2]：移除集合中一个或多个成员 spop key：移除并返回集合中的一个随机元素 smove source destination member：将member元素从source集合移动到destination集合 sdiff key1 [key2]：返回所有集合的差集 sdiffstore destination key1[key2]：返回给定所有集合的差集并存储在destination中 对两个集合间的数据[计算]进行交集、并集、差集运算 以非常方便的实现如共同关注、共同喜好、二度好友等功能。对上面的所有集合操作，你还可以使用不同的命令选择将结果返回给客户端还是存储到一个新的集合中。 利用唯一性，可以统计访问网站的所有独立 IP Sorted Set（zset） Sorted set 是排序的 Set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。 有序集合的使用场景与集合类似，但是set集合不是自动有序的，而Sorted set可以利用分数进行成员间的排序，而且是插入时就排序好。所以当你需要一个有序且不重复的集合列表时，就可以选择Sorted set数据结构作为选择方案。 排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。 用Sorted Sets来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。 微博热搜榜，就是有个后面的热度值，前面就是名称 ZADD key score1 memeber1 ZCARD key ：获取集合中的元素数量 ZCOUNT key min max 计算在有序集合中指定区间分数的成员数 ZCOUNT key min max计算在有序集合中指定区间分数的成员数 ZRANK key member：返回有序集合指定成员的索引 ZREVRANGE key start stop ：返回有序集中指定区间内的成员，通过索引，分数从高到底 ZREM key member [member …] 移除有序集合中的一个或多个成员 ZREMRANGEBYRANK key start stop 移除有序集合中给定的排名区间的所有成员(第一名是0)(低到高排序） ZREMRANGEBYSCORE key min max 移除有序集合中给定的分数区间的所有成员 常用于排行榜： 如推特可以以发表时间作为score来存储 存储成绩 还可以用zset来做带权重的队列，让重要的任务先执行 zset延时队列 Zset本质就是Set结构上加了个排序的功能，除了添加数据value之外，还提供另一属性score，这一属性在添加修改元素时候可以指定，每次指定后，Zset会自动重新按新的值调整顺序。可以理解为有两列字段的数据表，一列存value,一列存顺序编号。操作中key理解为zset的名字，那么对延时队列又有何用呢？试想如果score代表的是想要执行时间的时间戳，在某个时间将它插入Zset集合中，它变会按照时间戳大小进行排序，也就是对执行时间前后进行排序，这样的话，起一个死循环线程不断地进行取第一个key值，如果当前时间戳大于等于该key值的socre就将它取出来进行消费删除，就可以达到延时执行的目的, 注意不需要遍历整个Zset集合，以免造成性能浪费。 https://my.oschina.net/u/3266761/blog/1930360 持久化Redis 提供了 RDB 和 AOF 两种持久化方式，RDB 是把内存中的数据集以快照形式写入磁盘，实际操作是通过 fork 子进程执行，采用二进制压缩存储；AOF 是以文本日志的形式记录 Redis 处理的每一个写入或删除操作。 RDB 把整个 Redis 的数据保存在单一文件中，比较适合用来做灾备，但缺点是快照保存完成之前如果宕机，这段时间的数据将会丢失，另外保存快照时可能导致服务短时间不可用。 AOF 对日志文件的写入操作使用的追加模式，有灵活的同步策略，支持每秒同步、每次修改同步和不同步，缺点就是相同规模的数据集，AOF 要大于 RDB，AOF 在运行效率上往往会慢于 RDB。 过期策略和内存淘汰策略 参考 过期策略 定时过期、惰性过期、定期过期 Redis中同时使用了惰性过期和定期过期两种过期策略 内存淘汰策略（内存不足时淘汰的策略） noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。 allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。 volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。 事务 参考 MULTI、EXEC、WATCH 事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入队列中排队 redis 不支持回滚 WATCH 命令是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。 MULTI命令用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。 EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。 通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。UNWATCH命令可以取消watch对所有key的监控。 主从复制 Redis 主从复制模式可以将主节点的数据同步给从节点，从而保障当主节点不可达的情况下，从节点可以作为后备顶上来，并且可以保障数据尽量不丢失（主从复制可以保障最终一致性）。第二，从节点可以扩展主节点的读能力，一旦主节点不能支持大规模并发量的读操作，从节点可以在一定程度上分担主节点的压力。 主从复制面临的问题： 当主节点发生故障的时候，需要手动的将一个从节点晋升为主节点，同时通知应用方修改主节点地址并重启应用，同时需要命令其它从节点复制新的主节点，整个过程需要人工干预。 主节点的写能力受到单机的限制。 主节点的存储能力受到单机的限制。 原始的故障迁移 主节点发生故障后，客户端连接主节点失败，两个从节点与主节点连接失败造成复制中断。 如果主节点无法正常启动，需要选出一个从节点(slave-1),对其执行slaveof no one命令使其成为新的主节 原来的从节点（slave-1）成为新的主节点后，更新应用方的主节点信息，重新启动应用方。 客户端命令另一个从节点（slave-2）去复制新的主节点 待原来的主节点恢复后，让它去复制新的主节点 Redis Sentinel的高可用 当主节点出现故障时，Redis Sentinel 能自动完成故障发现和故障转移，并通知应用方，从而实现真正的高可用。 Redis Sentinel 是一个分布式架构，其中包含若干个 Sentinel 节点和 Redis 数据节点，每个 Sentinel 节点会对数据节点和其余 Sentinel 节点进行监控，当它发现节点不可达时，会对节点做下线标识。如果被标识的是“主节点”，它还会和其他的Sentinel节点进行“协商”，当大多数 Sentinel 节点都认为主节点不可达时，它们会选举一个 Sentinel 节点来完成自动故障转移的工作，同时会将这个变化实时通知给Redis应用方。整个过程是自动的，不需要人工干预，解决了 Redis 的高可用问题。 Redis Sentinel 包含了若干个 Sentinel 节点，这样做也带来了两个好处： 对节点的故障判断是由多个 Sentinel 节点共同完成，这样可以有效的防止误判。 Sentinel 节点集合是由若干个 Sentinel 节点组成的，这样即使个别 Sentinel 节点不可用，整个 Sentinel 节点集合依然是健壮的。 Redis Sentinel 具有以下几个功能： 监控：Sentinel 会定期检测 Redis 数据节点、其余 Sentinel 节点是否可到达 通知：Sentinel 会将故障转移的结果通知给应用方。 主节点故障转移：实现从节点晋升为主节点并维护后续正确的主从关系。 配置提供者：在RedisSentinel结构中，客户端在初始化的时候连接的是Sentinel节点集合，从中获取主节点信息。 Redis Sentinel拓扑结构 Redis Sentinel节点发现和监控机制 Redis Sentinel 通过三个定时监控任务完成对各个节点的发现和监控 每隔 10 秒，每个 Sentinel 会向主节点和从节点发送 info 命令获取最新的拓扑结构 每隔 2 秒，每个 Sentinel 节点会向 Redis 数据节点的 Sentinel：hello 频道上发送该 Senitnel 节点对于主节点的判断。以及当前 Sentinel 节点的信息，同时每个 Sentinel 节点也会订阅该频道，来了解其他 Sentinel 节点以及他们对主节点的判断。这个定时任务可以完成以下两个工作： 发现新的 Sentinel 节点：通过订阅主节点的 Sentinel：hello 了解其他 Sentinel 节点信息。如果是新加入的 Sentinel 节点，将该 Sentinel 节点信息保存起来，并与该 Sentinel 节点创建连接 Sentinel节点之间交换主节点状态，作为后面客观下线以及领导者选举的依据 每隔 1 秒，每个 Sentinel 节点会向主节点、从节点、其余 Sentinel 节点发送一条 ping 命令做一次心跳检测，来确认当前节点是否可达。与主节点，从节点，其余 Sentinel 都建立起连接，实现了对每个节点的监控。这个定时任务是节点失败判定的重要依据 Redis Sentinel部署技巧 Sentinel 节点不应该部署在一台物理机上 部署至少三个且奇数个的 Sentinel 节点 只有一套 Sentinel，还是每个主节点配置一套 Sentinel 如果 Sentinel 节点集合监控的是同一个业务的多个主节点集合，那么使用方案 1，否则使用方案 2 Redis Cluster|数据分区 Redis 数据分区：Redis Cluster 采用虚拟槽分区，所有的键根据哈希函数映射到 0-16383 整数槽内 计算公式：slot&#x3D;CRC16(key) &amp;16383。每一个节点负责维护一部分槽以及槽所映射的键值数据 Redis虚拟槽分区的特点 解耦数据和节点之间的关系，简化了节点扩容和收缩的难度 节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据 支持节点、槽、键之间的映射查询，用于数据路由、在线伸缩等场景。 Redis Cluster功能限制 Key 批量操作支持有限。目前只支持同 slot 内的 key 执行批量操作（如mget,mset） Key事务操作支持有限。只支持多key在同一个节点上的事务操作，多个key分布在不同节点上时无法使用事务功能。 Key作为数据分区的最小粒度，因此不能将一个大的键值对象如hash，list等映射到不同节点。 不支持多数据库空间，集群模式下只能使用db0空间。 复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。 集群伸缩 Redis集群提供了灵活的节点扩容和收缩方案，在不影响集群对外服务的情况下，可以为集群添加节点进行扩容也可以下线部分节点进行缩容。 扩容集群的步骤： 准备新节点 加入集群 迁移槽和数据 缩容集群的步骤： 首先要确定下线节点是否有负责的槽，如果是，需要把槽迁移到其他节点，保证节点下线后真个集群槽节点映射的完整性 当下线节点不再负责槽或者本身是从节点时，就可以通知集群内其他节点忘记下线节点，就可以通知集群内其他节点忘记下线节点当所有的节点忘记该节点后可以正常关闭。 故障发现 Redis 集群自身实现了高可用。高可用首先需要解决集群部分失败的场景：当少数节点出现故障时，可以通过自动故障转移保证集群可以正常对外提供服务。故障发现的类型： 主观下线：指某个节点认为另一个节点不可用，即下线状态，这个状态并不是最终的故障判定，只能代表一个节点的意见，可能存在误判情况。 客观下线：指标记一个节点真正的下线，集群内多个节点都认为该节点不可用，从而达成共识的结果。如果持有槽的主节点故障，需要为该节点进行故障转移。 故障恢复 故障节点变为客观下线后，如果下线节点是持有槽的主节点，则需要在它的从节点中选出一个替换它。从而保证集群高可用。下线主节点的所有从节点承担故障恢复的义务，当从节点通过内部定时任务发现自身复制的主节点进入客观下线时，将会触发故障恢复流程。","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://kebabshellgithub.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"中间件","slug":"中间件","permalink":"https://kebabshellgithub.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"缓存","slug":"缓存","permalink":"https://kebabshellgithub.github.io/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"Nginx","slug":"Nginx","date":"2020-07-17T13:03:38.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/07/17/Nginx/","link":"","permalink":"https://kebabshellgithub.github.io/2020/07/17/Nginx/","excerpt":"","text":"新建nginx文件夹 1mkdir /usr/local/docker/nginx 在nginx文件夹创建yml 1vi docker-compose.yml 12345678version: &#x27;3.1&#x27;services: nginx: restart: always image: daocloud.io/library/nginx:latest container_name: nginx ports: - 80:80 下面是nginx的配置exec -it进入容器 在/etc/nginx里面有nginx.conf,这就是nginx配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142worker_processes 1:error_log 巴拉巴拉pid 巴拉巴拉# 以上统称为全局块# worker_processes数值越大，Nginx的并发能力越强# error_log 错误日志位置events&#123; worker_connections 1024&#125;# events块# worker_connections数值越大，Nginx的并发能力越强http &#123; include /etc/nginx/mine.types; server &#123; listen 80; server_name localhost; location / &#123; root /usr/share/nginx/html; index index.html index.htm; &#125; # location块 # root 将接收到的请求数据根据/usr/share/nginx/html去查找静态资源 # index 默认去上述的路径中找到index.html或index.htm &#125;# server块,一般都是通过conf文件引入(最下面的include)# listen 代表Nginx监听的端口号# localhost 代表Nginx接收请求的ip include /etc/nginx/conf.d/*.conf&#125;# http块# include代表引入了一个外部的文件 -&gt; /mime.types中放着大量的媒体类型# include /etc/nginx/conf.d/*.conf -&gt; 引入了conf.d目录下以.conf结尾的配置文件 nginx目录下就有conf.d文件里面有default.conf,这是nginx给的示例 要修改nginx的docker-compose文件，添加数据卷 12345678910version: &#x27;3.1&#x27;services: nginx: restart: always image: daocloud.io/library/nginx:latest container_name: nginx ports: - 80:80 volumes: - ./conf.d:/etc/nginx/conf.d 修改完成后直接docker-compose build重新构建然后up,当前目录就有conf.d 打开conf.d，创建 default.conf ，编写server块 123456789server&#123; listen 80; server_name localhost; location / &#123; root /usr/share/nginx/html; index index.html index.htm; &#125;&#125; 然后restart 正向代理和反向代理 1、正向代理服务是由客户端设立的2、客户端了解代理服务器和目标服务器都是谁3、帮助我们突破访问权限，提高访问速度，对目标服务器隐藏客户端IP 1、反向代理服务器配置在服务端2、客户端不知道访问的是哪台服务器3、能负载均衡，并且可以隐藏服务器真实的IP 反向代理测试把conf.d里面的default.conf中的location注释 123456789101112server&#123; listen 80; server_name localhost; location / &#123; proxy_pass http://xxx.xxx.xxx.xxx:8080/; #Tomcat &#125; #location / &#123; # root /usr/share/nginx/html; # index index.html index.htm; #&#125;&#125; Nginx 的 location 路径映射优先级：(location &#x3D;) &gt; (location &#x2F;xxx&#x2F;ttt&#x2F;zzz) &gt; (location ^~) &gt; (location ~, ~*) &gt; (location &#x2F;起始路径) &gt; (location &#x2F;) 1234# 1、=location = / &#123; # 精准匹配，主机名后面不能带任何字符串&#125; 1234# 2、通用匹配location /xxx &#123; # 匹配所有以/xxx开头的路径&#125; 1234# 3、正则匹配location ~ /xxx &#123; # 匹配所有以/xxx开头的路径&#125; 1234# 4、匹配开头路径location ^~ /images/ &#123; # 匹配所有以/images开头的路径，注意 /&#125; 1234# 5、匹配结尾路径location ~* \\.(gif|jpg|png)$ &#123; # 匹配以gif或者jpg或者png结尾的路径&#125; Nginx 负载均衡1、轮询：轮流着来，平均分配 12345678910111213# 自定义my-server，注意自定义的不要加下划线_upstream my-server &#123; server xxx.xxx.xxx.xxx:8080; server xxx.xxx.xxx.xxx:8081;&#125;server&#123; listen 80; server_name localhost; location / &#123; proxy_pass http://my-server/; &#125;&#125; 2、权重：不同服务器可能性能不同，直接使用weight 12345678910111213# 自定义my-server，注意自定义的不要加下划线_upstream my-server &#123; server xxx.xxx.xxx.xxx:8080 weight 10; server xxx.xxx.xxx.xxx:8081 weight 2;&#125;server&#123; listen 80; server_name localhost; location / &#123; proxy_pass http://my-server/; &#125;&#125; 3、ip_hash：同一个ip就一直是那个服务器了 123456789101112131415upstream my-server &#123; # 只需要加上 ip_hash; ip_hash; # 下面有没有weight都没有关系 server xxx.xxx.xxx.xxx:8080; server xxx.xxx.xxx.xxx:8081;&#125;server&#123; listen 80; server_name localhost; location / &#123; proxy_pass http://my-server/; &#125;&#125; Nginx 动静分离123Nginx的并发公式 worker_processes * worker_connections /4 | 2 = Nginx最终的并发能力动态资源需要 /4，静态资源 /2 动态资源：静态资源： 配置动态资源： 123location / &#123; proxy_pass 路径;&#125; 静态资源： 12345location / &#123; root 静态资源路径; index 默认访问路径下的什么资源 autoindex on; # 代表展示静态资源全部内容，以列表形式&#125; docker-compose 添加数据卷 12345678910111213version: &#x27;3.1&#x27;services: nginx: restart: always image: daocloud.io/library/nginx:latest container_name: nginx ports: - 80:80 volumes: - ./conf.d:/etc/nginx/conf.d # 以下为添加内容 - ./img/:/data/img - ./html/:/data/html 启动。 网页和图片自行添加 修改 default.conf 123456789location /html &#123; # 这里访问的就是/data/html/目录，html/会拼接到/data/后面 root /data; index index.html;&#125;location /img &#123; root /data; autoindex on;&#125; restart Nginx集群一台Nginx会出现单点故障 多台 Nginx：如果一台挂了，但是客户端不知道，还是发送请求到这台上，就会报错 解决方法：Nginx 安装 keepalived，keepalived 能监听当前的 Nginx 是否正常 如果 Nginx1 是 99:8080，Nginx2 是 98:8081，客户端要访问哪台呢 解决方法：使用 HAProxy，提供一个虚拟的路径，统一的去接收用户的请求 配置新建 index-master.html新建 index-slave.html 新建 Dockerfile 123456FROM nginx:1.13.5-alpineRUN apk update &amp;&amp; upgradeRUN apk add --no-cache bash curl ipvsadm iproute2 openrc keepalivedCOPY entrypoint.sh /entrypoint.shRUN chmod +x /entrypoint.shCMD [&quot;/entrypoint.sh&quot;] 新建 entrypoint.sh 123456#!/bin/sh#/usr/sbin/keepalived -n -l -D -f /etc/keepalived/keepalived.conf --dont-fork --log-console &amp;/usr/sbin/keepalived -D -f /etc/keepalived/keepalived.confnginx -g &quot;daemon off&quot; 新建 keepalived-master.conf 123456789101112131415161718192021222324252627vrrp_script chk_nginx &#123; script &quot;pidof nginx&quot; interval 2&#125;# 上面表示keepalived多久检测一次vrrp_instance VI_1 &#123; state MASTER # 先接受请求的Nginx interface eth0 # 容器内部网卡名称 virtual_router_id 33 priority 200 # 优先级 advert_int 1 authentication &#123; auth_type PASS auth_pass letmein &#125; virtual_ipaddress &#123; xxx.xxx.xxx.xxx # 虚拟路径 &#125; track_script &#123; chk_nginx &#125;&#125; 新建 keepalived-slave.conf 123456789101112131415161718192021222324252627vrrp_script chk_nginx &#123; script &quot;pidof nginx&quot; interval 2&#125;# 上面表示keepalived多久检测一次vrrp_instance VI_1 &#123; state BACKUP # 先接受请求的Nginx interface eth0 # 容器内部网卡名称 virtual_router_id 33 priority 100 # 优先级 advert_int 1 authentication &#123; auth_type PASS auth_pass letmein &#125; virtual_ipaddress &#123; xxx.xxx.xxx.xxx # 虚拟路径 &#125; track_script &#123; chk_nginx &#125;&#125; 新建 haproxy.cfg 123456789101112131415161718192021global log 127.0.0.1 local0 maxconn 4096 daemon nbproc 4defaults log 127.0.0.1 local3 mode http option dontlognull option redispatch retries 2 maxconn 2000 balance roudrobin timeout connect 5000ms timeout client 5000ms timeout server 5000msfrontend main bin *:6301 default_backend webserverbackend webserver server nginx_master xxx.xxx.xxx.xxx check inter 2000 rise 2 fall 5 新建 docker-compose.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546version: &#x27;3.1&#x27;services: nginx_master: build: context: ./ dockerfile: ./Dockerfile ports: - 8081:80 volumes: - ./index-master.html:/usr/share/nginx/html/index.html - ./favicon.ico:/usr/share/nginx/html/favicon.ico - ./keepalived-master.conf:/etc/keepalived/keepalived.conf networks: static-network: # 固定Nginx在容器的ip ipv4_adress: xxx.xxx.xxx.xxx cap_add: - NET_ADMIN nginx_slave: build: context: ./ dockerfile: ./Dockerfile ports: - 8082:80 volumes: - ./index-slave.html:/usr/share/nginx/html/index.html - ./favicon.ico:/usr/share/nginx/html/favicon.ico - ./keepalived-slave.conf:/etc/keepalived/keepalived.conf networks: static-network: ipv4_adress: xxx.xxx.xxx.xxx cap_add: - NET_ADMIN proxy: image: haproxy:1.7-alpine ports: - 80:6301 volumes: - ./haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg networks: - static-networknetworks: static-network: ipam: config: - subnet: xxx.xxx.xxx.xxx/16 直接 up -d 启动。完成","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[]},{"title":"MySQL","slug":"MySQL","date":"2020-05-20T16:42:16.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/05/20/MySQL/","link":"","permalink":"https://kebabshellgithub.github.io/2020/05/20/MySQL/","excerpt":"","text":"还有 MySQL45讲学习笔记 （新的） 存储引擎SHOW ENGINES 查看支持的所有存储引擎 InnoDB MVCC 多版本并发控制 四个隔离级别 next-key locking 避免幻读( phantom ) 插入缓存 insert buffer 二次写 double write 自适应哈希索引 adaptive hash index 预读 read ahead 重做日志 redo log 聚集 clustered MyISAM[my-z[ei]m] 不支持 事务、表锁设计 支持 全文索引 缓冲池只缓存索引文件，不缓存数据文件 用 MyISAM 的表由 MYD 和 MYI 组成 MYD 用来存数据文件 MYI 用来存索引文件 可用 myisampack 工具来解压缩数据文件，myisampack 使用赫夫曼编码来压缩数据 压缩后的表是只读的 5.0 开始，MyISAM 单表默认支持256TB的数据 对于 MyISAM 存储引擎表，MySQL 数据库只缓存其索引文件，数据文件由操作系统来完成 64 位支持大于 4 GB 的索引缓冲区 常用 user 表 看信息 MySQL系统数据库mysql核心，它存储了 MySQL 的用户账户和权限信息，一些存储过程、事件的定义信息，一些运行过程中产生的日志信息，一些帮助信息以及时区信息等 information_schema这个数据库保存着 MySQL 服务器维护的所有其他数据库的信息，比如有哪些表、哪些视图、哪些触发器、哪些列、哪些索引。这些信息并不是真实的用户数据，而是一些描述性信息，有时候也称之为元数据 performance_schema这个数据库里主要保存 MySQL 服务器运行过程中的一些状态信息，算是对 MySQL 服务器的一个性能监控。包括统计最近执行了哪些语句，在执行过程的每个阶段都花费了多长时间，内存的使用情况等等信息 sys这个数据库主要是通过视图的形式把 information_schema 和 performance_schema 结合起来，让程序员可以更方便的了解 MySQL 服务器的一些性能信息 InnoDB(详) InnoDB是多线程的 基本名词 dirty page 脏页：LRU 列表被修改的页( 因为和磁盘数据不一样了 ) 存储结构存储结构 &#x3D; 表空间Tablespace( 段Segment( 区Extent( 页Page( 行Row ) ) ) ) 表空间最高层 启用 innodb_file_per_table 就能将每张表单独放到一个表空间 如果启用，每张表的表空间只存放 数据、索引、插入缓冲 BITmap 页，其他的如回滚( undo )信息、插入缓冲索引页、系统事务信息、二次写缓冲( Double write buffer )等还是在原来的共享表空间( ibdata1 )里 段表空间是由各个段组成的 有 数据段、索引段、回滚段 等 数据段 为 B+ 树的叶子节点 索引段为 B+ 树的非叶子节点( 非索引节点 ) 区由连续页组成 每个区大小都为 1 MB 每次从磁盘申请 4 ~ 5 个区 因为默认页 16 KB，所以一个区共 64 个连续页 对压缩页就另说了 页&#x2F;块页是 InnoDB 中磁盘和内存交互的基本单位，也是是管理存储空间的基本单位，一般是 16 KB 数据页 B-tree Node数据页是存放记录的页 记录按照主键值的大小串联成一个单向链表 页之间组成双向链表 页不是连续的，即不是页 1 页 2… 一个页最少存储 2 条记录 名称 中文名 占用空间大小 简单描述 File Header 文件头部 38 字节 页的一些通用信息 Page Header 页面头部 56 字节 数据页专有的一些信息 Infimum + Supremum 最小记录和最大记录 26 字节 两个虚拟的行记录 User Records 用户记录 不确定 实际存储的行记录内容 Free Space 空闲空间 不确定 页中尚未使用的空间 Page Directory 页面目录 不确定 页中的某些记录的相对位置 File Trailer 文件尾部 8 字节 校验页是否完整 存储的记录会按照我们指定的行格式存储到 User Records 部分 但是在一开始生成页的时候，其实并没有 User Records 这个部分，而是 Free Space 每当我们插入一条记录，都会从 Free Space 的那部分，申请一个记录大小的空间，然后划分到 User Records 部分 当 Free Space 部分的空间全部被 User Records 部分替代掉之后，也就意味着这个页使用完了 如果还有新的记录插入的话，就需要去 申请新的页 有两个伪记录 Infimum 和 Supremum，一个代表最小记录，一个代表最大记录 它们并不存放在页的 User Records 部分，他们被单独放在一个称为 Infimum + Supremum 的部分 Infimum记录( 也就是最小记录 )的下一条记录就是本页中主键值最小的用户记录，而本页中主键值最大的用户记录的下一条记录就是 Supremum记录( 也就是最大记录 ) 当删除第2条记录后： 第 2 条记录并没有从存储空间中移除，而是把该条记录的 delete_mask 值设置为 1 第 2 条记录的 next_record 值变为了 0，意味着该记录没有下一条记录了 第 1 条记录的 next_record 指向了第 3 条记录 最大记录 的 n_owned 值从 5 变成了 4 n_owned 是目录页 当数据页中存在多条被删除掉的记录时，这些记录的 next_record 属性将会把这些被删除掉的记录组成一个垃圾链表，以备之后直接重用这部分存储空间 初始情况下一个数据页里只有最小记录和最大记录两条记录，它们分属于两个分组 之后每插入一条记录，都会从页目录中找到主键值比本记录的主键值大并且差值最小的槽，然后把该槽对应的记录的 n_owned 值加 1，表示本组内又添加了一条记录，直到该组中的记录数等于 8 个 在一个组中的记录数等于 8 个后再插入一条记录时，会将组中的记录拆分成两个组，一个组中 4 条记录，另一个 5 条记录 这个过程会在页目录中新增一个槽来记录这个新增分组中最大的那条记录的偏移量 File Trailer InnoDB存储引擎会把数据存储到磁盘上，但是磁盘速度太慢，需要以页为单位把数据加载到内存中处理，如果该页中的数据在内存中被修改了，那么在修改后的某个时间需要把数据同步到磁盘中。但是在同步了一半的时候中断电了咋办，这不是莫名尴尬么？为了检测一个页是否完整（也就是在同步的时候有没有发生只同步一半的尴尬情况），每个页的尾部都加了一个File Trailer部分，这个部分由8个字节组成，可以分成2个小部分： 前4个字节代表页的校验和 这个部分是和File Header中的校验和相对应的。每当一个页面在内存中修改了，在同步之前就要把它的校验和算出来，因为File Header在页面的前边，所以校验和会被首先同步到磁盘，当完全写完时，校验和也会被写到页的尾部，如果完全同步成功，则页的首部和尾部的校验和应该是一致的。如果写了一半儿断电了，那么在File Header中的校验和就代表着已经修改过的页，而在File Trialer中的校验和代表着原先的页，二者不同则意味着同步中间出了错。 后4个字节代表页面被最后修改时对应的日志序列位置（LSN） 这个部分也是为了校验页的完整性的，只不过我们目前还没说LSN是个什么意思，所以大家可以先不用管这个属性。 这个File Trailer与File Header类似，都是所有类型的页通用的。 总结 InnoDB为了不同的目的而设计了不同类型的页，我们把用于存放记录的页叫做数据页 一个数据页可以被大致划分为7个部分，分别是 File Header，表示页的一些通用信息，占固定的38字节 Page Header，表示数据页专有的一些信息，占固定的56个字节 Infimum + Supremum，两个虚拟的伪记录，分别表示页中的最小和最大记录，占固定的26个字节 User Records：真实存储我们插入的记录的部分，大小不固定 Free Space：页中尚未使用的部分，大小不确定 Page Directory：页中的某些记录相对位置，也就是各个槽在页面中的地址偏移量，大小不固定，插入的记录越多，这个部分占用的空间越多 File Trailer：用于检验页是否完整的部分，占用固定的8个字节 每个记录的头信息中都有一个next_record属性，从而使页中的所有记录串联成一个单链表 InnoDB会为把页中的记录划分为若干个组，每个组的最后一个记录的地址偏移量作为一个槽，存放在Page Directory中，所以在一个页中根据主键查找记录是非常快的，分为两步： 通过二分法确定该记录所在的槽 通过记录的 next_record 属性遍历该槽所在的组中的各个记录 每个数据页的File Header部分都有上一个和下一个页的编号，所以所有的数据页会组成一个双链表 为保证从内存中同步到磁盘的页的完整性，在页的首部和尾部都会存储页中数据的校验和和页面最后修改时对应的LSN值，如果首部和尾部的校验和和LSN值校验不成功的话，就说明同步过程出现了问题 undo 页 undo Log Page 系统页 System Page Transaction system Page Insert Buffer Bitmap Insert Buffer Free List Uncompressed BLOB Page compressed BLOB Page 行每个页最多允许存放 16 KB &#x2F; 2 - 200 行的记录，即 7992 行 行格式有 4 种不同类型的行格式，分别是 Compact、Redundant、Dynamic 和 Compressed 指定行格式： 123CREATE TABLE 表名 (列的信息) ROW_FORMAT=行格式名称 ALTER TABLE 表名 ROW_FORMAT=行格式名称 Compact 记录被分为 额外信息 和 真实数据 额外信息是为了描述这条记录而不得不额外添加的一些信息，分为 3 类，分别是 变长字段长度列表、NULL 值列表 和 记录头信息 变长字段长度列表 所有变长字段( 如 VARCHAR(M)、VARBINARY(M)、各种 TEXT、BLOB 类型 )的真实数据占用的字节长度，形成一个变长字段长度列表，各变长字段数据占用的字节数按照 列的顺序 逆序 存放 变长字段中存储多少字节的数据是不固定的，要把这些数据占用的字节数也存起来( 十六进制 )，才不至于把 MySQL 服务器搞懵 变长字段长度列表中只存储值为 非 NULL 的列内容占用的长度，值为 NULL 的列的长度是不储存的 对于 CHAR(M) 类型的列来说，当列采用的是定长字符集时，该列占用的字节数不会被加到变长字段长度列表，而如果采用变长字符集时，该列占用的字节数也会被加到变长字段长度列表 逆序存放！！！ NULL 值列表 把这些值为 NULL 的列统一管理起来，存储到 NULL 值列表中，不然存储会很占地方 如果表中没有允许存储 NULL 的列，那就不会有 NULL 值列表 将每个允许存储 NULL 的列对应一个 二进制位，二进制位按照列的顺序 逆序 排列 二进制位的值为 1 时，代表该列的值为 NULL 二进制位的值为 0 时，代表该列的值不为 NULL 逆序！！！ 记录头信息 由固定的 5 个字节( 也就是 40 个二进制位 )组成 真实数据 除了自己定义的列，还有隐藏列，如 DB_ROW_ID、DB_TRX_ID、DB_ROLL_PTR，分别表示 行 ID，唯一标识一条记录、事务 ID、回滚指针 InnoDB 表主键的生成策略：优先使用用户自定义主键作为主键，如果用户没有定义主键，则选取一个 Unique 键作为主键，如果表中连 Unique 键都没有定义的话，则 InnoDB 会为表默认添加一个名为 DB_ROW_ID 的隐藏列作为主键 Redundant老，略 溢出在 Compact 和 Reduntant 行格式中，对于占用存储空间非常大的列，在记录的真实数据处只会存储该列的一部分数据，把剩余的数据分散存储在几个其他的页中，然后记录的真实数据处用 20 个字节存储指向这些页的地址( 这 20 个字节中还包括这些分散在其他页面中的数据的占用的字节数 )，从而可以找到剩余数据所在的页 Dynamic 与 Compressed它们不会在记录的真实数据处存储字段真实数据的前 768 个字节，而是把 所有的字节 都存储到其他页面中，只在记录的真实数据处存储其他页面的地址 与 Dynamic 不同的是，Compressed 行格式会采用压缩算法对页面进行压缩，以节省空间 架构 InnoDB有多个内存块，可以认为这些内存块组成了一个大的内存池，作用： 维护线程 缓存 后台线程 Master Thread IO Thread Purge Thread Page Cleaner Thread 内存内存组成： innodb_buffer_pool 缓冲池 redo log_buffer 重做日志缓冲 innodb_additional_men_pool_size 额外内存池 缓冲池作用是提高性能： 读取：硬盘读到的数据 → 缓冲池，下次读相同的页，看缓冲池有没有，没有再去硬盘找 修改：改缓冲池 → 以一定频率刷新到硬盘 Checkpoint 机制 缓存的数据页类型有： data page 数据页 index page 索引页 [insert buffer 插入缓存](#Insert Buffer) [adaptive hash index 自适应哈希索引](#Adaptive Hash Index) lock info 锁信息 data dictionary 数据字典 缓冲池的组成： ( 碎片：分配空间后，剩余的不够一个页( 16 KB ( 未压缩 ) )，就成了碎片 ) 允许多个缓冲池实例，每个页根据 hash 值平均分配到不同缓冲池实例 管理缓冲池主要使用的 List： LRU List：左边是热区( new )，右边是 old，当缓冲区满了，就释放末尾的页( new 和 old 是相对 midpoint 来说的 ) 防止全表扫描污染缓冲池，有： midpoint 新读取到的页不是加入 LRU 首部，而是放入 midpoint 位置( 默认在 LRU 5&#x2F;8 处 ) 可以通过 innodb_old_blocks_pct 改 innodb_old_blocks_time 表示页读取到 mid 位置后还需要多长时间才加入 LRU 热端 Free List：记录空闲的页 有维护一个控制信息，记录了头&#x2F;尾地址，以及数量 Buffer Pool 初始化的时候已经分配好了控制块和缓存页，只是没有数据。此时 LRU List 为空，所有页都在 Free List 每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free List 中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的 Free List 节点从链表中移除，放入 LRU List，表示该页已经被使用了 如果 Free List 没空闲的，就要移除 LRU List 末尾的页 Flush List 结构与 Free List 相似 Flush List 存储的是 dirty page 脏页( 是指针，指向 LRU List 的脏页 ) 脏页既存在于 LRU List，也在 Flush List 这里的脏页修改指的此页被加载进 Buffer Pool 后第一次被修改，只有第一次被修改时才需要加入 Flush List ( 代码中是根据 Page 头部的 oldest_modification &#x3D;&#x3D; 0 来判断是否是第一次修改 )，如果这个页被再次修改就不会再放到 Flush List 了，因为已经存在 并且在 Flush List 中的脏页是根据 oldest_lsn ( 这个值表示这个页第一次被更改时的 lsn 号，对应值 oldest_modification，每个页头部记录 )进行排序刷新到磁盘的，值越小表示要最先被刷新，避免数据不一致 Checkpoint 机制 重做日志缓冲 InnoDB 首先将重做日志信息放入 redo log buffer，然后按一定频率将其刷新到 重做日志文件 一般情况，每一秒会将重做日志缓冲刷新到日志文件 缓冲大小由 innodb_log_buffer_size 控制，默认的 8 MB 已经基本满足每一秒发生的事务量 刷入磁盘的时机： Master Thread 每秒都会刷新 每个事务提交时会刷新 当 重做日志缓冲 空间小于 1&#x2F;2 时，会刷新 Change Buffer 参考 注意：唯一索引普通索引选择难题 对于一个字段，比如身份证，是选择唯一索引，还是普通索引？ 对于查询来说，差距微乎其微，即使是普通索引，相同的值也在页的同一个位置（再不济也在隔壁吧~），而唯一索引查到了就停止了 对于更新来说，就会影响了 change buffer：当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。 需要说明的是，虽然名字叫作change buffer，实际上它是可以持久化的数据。也就是说，change buffer在内存中有拷贝，也会被写入到磁盘上 将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。除了访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中，也会执行merge操作。 对于唯一索引来说，更新时必须验证整个表都没有这个值，必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer了 change buffer 实际上也只有普通索引可以使用 将更新操作先记录在change buffer，减少读磁盘，语句的执行速度会得到明显的提升 Checkpoint主要解决： 缩短数据库恢复时间 重做日志中记录了 Checkpoint 的位置，这个点之前的页已经刷新回磁盘，只需要对 Checkpoint之后的重做日志进行恢复。这样就大大缩短了恢复时间 缓冲池不够用时，将脏页刷新到磁盘 缓冲池不够用时，根据 LRU 算法，溢出最近最少使用的页，如果页为脏页，强制执行 Checkpoint，将脏页刷新回磁盘 重做日志不可用时，刷新脏页 重做日志写满了，但脏页还在 Flush List 里面，没有刷到磁盘。要强制产生 Checkpoint，将缓冲池中的页至少刷新到当前位置 引入 LSN ( Log Sequence Number ) 就是字面意思 每个页都有 LSN，重做日志也有，Checkpoint 也有 实现： 有三种 Checkpoint： Sharp Checkpoint：在数据库关闭时使用，将所有的脏页都刷新回磁盘 Fuzzy Checkpoint：在数据库运行时使用，只刷新一部分脏页 MasterThread Checkpoint 每秒&#x2F;十秒从 Flush List 刷新一定比例脏页到磁盘 FLUSH_LRU_LIST Checkpoint 解决上面的 “缓冲池不够用时，将脏页刷新到磁盘“ Async&#x2F;Sync Flush Checkpoint ( 在 Page Cleaner Threader 中操作 ) 解决上面的 “重做日志不可用” 强制把一些页刷回磁盘( 从 Flush List 获取 ) 把已经写入重做日志的 LSN 称为 redo_lsn，已经刷回磁盘的最新的 LSN 称为 checkpoint_lsn，则有： 1checkpoint_age = redo_lsn - checkpoint_lsn 1async_water_mark = 75% * total_redo_log_file_size 1sync_water_mark = 90% * total_redo_log_file_size 如果 checkpoint_age &lt; async_water_mark：不需要刷新 如果 sync_water_mark &gt; checkpoint_age &gt; async_water_mark：从 Flush List 刷新足够脏页到磁盘。使得 checkpoint_age &lt; async_water_mark 如果 checkpoint_age &gt; sync_water_mark，很少发生。和上面一样 Dirty Page too much 脏页太多，强制 Checkpoint 总的来说还是为了保证缓冲池有足够的页 关键特性5个Insert Buffer插入缓存 增强插入性能 使用的条件 索引是辅助索引( secondary index ) 索引不是唯一的( unique ) 对于非聚集索引的插入和更新操作，不是每一次直接插入到索引页中，而是先判断插入非聚集索引页是否在缓冲池中，若存在，则直接插入，不存在，则先放入一个 Insert Buffer 对象中。数据库这个非聚集的索引已经插到叶子节点，而实际并没有，只是存放在另一个位置。然后再以一定的频率和情况进行 Insert Buffer 和辅助索引页子节点的 merge( 合并 )操作，这时通常能将多个插入合并到一个操作中( 因为在一个索引页中 )，这就大大提高了对于非聚集索引插入的性能 Double Write两次写 https://www.cnblogs.com/geaozhang/p/7241744.html#gongzuoliucheng 《内幕》P53 增强可靠性 重做日志记录的是对页的物理修改，如果页本身已经损坏，重做日志也无能为力 在应用重做日志前，需要一个页的副本，当写入失败时，先用副本来还原这个页，在进行重做 关键词：内存、共享表空间、各个表空间、副本在共享表空间、顺序写（写进共享表空间）、随机写（内存到各个表空间）、2M、1M Adaptive Hash IndexAHI 自适应哈希索引 AHI 是通过缓冲池的 B+ 树页构造出来的，不需要对整张表构建 Async IOAIO、异步 IO Flush Neighbor Page刷新邻接页 当刷新一个脏页时，会检测该页所在区( extent )的所有页，如果是脏页，也一并刷新 视图虚表 某个查询语句的一个别名 在存储视图的时候是不需要存储真实的数据的，只需要把它的结构存储起来就行了 索引B+ 树索引一个 B+ 树索引的根节点自诞生之日起，便不会再移动 最下边一层是叶子节点，其余的是内节点 B+ 树找到的是 被查找数据行 所在的 页，然后把页读到内存，在内存找 一个页最少存储 2 条记录 一般情况下，我们用到的 B+ 树都不会超过 4 层，通过主键值去查找某条记录最多只需要做 4 个页面内的查找( 查找 3 个目录项页和一个用户记录页 ) 在 InnoDB 中，索引即数据，数据即索引 MyISAM 将索引和数据分开存储，对数据&#x2F;用户记录没有按主键大小排序，而是有个行号，索引叶子节点不存数据，而是存主键 + 行号，即先通过索引找行号，再根据行号找完整的数据( 对其他列建立的索引也是这样 ) 也就是说，MyISAM 中建立的索引相当于全部都是 二级索引 使用二分法查找 大目录嵌套小目录，小目录表示的才是数据 即数据都在树的叶子节点上( 完整的用户记录 ) 对于一条记录( record )，有分为 用户记录( 0 )、目录项记录( 1 )、最小记录( 2 )、最大记录( 3 )，由 记录头信息 里的 record_type 决定 目录项中的两个列是 主键 和 页号 主键 key：页的用户记录中 最小 的主键值 页号 page_no 用户记录包含完整的数据，存储了所有列的值 聚簇索引而 B+ 树索引叫做 聚簇( chu4 )索引 聚簇索引的两个特性： 使用 记录主键值的大小 进行记录和页的排序，包括 页内的 记录 是按照主键的大小顺序排成一个 单向链表 各个存放用户记录的 页 也是根据页中用户记录的主键大小顺序排成一个 双向链表 存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的主键大小顺序排成一个 双向链表 B+树的叶子节点存储的是 完整的用户记录 所谓完整的用户记录，就是指这个记录中存储了所有列的值（包括隐藏列） InnoDB 会自动的为我们创建聚簇索引 聚簇索引只能在搜索条件是主键值时才能发挥作用 二级索引与联合索引( 注意回表 )也叫非聚簇索引 针对某一列叫二级索引，多个列叫联合索引，联合索引 本质上也是 二级索引 对二级索引来说 用户记录里只有 b 列的数据( b 列数据 + 主键 )，不包含其他列 目录项记录是 b 列最小值 + 页号 + 对应主键 因为 b 列不唯一，主键值是为了在有 b 列值相同的时候，防止插入时懵逼，不知道插入哪个页，即先比 b 列，如果一样，再比主键 所以在二级索引中，要通过某一列的值查用户数据，需要查到二级索引的叶子节点的用户记录，拿到用户记录里的主键值，再去 聚簇索引 里找完整的用户记录 这个过程称为 回表 ( 通过某列的值查找完整的用户记录需要使用到 2 棵 B+ 树 )，所以叫做二级索引 找第一次的时候，因为记录都是连在一起的，叫 顺序 IO，而找第二次时，主键可能是不连续的，这就导致了 随机 IO 需要回表的记录越多，使用二级索引的性能就越低 如果第一次返回的记录占比很大，那么第二次回表随机 IO 花费的也就越多，还不如直接聚簇索引( 全表扫描 ) 而决定什么时候用全表扫描，什么时候是 二级索引 + 回表，就是 查询优化器 的工作了 为避免回表，应该尽量 索引覆盖 对联合索引来说 假如针对 b、c 列建立联合索引，就先按 b 列进行排序，再按 c 列进行排序 目录项记录是 b最小值 + c最小值 + 页号 + 对应主键 用户记录是 b + c + 对应主键 基本操作InnoDB 和 MyISAM 都会自动为主键或者声明为 UNIQUE 的列去建立 B+ 树索引 在创建表的时候指定需要建立索引的单个列或者建立联合索引的多个列： 1234CREATE TALBE 表名 ( 各种列的信息 ··· , [KEY|INDEX] 索引名 (需要被索引的单个列或多个列)) 其中的 KEY 和 INDEX 是同义词，任意选用一个就可以。我们也可以在修改表结构的时候添加索引： 1ALTER TABLE 表名 ADD [INDEX|KEY] 索引名 (需要被索引的单个列或多个列); 也可以在修改表结构的时候删除索引： 1ALTER TABLE 表名 DROP [INDEX|KEY] 索引名; 比方说我们想在创建 index_demo 表的时候就为 c2 和 c3 列添加一个 联合索引，可以这么写建表语句： 1234567CREATE TABLE index_demo( c1 INT, c2 INT, c3 CHAR(1), PRIMARY KEY(c1), INDEX idx_c2_c3 (c2, c3)); 在这个建表语句中我们创建的索引名是 idx_c2_c3，这个名称可以随便起，不过我们还是建议以 idx_ 为前缀，后边跟着需要建立索引的列名，多个列名之间用下划线 _ 分隔开。 如果我们想删除这个索引，可以这么写： 1ALTER TABLE index_demo DROP INDEX idx_c2_c3; WHERE 子句中的几个搜索条件的顺序对查询结果没有影响，有 查询优化器，会分析这些搜索条件并且按照可以使用的索引中列的顺序来决定先使用哪个搜索条件，后使用哪个搜索条件 适用条件全值匹配、匹配左边连续列、匹配列前缀、匹配范围值、精确匹配某一列并范围匹配另外一列、用于排序、用于分组 a、全值匹配…就是全值匹配… b、匹配左边连续列搜索条件中的各个列必须是联合索引中从最左边连续的列 c、匹配列前缀&#39;As%&#39; 可以，&#39;%As%&#39; 不行 d、匹配范围值如果对多个列同时进行范围查找的话，只有对索引最左边的那个列进行范围查找的时候才能用到 B+ 树索引 e、精确匹配某一列并范围匹配另外一列…就是精确匹配某一列并范围匹配另外一列 f、用于排序一般情况下，把记录都加载到内存中，再用一些排序算法，在内存中对这些记录进行排序，有的时候结果集太大以至于不能在内存中进行排序，就得暂时借助磁盘的空间来存放中间结果，排序操作完成后再把排好序的结果集返回到客户端 在 MySQL 中，把在内存中或者磁盘上进行排序的方式统称为文件排序( filesort ) 如果 ORDER BY 子句里使用到了我们的索引列，就有可能省去在内存或文件中排序的步骤 ORDER BY 的子句后边的列的 顺序 也必须按照索引列的顺序给出 不能使用索引进行排序的情况 ASC、DESC 混用 WHERE 子句出现非排序使用到的索引列 排序列包含非同一个索引的列 有时候用来排序的多个列不是一个索引里的，这种情况也不能使用索引进行排序 排序列使用了复杂的表达式 要想使用索引进行排序操作，必须保证索引列是以单独列的形式出现，而不是修饰过的形式，如使用一些 函数 g、用于分组如果按索引来分组 GROUP BY，就能用到索引 总的来说一切按照 B+ 树节点的存放方式来决定 索引的代价 空间 每建立一个索引都要为它建立一棵 B+ 树，每一棵 B+ 树的每一个节点都是一个数据页，一个页默认会占用 16KB 的存储空间，一棵很大的 B+ 树由许多数据页组成 时间 每次对表中的数据进行增、删、改操作时，都需要去修改各个 B+ 树索引 查询优化器查询优化器会事先对表中的记录计算一些统计数据，然后再利用这些统计数据根据查询的条件来计算一下需要回表的记录数，需要回表的记录数越多，就越倾向于使用全表扫描，反之倾向于使用 二级索引 + 回表 的方式 一般情况下，限制查询获取较少的记录数会让优化器更倾向于选择使用 二级索引 + 回表 的方式进行查询，因为回表的记录越少，性能提升就越高 覆盖索引为了避免 回表 操作带来的性能损耗，最好在 查询列表里只包含索引列 对这种查询&#x2F;排序条件只用到索引的方式称为 索引覆盖 索引的挑选只为用于搜索、排序或分组的列创建索引考虑列的基数 列的基数 指的是某一列中 不重复数据 的个数 在记录行数一定的情况下，列的基数越大，该列中的值越分散，列的基数越小，该列中的值越集中 最好为那些列的基数大的列建立索引，为基数太小列的建立索引效果可能不好 索引列的类型尽量小 数据类型越小，在查询时进行的比较操作越快( CPU 的层次 ) 数据类型越小，索引占用的存储空间就越少，在一个数据页内就可以放下更多的记录，从而减少磁盘I/O带来的性能损耗，也就意味着可以把更多的数据页缓存在内存中，从而加快读写效率 索引字符串值的前缀只对字符串的前几个字符进行索引 1234567CREATE TABLE person_info( name VARCHAR(100) NOT NULL, birthday DATE NOT NULL, phone_number CHAR(11) NOT NULL, country varchar(100) NOT NULL, KEY idx_name_birthday_phone_number (name(10), birthday, phone_number)); name(10) 就表示在建立的 B+ 树索引中只保留记录的前 10 个字符的编码，这种只索引字符串值的前缀的策略是非常鼓励的，尤其是在字符串类型能存储的字符比较多的时候 但是这种就用不了索引排序了，因为只对前几个字符进行索引，后面的字符都是无序的 让索引列在比较表达式中单独出现有一个整数列 my_col，我们为其建立了索引。有下边的两个WHERE子句 WHERE my_col * 2 &lt; 4 WHERE my_col &lt; 4/2 第1个 my_col 并不是以单独列的形式出现的，存储引擎会依次遍历所有的记录，计算这个表达式的值是不是小于 4，这种情况下是使用不到 B+ 树索引的 第2个 my_col 是以单独列的形式出现的，这样的情况可以直接使用 B+树索引 主键插入顺序让主键具有 AUTO_INCREMENT，让存储引擎自己为表生成主键 因为如果一个主键 1 ~ 20 的数据页满了，这时候插进去一个主键是 5 的，就得分成两个页，造成性能损耗 避免冗余和重复索引全文索引通常使用倒排索引( inverted index )innodb 使用 full inverted index 哈希索引就是上面的 [自适应哈希索引](#Adaptive Hash Index) Innodb 会监控对表上二级索引的查找，如果发现某二级索引被频繁访问，二级索引成为热数据，建立哈希索引可以带来速度的提升 要求：对这个页的连续访问模式都是一样的，访问模式即查询条件 特点 1、无序，没有树高 2、降低对二级索引树的频繁访问资源 3、自适应 缺陷 1、hash 自适应索引会占用 innodb buffer pool 2、自适应 hash 索引只适合搜索等值的查询，如 select * from table where index_col&#x3D;’xxx’，而对于其他查找类型，如范围查找，是不能使用的 3、极端情况下，自适应 hash 索引才有比较大的意义，可以降低逻辑读 事务ACID 原子性（Atomicity）[ˌætəˈmisiti:] 转账不能转一半 一致性（Consistency） 隔离性（Isolation）[ˌaisəˈleiʃən] 执行顺序有一定规律 持久性（Durability）[ˌdjʊərəˈbɪlɪtɪ&#x2F;] 事务的状态 提交autocommit：默认ON，每一条语句都算是一个独立的事务 隐式提交：即使 autocommit off，也会隐式提交（结构变化） 保存点SAVEPOINT 保存点名称; ROLLBACK [WORK] TO [SAVEPOINT] 保存点名称; RELEASE SAVEPOINT 保存点名称; redo事务提交后还在内存，但是如果故障，内存数据都没了 我们只是想让已经提交了的事务对数据库中数据所做的修改永久生效，即使后来系统崩溃，在重启后也能把这种修改恢复出来 只需要把修改了哪些东西记录一下就好 是顺序写的 redo 有 redo log buffer（重做日志缓冲，易丢失） 和 redo log file（重做日志文件，持久的） 事务提交时，必须先把日志写到重做日志文件（这里指 redo log 和 undo log）进行持久化 把一条记录插入到一个页面时需要更改的地方非常多，所以有很多类型的 redo log MLOG_REC_INSERT（对应的十进制数字为 9）：表示插入一条使用非紧凑行格式的记录时的redo日志类型 MLOG_COMP_REC_INSERT（对应的十进制数字为 38）：表示插入一条使用紧凑行格式的记录时的redo日志类型 MLOG_COMP_PAGE_CREATE（type 字段对应的十进制数字为 58）：表示创建一个存储紧凑行格式记录的页面的redo日志类型 MLOG_COMP_REC_DELETE（type 字段对应的十进制数字为 42）：表示删除一条使用紧凑行格式记录的redo日志类型 … 这些类型的 redo log 既包含物理层面的意思，也包含逻辑层面的意思，具体指： 物理层面看，这些日志都指明了对哪个表空间的哪个页进行了修改 逻辑层面看，在系统奔溃重启时，并不能直接根据这些日志里的记载，将页面内的某个偏移量处恢复成某个数据，而是需要调用一些事先准备好的函数，执行完这些函数后才可以将页面恢复成系统奔溃前的样子 对 redo 日志中的某些数据还可能进行压缩处理 底层页面中的一次原子访问的过程称之为一个 Mini-Transaction，简称 mtr 对于 redo log 组，因为一条 redo 可能导致很多操作，如页分裂啥的，需要保证原子性，所以要在该组中的最后一条 redo 日志后边加上一条特殊类型的 redo 日志，该类型名称为MLOG_MULTI_REC_END（他只有一个type字段） 对于 Mini-Transaction 通过mtr生成的redo日志都放在了大小为512字节的页中，叫 redo log block 真正的 redo 日志都是存储到占用 496 字节大小的 log block body 中 redo log buffer（redo日志缓冲区） 每个 mtr 运行过程中产生的日志先暂时存到一个地方，当该 mtr 结束的时候，将过程中产生的一组 redo 日志再全部复制到 log buffer 中，不同事务的 mtr 可能是交替写入 log buffer 的 redo 日志刷盘时机是 log buffer 空间不足时（超过一半） 事务提交时 后台线程（每秒） 正常关闭服务器时 checkpoint … 需要调用一下操作系统提供的fsync函数才可以 恢复 checkpoint_lsn undoundo log 撤销日志，用来帮助事务回滚和 MVCC 隐藏列：roll_pointer 改动时，都会把旧的版本写入到 undo 日志中，这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息 是随机读写的 事务 id 只有在事务对表中的记录做改动时才会为这个事务分配一个唯一的事务 id 事务隔离事务并发会遇到的问题 脏写：一个事务修改了另一个未提交事务修改过的数据 脏读：一个事务读到了另一个未提交事务修改过的数据 不可重复读：一个事务读到另一个事务修改过的数据，并且其他事务每对该数据进行一次修改后，该事务查询到的是不一样的值 幻读：一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中插入了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来 幻读强调的是一个事务按照某个相同条件多次读取记录时，后读取时读到了之前没有读到的记录，如果后读取时没有读到，那就是不可重复读 不论是哪种隔离级别，都不允许脏写的情况发生 严重性：脏写 &gt; 脏读 &gt; 不可重复读 &gt; 幻读 不可重复读和幻读有什么区别？ (1) 不可重复读是读取了其他事务更改的数据，针对 update 操作 (2) 幻读是读取了其他事务新增的数据，针对 insert 和 delete 操作 既想保持事务的隔离性（按顺序来），又想让服务器在处理访问同一数据的多个事务时性能尽量高些，所以有隔离级别这东西 隔离级别 脏读 不可重复读 幻读 READ UNCOMMITTED 读未提交 Possible Possible Possible READ COMMITTED 读已提交 Not Possible Possible Possible REPEATABLE READ 可重复读 Not Possible Not Possible Possible SERIALIZABLE 可串行化 Not Possible Not Possible Not Possible Oracle 只支持 READ COMMITTED 和 SERIALIZABLE 隔离级别 MySQL 在 REPEATABLE READ 隔离级别下，是可以防止幻读问题的发生 MySQL的默认隔离级别为 REPEATABLE READ 设置隔离级别：SET [GLOBAL|SESSION] TRANSACTION ISOLATION LEVEL level; level REPEATABLE READ READ COMMITTED READ UNCOMMITTED SERIALIZABLE GLOBAL、SESSION或者什么都不放 MVCC 版本链 每次对记录进行改动，都会记录一条undo日志，每条undo日志也都有一个roll_pointer属性（INSERT操作对应的undo日志没有该属性，因为该记录并没有更早的版本），可以将这些undo日志都连起来，串成一个链表。版本链的头节点就是当前记录最新的值 ReadView 需要判断一下版本链中的哪个版本是当前事务隔离级别可见的 m_ids、min_trx_id、max_trx_id、creator_trx_id 在访问某条记录时 如果被访问版本的trx_id属性值与ReadView中的creator_trx_id值相同，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问 如果被访问版本的trx_id属性值小于ReadView中的min_trx_id值，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问 如果被访问版本的trx_id属性值大于ReadView中的max_trx_id值，表明生成该版本的事务在当前事务生成ReadView后才开启，所以该版本不可以被当前事务访问 如果被访问版本的trx_id属性值在ReadView的min_trx_id和max_trx_id之间，那就需要判断一下trx_id属性值是不是在m_ids列表中，如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问 READ COMMITTD 在每一次进行普通 SELECT 操作前都会生成一个 ReadView，而 REPEATABLE READ 只在第一次进行普通 SELECT 操作前生成一个 ReadView，之后的查询操作都重复使用这个 ReadView 就好了 purge在确定系统中包含最早产生的那个 ReadView 的事务不会再访问某些 update undo 日志以及被打了删除标记的记录后，有一个后台运行的 purge 线程会把它们真正的删除掉 锁锁结构主要属性 trx信息：代表这个锁结构是哪个事务生成的 is_waiting：代表当前事务是否在等待 当某事务改动了这条记录后，就生成了一个锁结构与该记录关联，因为之前没有别的事务为这条记录加锁，所以 is_waiting 属性就是false，我们把这个场景就称之为获取锁成功，或者加锁成功，然后就可以继续执行操作了 另一个事务也想对该记录做改动，那么先去看看有没有锁结构与这条记录关联，发现有一个锁结构与之关联后，然后也生成了一个锁结构与这条记录关联，不过锁结构的 is_waiting 为 true，表示当前事务需要等待，我们把这个场景就称之为获取锁失败，或者加锁失败，或者没有成功的获取到锁 在持有锁事务提交之后，就会把该事务生成的锁结构释放掉，然后看看还有没有别的事务在等待获取锁，发现了另一个事务还在等待获取锁，所以把那个事务对应的锁结构的 is_waiting 属性设置为 false，然后把该事务对应的线程唤醒，让它继续执行，此时那个事务就算获取到锁了 锁类别 共享锁（S锁） 独占锁（X锁） 意向锁（是表级锁） 意向共享锁（IS锁）：当事务准备在某条记录上加S锁时，需要先在表级别加一个IS锁 意向独占锁（IX锁）：当事务准备在某条记录上加X锁时，需要先在表级别加一个IX锁 InnoDB的表级锁 InnoDB的行级锁（记录锁） Record Locks Gap Locks（gap锁） gap锁的提出仅仅是为了防止插入幻影记录而提出的 Next-Key Locks（next-key锁 既想锁住某条记录，又想阻止其他事务在该记录前边的间隙插入新记录 Insert Intention Locks（插入意向锁 隐式锁 备份与恢复调优 https://coolshell.cn/articles/1846.html Explain id 在一个大的查询语句中每个SELECT关键字都对应一个唯一的id 在连接查询的执行计划中，每个表都会对应一条记录，这些记录的id列的值是相同的，出现在前边的表表示驱动表，出现在后边的表表示被驱动表 在包含子查询的查询语句的执行计划中，每个SELECT关键字都会对应一个唯一的id值 查询优化器可能对涉及子查询的查询语句进行重写，从而转换为连接查询 两个表的 UNION 是有三个 id，因为还有一个临时表，id 为 NULL 表明这个临时表是为了合并两个查询的结果集去重而创建的 UNION ALL 就只有两个，不需要去重 select_type SELECT关键字对应的那个查询的类型 PRIMARY：对于包含UNION、UNION ALL或者子查询的大查询来说，它是由几个小查询组成的，其中最左边的那个查询的select_type值就是PRIMARY UNION：对于包含UNION或者UNION ALL的大查询来说，它是由几个小查询组成的，其中除了最左边的那个小查询以外，其余的小查询的select_type值就是UNION UNION RESULT：UNION 临时表 SUBQUERY：如果包含子查询的查询语句不能够转为对应的semi-join的形式，并且该子查询是不相关子查询，并且查询优化器决定采用将该子查询物化的方案来执行该子查询时，该子查询的第一个SELECT关键字代表的那个查询的select_type就是SUBQUERY，由于select_type为SUBQUERY的子查询由于会被物化，所以只需要执行一遍 https://www.modb.pro/db/29203 DEPENDENT SUBQUERY：子查询是相关子查询，DEPENDENT SUBQUERY的查询可能会被执行多次 DEPENDENT UNION DERIVED MATERIALIZED table 表名 partitions 匹配的分区信息 type 针对单表的访问方法 system：当表中只有一条记录并且该表使用的存储引擎的统计数据是精确的，比如MyISAM、Memory const：根据主键或者唯一二级索引列与常数进行等值匹配 eq_ref：在连接查询时，如果被驱动表是通过主键或者唯一二级索引列等值匹配的方式进行访问的 ref：通过普通的二级索引列与常量进行等值匹配时来查询某个表，可能是ref ref_or_null：当对普通二级索引进行等值匹配查询，该索引列的值也可以是NULL值，可能 index_merge：索引合并 range：范围区间 index：覆盖索引，但是没有匹配所有索引列 ALL：全表 possible_keys 可能用到的索引 key 实际上使用的索引 key_len 实际使用到的索引长度 ref 当使用索引列等值查询时，与索引列进行等值匹配的对象信息 rows 预估的需要读取的记录条数 filtered 某个表经过搜索条件过滤后剩余记录条数的百分比 Extra 一些额外的信息 Using index：可以使用索引覆盖 Using index condition：搜索条件中虽然出现了索引列，但却不能使用到索引 SELECT * FROM s1 WHERE key1 &gt; ‘z’ AND key1 LIKE ‘%a’;其中的key1 &gt; ‘z’可以使用到索引，但是key1 LIKE ‘%a’却无法使用到索引，在以前版本的MySQL中，是按照下边步骤来执行这个查询的： 先根据key1 &gt; ‘z’这个条件，从二级索引idx_key1中获取到对应的二级索引记录。 根据上一步骤得到的二级索引记录中的主键值进行回表，找到完整的用户记录再检测该记录是否符合key1 LIKE ‘%a’这个条件，将符合条件的记录加入到最后的结果集。 但是虽然key1 LIKE ‘%a’不能组成范围区间参与range访问方法的执行，但这个条件毕竟只涉及到了key1列，所以新版本MySQL把上边的步骤改进了一下： 先根据key1 &gt; ‘z’这个条件，定位到二级索引idx_key1中对应的二级索引记录。 对于指定的二级索引记录，先不着急回表，而是先检测一下该记录是否满足key1 LIKE ‘%a’这个条件，如果这个条件不满足，则该二级索引记录压根儿就没必要回表。 对于满足key1 LIKE ‘%a’这个条件的二级索引记录执行回表操作。 我们说回表操作其实是一个随机IO，比较耗时，所以上述修改虽然只改进了一点点，但是可以省去好多回表操作的成本。设计MySQL的大叔们把他们的这个改进称之为索引条件下推（英文名：Index Condition Pushdown）。 Using where：使用全表扫描来执行对某个表的查询，并且该语句的WHERE子句中有针对该表的搜索条件 EXPLAIN FORMAT&#x3D;JSON + 语句 json格式的执行计划 SHOW WARNINGS 使用EXPLAIN语句查看了某个查询的执行计划后，紧接着还可以使用SHOW WARNINGS语句查看与这个查询的执行计划有关的一些扩展信息 高可用主从复制 参考 分表 参考 中间件：sharding-sphere、sharding-jdbc 1、垂直拆分（分字段）在实际业务中用的不多，麻烦 2、水平拆分 3、MySQL 分区表 HASH 分区 分库按业务拆库和按表分库 按表分库：垂直分库和水平分库 乱七八糟数据库三大范式 第一范式：每个列都不可以再拆分 第二范式：在第一范式的基础上，非主键列完全依赖于主键，而不能是依赖于主键的一部分 第三范式：在第二范式的基础上，非主键列只依赖于主键，不依赖于其他非主键","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://kebabshellgithub.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"https://kebabshellgithub.github.io/tags/MySQL/"}]},{"title":"Java基础","slug":"Java基础","date":"2020-05-12T22:47:35.000Z","updated":"2023-04-06T11:06:55.022Z","comments":true,"path":"2020/05/12/Java基础/","link":"","permalink":"https://kebabshellgithub.github.io/2020/05/12/Java%E5%9F%BA%E7%A1%80/","excerpt":"","text":"错题1、 1234567public class Test &#123; public static void main(String args[]) &#123; int x = -5; int y = -12; System.out.println(y % x); &#125;&#125; 取余取头，取模取尾 1.取余 rem(3,2)&#x3D;1 rem(-3,-2)&#x3D;-1 rem(3,-2)&#x3D;1 rem(-3,2)&#x3D;-1 2.取模 mod(3,2)&#x3D;1 mod(-3,-2)&#x3D;-1 mod(3,-2)&#x3D;-1 mod(-3,2)&#x3D;1 2、 重载 overload 就是同一个类中，有多个方法名相同，但参数列表不同（包括参数个数和参数类型），与返回值无关，与权限修饰符也无关 调用重载的方法时通过传递给它们不同的参数个数和参数类型来决定具体使用哪个方法，这叫多态 重写就是子类重写基类的方法，方法名，参数列表和返回值都必须相同，否则就不是重写而是重载 权限修饰符不能小于被重写方法的修饰符。重写方法不能抛出新的异常或者是比被重写方法声明更加宽泛的检查型异常 重写（overriding）：指在继承情况下，子类中定义了与其父类中方法具有相同型构的新方法，就称为子类把父类的方法重写了。这是实现多态必须的步骤。 重载（overloading）：指在同一个类中定义了一个以上具有相同名称，但是型构不同的方法。 返回值不能作为重载的依据 3、 Java 面向对象编程有三大特性：封装、继承、多态。 封装：隐藏对象的属性和实现细节，仅对外公开访问方法，控制在程序中属性的读和写的访问级别 继承：可以理解为，在一个现有类的基础之上，增加新的方法或重写已有方法，从而产生一个新类 继承都是单继承 接口是多继承多实现 多态：相同的事物，调用其相同的方法，参数也相同时，但表现的行为却不同。 继承是多态得以实现的基础 实现多态的三个必要条件 继承：在多态中必须存在有继承关系的子类和父类。 重写：子类对父类中某些方法进行重新定义，在调用这些方法时就会调用子类的方法。 向上转型：在多态中需要将子类的引用赋给父类对象，只有这样该引用才能够具备技能调用父类的方法和子类的方法。 类型 private 无修饰 protected public 同一类 可访问 可访问 可访问 可访问 同一包中的子类 不可访问 可访问 可访问 可访问 同一包中的非子类 不可访问 可访问 可访问 可访问 不同包中的子类 不可访问 不可访问 可访问 可访问 不同包中的非子类 不可访问 不可访问 不可访问 可访问 Java 中类可分为以下三种： 普通类：使用 class 定义且不含有抽象方法的类。 普通类可以继承（extends）普通类，可以继承（extends）抽象类，可以继承（implements）接口。 抽象类：使用 abstract class 定义的类，它可以含有或不含有抽象方法。 抽象类可以继承（extends）普通类，可以继承（extends）抽象类，可以继承（implements）接口。 接口：使用 interface 定义的类 接口只能继承（extends）接口 4、 sleep()方法（休眠）是线程类（Thread）的静态方法，调用此方法让当前线程暂停执行指定的时间，将执行机会（CPU）让给其他线程，但是对象的锁依然保持，因此休眠时间结束后会自动恢复（线程回到就绪状态，请参考第66题中的线程状态转换图）。wait()是Object类的方法，调用对象的wait()方法导致当前线程放弃对象的锁（线程暂停执行），进入对象的等待池（wait pool），只有调用对象的notify()方法（或notifyAll()方法）时才能唤醒等待池中的线程进入等锁池（lock pool），如果线程重新获得对象的锁就可以进入就绪状态。 5、 java中long类型自动转换为float类型 6、 volatile保证了其他线程的立即可见性，就没有保证原子性 由于有些时候对 volatile的操作，不会被保存，说明不会造成阻塞。不可用与多线程环境下的计数器 上下界泛型1234567891011121314151617181920212223242526272829303132public class Test_2 &#123; public static void main(String[] args) &#123; List&lt;? extends B&gt; list1 = new ArrayList&lt;&gt;(); // 上界 List&lt;? super B&gt; list2 = new ArrayList&lt;&gt;(); // 下界 A a = new A(); B b = new B(); C c = new C(); Object o = new Object(); // list1.add(o); 不能添加任何元素，因为List中具体是B的哪种子类无法确定 // list1.add(a); // list1.add(b); // list1.add(c); o = list1.get(0); a = list1.get(0); b = list1.get(0); // c = list1.get(0); 编译错误，编译器无法向下转型 // list2.add(o); 编译错误， // list2.add(a); 因为List中具体是B的哪种父类无法确定 list2.add(b); list2.add(c); o = list2.get(0); // a = list2.get(0); 编译错误，因为List中具体是B的哪种父类无法确定，无法向下转型，而Object是所有类的父类 // b = list2.get(0); // c = list2.get(0); &#125;&#125;class A &#123;&#125;class B extends A &#123;&#125;class C extends B &#123;&#125; 上界 上界用 extends 关键字声明，表示参数化的类型可能是所指定的类或者其任意子类。例如&lt;? extends B&gt;，泛型的上界就是 B 类。 形如 List&lt;? extends B&gt;，具体哪一种不能确定，既可以是 B，也可以是 C。在尝试执行 add() 方法时，List中的类型不能确定是具体哪一种，所以会编译报错。在执行 get() 方法时，不管是 B 还是 Ｃ，都可以以 Ａ 类对象来接收。所以 List&lt;? extends B&gt; 不能添加元素，具有只读属性，只能获取。 下界 下界用 super 关键字声明，表示参数化的类型可能是所指定的类型或者其任意父类。例如&lt;? super B&gt;，泛型的下界就是 B 类。 形如 List&lt;? super B&gt;，具体哪一种不能确定，既可以是 B，也可以是 A，直至 Object类。在尝试执行 add() 方法时，虽然 List 的具体类型不能确定，但是根据多态， B 类及其子类的对象肯定都可以被赋值给 B 的对象，所以只能添加 B 类及其子类的对象。在尝试执行 get() 方法时，List 中的类型是 B 类或者其父类的具体一种，向上直至 Object 类，所以只能将获取的元素赋值给 Object 对象。 Integer123456789Integer a = 1000;Integer b = 1000;System.out.println(a == b); // falseInteger c = 100;Integer d = 100;System.out.println(c == d); // true Debug 进入第一行： 12345public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; IntegerCache.low 是 -128 IntegerCache.high 是 127 Integer 有个内部类 IntegerCache，缓存了 -128 ~ 127 的 Integer 对象 这个范围内都是一个对象，超过这个范围就 new ，所以 1000 为 false MySQL一个字段同时满足多个条件 Interface接口是一种特殊的抽象类 接口中的变量默认是public static final 的，方法默认是public abstract 的 接口就是提供一种统一的’协议’,而接口中的属性也属于’协议’中的成员.它们是公共的,静态的,最终的常量.相当于全局常量.抽象类是不’完全’的类,相当于是接口和具体类的一个中间层.即满足接口的抽象,也满足具体的实现.如果接口可以定义变量，但是接口中的方法又都是抽象的，在接口中无法通过行为来修改属性。有的人会说了，没有关系，可以通过实现接口的对象的行为来修改接口中的属性。这当然没有问题，但是考虑这样的情况。如果接口A中有一个public访问权限的静态变量a。按照Java的语义，我们可以不通过实现接口的对象来访问变量a，通过A.a &#x3D; xxx;就可以改变接口中的变量a的值了。正如抽象类中是可以这样做的，那么实现接口A的所有对象也都会自动拥有这一改变后的a的值了，也就是说一个地方改变了a，所有这些对象中a的值也都跟着变了。这和抽象类有什么区别呢，怎么体现接口更高的抽象级别呢，怎么体现接口提供的统一的协议呢，那还要接口这种抽象来做什么呢？所以接口中不能出现变量，如果有变量，就和接口提供的统一的抽象这种思想是抵触的。所以接口中的属性必然是常量，只能读不能改，这样才能为实现接口的对象提供一个统一的属性。 通俗的讲，你认为是要变化的东西，就放在你自己的实现中，不能放在接口中去，接口只是对一类事物的属性和行为更高层次的抽象。对修改关闭，对扩展（不同的实现implements）开放，接口是对开闭原则的一种体现。 乱七八糟String 内部是 byte[] 字节数组实现 Java 中的 char 是 Unicode 编码，Unicode 编码占两个字节，就是 16 位，足够存储一个汉字 abstract 类 abstract 类不能与 final，static 一起使用。final修饰方法，子类可以调用，但不能覆盖。 abstract 类可以有 private 成员，但最好不要，因为私有和抽象放在一起，子类如果想重写父类的私有方法根本继承不过来，也就无法重写 abstract 类中可以有非抽象方法 abstract 类中可以都是非抽象的，但是抽象方法一定要在类和接口中 在 main() 方法中给出的字节数组，如果将其显示到控制台上，直接标准输出流 System.out.println() out 是 java.lang.System 类中的一个字段，out 是“标准“”输出流，public static final PrintStream out，out是PrintStream类型，PrintStream是包装流，你传入什么，他就输出什么 类变量 &#x3D; 静态变量，区分成员变量 类加载过程中只是对类变量进行初始化赋值（非真正的值），并没有对成员变量初始化，成员变量是实例化的时候才搞的 在集合中 vector：就比arraylist多了个同步化机制（线程安全），因为效率较低，现在已经不太建议使用。在web应用中，特别是前台页面，往往效率（页面响应速度）是优先考虑的。 stack：堆栈类，先进后出 hashtable：就比hashmap多了个线程安全 enumeration：枚举，相当于迭代器 除了这些之外，其他的都是非线程安全的类和接口。 Java程序初始化顺序： 父类的静态代码块 子类的静态代码块 父类的普通代码块 父类的构造方法 子类的普通代码块 子类的构造方法 日志的级别之间的大小关系如右所示：ALL &lt; TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL &lt; OFF Log4j建议只使用四个级别，优先级从高到低分别是 ERROR &gt; WARN &gt; INFO &gt; DEBUG log4j在运行期间是不可以重新设置的（springboot可以动态修改日志级别（https://blog.didispace.com/spring-boot-1-5-x-feature-1/）） 123456789101112131415float func3()&#123; long i= 3; return i;&#125;long转float，这个是对的loat占4个字节为什么比long占8个字节大呢，因为底层的实现方式不同。浮点数的32位并不是简单直接表示大小，而是按照一定标准分配的。第1位，符号位，即S接下来8位，指数域，即E。剩下23位，小数域，即M，取值范围为[1 ,2 ) 或[0 , 1)然后按照公式： V=(-1)^s * M * 2^E也就是说浮点数在内存中的32位不是简单地转换为十进制，而是通过公式来计算而来，通过这个公式虽然，只有4个字节，但浮点数最大值要比长整型的范围要大。 方法重写 两同两小一大原则： 两同：方法名和参数列表相同 两小：返回值或声明异常比父类小（或相同） 一大：访问修饰符比父类的大（或相同） 方法重写要注意的事项： 1.方法重写时， 方法名与形参列表必须一致。 2.方法重写时，子类的权限修饰符必须要大于或者等于父类的权限修饰符。 3.方法重写时，子类的返回值类型必须要小于或者等于父类的返回值类型。 4.方法重写时， 子类抛出的异常类型要小于或者等于父类抛出的异常类型。 default：https://my.oschina.net/dongtianxi/blog/757554 javac.exe是编译.java文件 java.exe是java虚拟机 javadoc.exe用来制作java文档 jdb.exe是java的调试器 javaprof.exe是剖析工具 Java体系结构包括四个独立但相关的技术： Java程序设计语言 Java.class文件格式 Java应用编程接口（API） Java虚拟机 当我们编写并运行一个Java程序时，就同时运用了这四种技术，用Java程序设计语言编写源代码，把它编译成Java.class文件格式，然后再在Java虚拟机中运行class文件。当程序运行的时候，它通过调用class文件实现了Java API的方法来满足程序的Java API调用 String对象不可变、StringBuffer对象可变的含义： 举个例子： String str &#x3D; “aa”; str &#x3D; “aa”+”bb”; 此时str的值为”aabb”，但是”aabb”不是在开始的字符串”aa”后面直接连接的”bb”，而是又新生成了字符串”aabb”，字符串”aa”一旦被初始化，那么它的值不可能再改变了。 StringBuffer strb &#x3D; StringBuffer(“aa”); strb.append(“bb”); 此时的strb的值也为”aabb”，但是”aabb”是直接在开始的字符串”aa”后面连接的“bb”，并没有生成新的字符串。 String str &#x3D;“”;System.out.print(str.split(“,”).length); 输出1 str.split(&quot;,&quot;)方法是把str字符串根据分割符&quot;,&quot;划分成一个字符串数组，如果str字符串中找不到分隔符&quot;,&quot;，则把整个str字符串放入字符串数组的第一个元素。因此str.split(&quot;,&quot;).length&#x3D;1。 抽象类中可以构造方法，接口不可以 线性结构 线性结构是一个有序数据元素的集合。 其中数据元素之间的关系是一对一的关系，即除了第一个和最后一个数据元素之外，其它数据元素都是首尾相接的。常用的线性结构有：线性表，栈，队列，双队列，数组，串。非线性结构中各个数据元素不再保持在一个线性序列中，每个数据元素可能与零个或者多个其他数据元素发生联系。根据关系的不同，可分为层次结构和群结构。常见的非线性结构有：二维数组，数组，广义表，树(二叉树等)，图。（其中数组是由多个一维数组组成的，所以不再是线性结构） 二叉树 参考 二叉树、平衡二叉树、满二叉树、完全二叉树、二叉搜索树、平衡二叉搜索树、红黑树、线索二叉树、哈夫曼树 完全二叉树是到最后一个叶子结点之前每个节点都不为空 平衡二叉树父节点的左子树和右子树的高度之差不能大于1 二叉搜索树是左边小于根节点，右边大于根节点 平衡二叉搜索树既满足平衡二叉树条件有满足二叉搜索树条件（红黑树） 哈夫曼树是最优二叉树，是一种带权路径长度最短的二叉树 权值越大的叶子节点越靠近根节点，权值越小的叶子节点越远离根节点。 只有度为0（叶子节点）和度为2（分支节点）的节点，没有度为1的节点。 没有强行说限制一定要0表示左子树，1表示右子树 图的拓扑排序 线索二叉树 二叉树在线索化后，仍不能有效求解的问题是后序线索二叉树中求后序后继 无向图边数的两倍等于各顶点度数的总和 array.sort((a,b)&#x3D;&gt;Math.abs(a-3)-Math.abs(b-3)); (a,b)&#x3D;&gt;Math.abs(a-3)-Math.abs(b-3)； 箭头函数表示：当Math.abs(a-3)&gt;Math.abs(b-3)时，a放在b后面，Math.abs(a-3)&lt;Math.abs(b-3)时，不交换位置，也就是说数组中的每一项减去3的绝对值越大越靠后。这里主要考的是对sort()方法的掌握。","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"Java 208道面试题","slug":"对于Java-208道面试题的转载和补充","date":"2020-05-03T16:33:38.000Z","updated":"2023-04-06T11:06:55.038Z","comments":true,"path":"2020/05/03/对于Java-208道面试题的转载和补充/","link":"","permalink":"https://kebabshellgithub.github.io/2020/05/03/%E5%AF%B9%E4%BA%8EJava-208%E9%81%93%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9A%84%E8%BD%AC%E8%BD%BD%E5%92%8C%E8%A1%A5%E5%85%85/","excerpt":"","text":"转载自这篇文章 JDK 和 JRE 有什么区别？ JDK是Java Development Kit(Java开发工具包)的简称，在开发的时候需要 JRE是Java Runtime Environment(Java运行环境)的简称，运行Java程序只需要它 == 和 equals 的区别 ==：对于基本类型(Java有8种基本类型，byte、boolean、char、double、float、int、long、short，而String是引用类型)，比较的是值；对于引用类型，比较的是引用 equals：equals本质上是== 123public boolean equals(Object obj) &#123; return (this == obj);&#125; 只是String和Integer等重写了equals方法，把它变成了值比较 所以说自定义引用类型建议重写equals方法，建议也一起重写hashcode方法 两个对象的 hashCode()相同，则 equals()也一定为 true，对吗？ 错。 如果两个对象equals相等，那么这两个对象的HashCode一定也相同 如果两个对象的HashCode相同，不代表两个对象就相同，只能说明这两个对象在散列存储结构中，存放于同一个位置 对于hashcode，请参考这篇文章 final在Java中有什么作用？ final 修饰的类叫最终类，该类不能被继承。 final 修饰的方法不能被重写。 final 修饰的变量叫常量，常量必须初始化，初始化之后值就不能被修改 Java中的Math.round(-1.5)等于多少？ 等于 -1，因为在数轴上取值时，中间值（0.5）向右取整，所以正 0.5 是往上取整，负 0.5 是直接舍弃。 String属于基础的数据类型吗？ 见2 Java中操作字符串都有哪些类？它们之间有什么区别？ 操作字符串的类有：String、StringBuffer、StringBuilder。 String声明的是不可变的对象，每次操作都会生成新的String对象，然后将指针指向新的String对象，而StringBuffer、StringBuilder可以在原有对象的基础上进行操作，所以在经常改变字符串内容的情况下最好不要使用 String；StringBuffer比StringBuilder多了线程安全 String str=&quot;i&quot;与String str=new String(&quot;i&quot;)一样吗？ 不一样，因为内存的分配方式不一样。String str=&quot;i&quot;的方式，java虚拟机会将其分配到常量池中；而 String str=new String(&quot;i&quot;) 则会被分到堆内存中。 如何将字符串反转？ 使用StringBuilder或者 StringBuffer 的 reverse() 方法 String 类的常用方法都有那些？ indexOf()：返回指定字符的索引。 charAt()：返回指定索引处的字符。 replace()：字符串替换。 trim()：去除字符串两端空白。 split()：分割字符串，返回一个分割后的字符串数组。 getBytes()：返回字符串的 byte 类型数组。 length()：返回字符串长度。 toLowerCase()：将字符串转成小写字母。 toUpperCase()：将字符串转成大写字符。 substring()：截取字符串。 equals()：字符串比较。 抽象类必须要有抽象方法吗？no。 普通类和抽象类有哪些区别？普通类不能包含抽象方法，抽象类可以包含抽象方法。抽象类不能直接实例化，普通类可以直接实例化。 抽象类能使用 final 修饰吗？不能，定义抽象类就是让其他类继承的，如果定义为 final 该类就不能被继承，这样彼此就会产生矛盾，所以 final 不能修饰抽象类 接口和抽象类有什么区别？实现：抽象类的子类使用 extends 来继承；接口必须使用 implements 来实现接口。构造函数：抽象类可以有构造函数；接口不能有。main 方法：抽象类可以有 main 方法，并且我们能运行它；接口不能有 main 方法。实现数量：类可以实现很多个接口；但是只能继承一个抽象类。访问修饰符：接口中的方法默认使用 public 修饰；抽象类中的方法可以是任意访问修饰符。 java 中 IO 流分为几种？按功能来分：输入流（input）、输出流（output）。按类型来分：字节流和字符流。字节流和字符流的区别是：字节流按 8 位传输以字节为单位输入输出数据，字符流按 16 位传输以字符为单位输入输出数据。(答案这么写，不过貌似debug会判断编码，8位或16位) BIO、NIO、AIO 有什么区别？ BIO：Block IO 同步阻塞式 IO，就是我们平常使用的传统 IO，它的特点是模式简单使用方便，并发处理能力低。 NIO：New IO 同步非阻塞 IO，是传统 IO 的升级，客户端和服务器端通过 Channel（通道）通讯，实现了多路复用。 AIO：Asynchronous IO 是 NIO 的升级，也叫 NIO2，实现了异步非堵塞 IO ，异步 IO 的操作基于事件和回调机制。 Files的常用方法都有哪些？ Files.exists()：检测文件路径是否存在。 Files.createFile()：创建文件。 Files.createDirectory()：创建文件夹。 Files.delete()：删除一个文件或目录。 Files.copy()：复制文件。 Files.move()：移动文件。 Files.size()：查看文件个数。 Files.read()：读取文件。 Files.write()：写入文件。 java 容器都有哪些？ Collection 和 Collections 有什么区别？ java.util.Collection 是一个集合接口（集合类的一个顶级接口）。它提供了对集合对象进行基本操作的通用接口方法。Collection接口在Java 类库中有很多具体的实现。Collection接口的意义是为各种具体的集合提供了最大化的统一操作方式，其直接继承接口有List与Set。 Collections则是集合类的一个工具类&#x2F;帮助类，其中提供了一系列静态方法，用于对集合中元素进行排序、搜索以及线程安全等各种操作。 List、Set、Map 之间的区别是什么？ HashMap 和 Hashtable 有什么区别？ hashMap去掉了HashTable 的contains方法，但是加上了containsValue（）和containsKey（）方法。 hashTable同步的，而HashMap是非同步的，效率上逼hashTable要高。 hashMap允许空键值，而hashTable不允许。这篇文章挺好 如何决定使用 HashMap 还是 TreeMap？对于在Map中插入、删除和定位元素这类操作，HashMap是最好的选择。然而，假如你需要对一个有序的key集合进行遍历，TreeMap是更好的选择。基于你的collection的大小，也许向HashMap中添加元素会更快，将map换为TreeMap进行有序key的遍历。 说一下 HashMap 的实现原理？ HashMap概述：HashMap是基于哈希表的Map接口的非同步实现。此实现提供所有可选的映射操作，并允许使用null值和null键。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 HashMap的数据结构：在java编程语言中，最基本的结构就是两种，一个是数组，另外一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，HashMap也不例外。HashMap实际上是一个“链表散列”的数据结构，即数组和链表的结合体。 当我们往Hashmap中put元素时,首先根据key的hashcode重新计算hash值,根绝hash值得到这个元素在数组中的位置(下标),如果该数组在该位置上已经存放了其他元素,那么在这个位置上的元素将以链表的形式存放,新加入的放在链头,最先加入的放入链尾.如果数组中该位置没有元素,就直接将该元素放到数组的该位置上。 需要注意Jdk 1.8中对HashMap的实现做了优化,当链表中的节点数据超过八个之后,该链表会转为红黑树来提高查询效率,从原来的O(n)到O(logn) 说一下 HashSet 的实现原理？ HashSet底层由HashMap实现 HashSet的值存放于HashMap的key上 HashSet的value统一为PRESENT ArrayList 和 LinkedList 的区别是什么？最明显的区别是ArrrayList底层的数据结构是数组，支持随机访问，而 LinkedList 的底层数据结构是双向循环链表，不支持随机访问。使用下标访问一个元素，ArrayList 的时间复杂度是 O(1)，而 LinkedList 是 O(n)。顺序插入的速度ArrayList会快些，LinkedList的速度回稍慢一些。因为ArrarList只是在指定的位置上赋值即可，而LinkedList则需要创建Node对象，并且需要建立前后关联，如果对象较大的话，速度会慢一些。基于上面的理解LinkedList的占用的内存空间要大一些。 如何实现数组和 List 之间的转换？ List转换成为数组：调用ArrayList的toArray方法。 数组转换成为List：调用Arrays的asList方法。 ArrayList 和 Vector 的区别是什么？ Vector是同步的，而ArrayList不是。然而，如果你寻求在迭代的时候对列表进行改变，你应该使用CopyOnWriteArrayList。 ArrayList比Vector快，它因为没有同步，不会过载。 ArrayList更加通用，因为我们可以使用Collections工具类轻易地获取同步列表和只读列表。 ArrayList与Vector都可以设置初始的空间大小。Vector可以指定增长因子，而ArrayList不行，而且两者默认扩容的大小也是不一样的，一个1.5倍；一个是2倍而且还可以指定。 为什么ArrayList的elementData是用transient修饰的说明：ArrayList实现了Serializable接口，这意味着ArrayList是可以被序列化的，用transient修饰elementData意味着我不希望elementData数组被序列化理解：序列化ArrayList的时候，ArrayList里面的elementData未必是满的，比方说elementData有10的大小，但是我只用了其中的3个，那么是否有必要序列化整个elementData呢？显然没有这个必要，因此ArrayList中重写了writeObject方法。优点：这样做既提高了序列化的效率，减少了无意义的序列化；而且还减少了序列化后文件大小。28. Array 和 ArrayList 有何区别？ - Array可以容纳基本类型和对象，而ArrayList只能容纳对象。 - Array没有提供ArrayList那么多功能，比如addAll、removeAll和iterator等。29. 在 Queue 中 poll()和 remove()有什么区别？ poll() 和 remove() 都是从队列中取出一个元素，但是 poll() 在获取元素失败的时候会返回空，但是 remove() 失败的时候会抛出异常。30. 哪些集合类是线程安全的？ - Vector：就比Arraylist多了个同步化机制（线程安全），因为效率较低，现在已经不太建议使用。在web应用中，特别是前台页面，往往效率（页面响应速度）是优先考虑的。 - Statck：堆栈类，先进后出。 - Hashtable：就比hashmap多了个线程安全。 - Enumeration：枚举，相当于迭代器。31. 迭代器 Iterator 是什么？ 迭代器是一种设计模式，它是一个对象，它可以遍历并选择序列中的对象，而开发人员不需要了解该序列的底层结构。迭代器通常被称为“轻量级”对象，因为创建它的代价小。32. Iterator 怎么使用？有什么特点？ Java中的Iterator功能比较简单，并且只能单向移动： (1) 使用方法iterator()要求容器返回一个Iterator。第一次调用Iterator的next()方法时，它返回序列的第一个元素。注意：iterator()方法是java.lang.Iterable接口,被Collection继承。 (2) 使用next()获得序列中的下一个元素。 (3) 使用hasNext()检查序列中是否还有元素。 (4) 使用remove()将迭代器新返回的元素删除。 Iterator是Java迭代器最简单的实现，为List设计的ListIterator具有更多的功能，它可以从两个方向遍历List，也可以从List中插入和删除元素。33. Iterator 和 ListIterator 有什么区别？ - Iterator可用来遍历Set和List集合，但是ListIterator只能用来遍历List。 - Iterator对集合只能是前向遍历，ListIterator既可以前向也可以后向。 - ListIterator实现了Iterator接口，并包含其他的功能，比如：增加元素，替换元素，获取前一个和后一个元素的索引，等等。35. 并行和并发有什么区别？ - 并行是指两个或者多个事件在同一时刻发生；而并发是指两个或多个事件在同一时间间隔发生。 - 并行是在不同实体上的多个事件，并发是在同一实体上的多个事件。 - 在一台处理器上“同时”处理多个任务，在多台处理器上同时处理多个任务。如hadoop分布式集群。 - 所以并发编程的目标是充分的利用处理器的每一个核，以达到最高的处理性能。36. 线程和进程的区别？ 未完待续。。。","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://kebabshellgithub.github.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"算法","slug":"算法","permalink":"https://kebabshellgithub.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"refreshContext","slug":"了解refreshContext","date":"2020-05-01T16:11:54.000Z","updated":"2023-04-06T11:06:55.034Z","comments":true,"path":"2020/05/01/了解refreshContext/","link":"","permalink":"https://kebabshellgithub.github.io/2020/05/01/%E4%BA%86%E8%A7%A3refreshContext/","excerpt":"","text":"refreshContext 这是容器的初始化的地方，通过调用 refresh() 来实现，定义在 AbstractApplicationContext 接口里。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing.准备刷新 //容器预先准备 prepareRefresh(); // Tell the subclass to refresh the internal bean factory.刷新bean factory //创建bean工厂，如果有则销毁 //里面实现对beanDefinition的装载 // 告知子类要初始化BeanFactory，BeanDefinition信息的读取是在子类的 // refreshBeanFactory()方法里完成的 //beanDefinition信息是通过ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory()里的refreshBeanFactory()来完成的 //而这个方法则是在AbstractRefreshableApplicationContext实现的。 //创建bean工厂，如果有则销毁这个操作就是在refreshBeanFactory() //refreshBeanFactory()中是通过loadBeanDefinitions()来完成BeanDefinition的定位,而loadBeanDefinitions()是一个抽象的方法,具体由AbstractBeanDefinitionReader里的loadBeanDefinitions()来实现。 //在loadBeanDefinitions()通过DefaultResourceLoader的getResource方法里返回resource对象 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context.为这个context准备bean factory //配置bean工厂的标准上下文特性，如类装载器、PostProcesser等 prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. //beanFactory的后置处理器 //模板方法，在bean定义被装载后，提供一个修改容器beanFactory的入口 postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. //实现beanFactory的后置处理器 //在Bean未开始实例化时，对Definition定义的修改的入口 //常见的PropertyPlaceholderConfigurer在这里被调用 invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. //注册后置处理器 //注册用于拦截bean创建过程的BeanPostProdessors registerBeanPostProcessors(beanFactory); // Initialize message source for this context. //初始化messageSource,国际化 initMessageSource(); // Initialize event multicaster for this context. //注册事件发布器 initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. //初始化其他特殊的bean onRefresh(); // Check for listener beans and register them. //注册监听器 registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. //完成beanFactory初始化 //里面的preInstantiateSingletons会完成单例对象的创建 finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. //发布完成事件 finishRefresh(); &#125; catch (BeansException ex) &#123; //异常 if (logger.isWarnEnabled()) &#123; //打印异常日志 logger.warn(&quot;Exception encountered during context initialization - &quot; + &quot;cancelling refresh attempt: &quot; + ex); &#125; // Destroy already created singletons to avoid dangling resources. //销毁已注册的bean destroyBeans(); // Reset &#x27;active&#x27; flag. //取消刷新 cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring&#x27;s core, since we // might not ever need metadata for singleton beans anymore... //重置缓存 resetCommonCaches(); &#125; &#125;&#125; beanDefinition信息是通过ConfigurableListableBeanFactory beanFactory &#x3D; obtainFreshBeanFactory()里的refreshBeanFactory()来完成的，而这个方法则是在AbstractRefreshableApplicationContext实现的。 如果容器已经存在,那么销毁并且关闭该容器,保证每次产生的都是新的容器 DefaultListableBeanFactory其实是一个最基础的容器,很多容器都是基于这个容器来作扩展,那么这个容器里自然也包含了很多基础重要的功能，那么通过loadBeanDefinitions()来完成BeanDefinition信息的载入的,这里是委托子类来完成这个工作的。 1234567891011//抽象类,具体的resource定位跟BeanDefinition的载入是委托子类来完成的/** * Load bean definitions into the given bean factory, typically through * delegating to one or more bean definition readers. * @param beanFactory the bean factory to load bean definitions into * @throws BeansException if parsing of the bean definitions failed * @throws IOException if loading of bean definition files failed * @see org.springframework.beans.factory.support.PropertiesBeanDefinitionReader * @see org.springframework.beans.factory.xml.XmlBeanDefinitionReader*/protected abstract void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException; 具体实现看源码 总结下Resource定位BeanDefinition的流程1.FileSystemXmlApplicationContext里调用refresh()方法初始化IoC容器。2.在refresh()方法里调用obtainFreshBeanFactory()里面的refreshBeanFactory()来完成BeanDefinition的定位,而refreshBeanFactory()是由子类AbstractRefreshableApplicationContext来实现的。3.refreshBeanFactory()中是通过loadBeanDefinitions()来完成BeanDefinition的定位,而loadBeanDefinitions()是一个抽象的方法,具体由AbstractBeanDefinitionReader里的loadBeanDefinitions()来实现。4.在loadBeanDefinitions()通过DefaultResourceLoader的getResource方法里返回resource对象。 BeanDefinition的信息已经定位到了，第二步就是把定义的BeanDefinition在Ioc容器中转化成一个Spring内部标示的数据结构的过程。 首先通过调用XML的解析器得到Document对象，此时这些Document对象并没有按照Spring的Bean规则进行解析，在完成通用的XML解析以后，才是按照Spring Bean规则进行解析的地方，这个过程在documentReader中实现，使用的documentReader是默认设置好的DefaultBeanDefinitionDocumentReader。 将抽象好的BeanDefinition统一注册到IoC容器中，IoC容器是通过hashMap来维护BeanDefinition信息的，key为beanName，value为BeanDefinition。 BeanDefinition的注册是发生在BeanDefinition信息载入之后的, 通过registerBeanDefinition实现 总的来说 spring ioc初始化流程就是resource定位 即寻找用户定义的bean资源，由ResourceLoader通过统一的接口Resource接口来完成 beanDefinition载入BeanDefinitionReader读取、解析Resource定位的资源成BeanDefinition载入到ioc中（通过HashMap进行维护BeanDefinition） BeanDefinition注册 即向IOC容器注册这些BeanDefinition， 通过registerBeanDefinition实现 BeanDefinition加载流程：定义BeanDefinitionReader解析xml的document BeanDefinitionDocumentReader解析document成beanDefinition SpringBoot 对@SpringBootApplication注解的类的注入 在prepareContext进行bean的加载 load 123456789101112131415161718protected void load(ApplicationContext context, Object[] sources) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Loading source &quot; + StringUtils.arrayToCommaDelimitedString(sources)); &#125; //这个BeanDefinationLoader的实现类为org.springframework.boot.BeanDefinitionLoader,为springboot自定义的一个beanDefination的加载器，专门用来加载配置声明的类的 BeanDefinitionLoader loader = createBeanDefinitionLoader(getBeanDefinitionRegistry(context), sources); if (this.beanNameGenerator != null) &#123; loader.setBeanNameGenerator(this.beanNameGenerator); &#125; if (this.resourceLoader != null) &#123; loader.setResourceLoader(this.resourceLoader); &#125; if (this.environment != null) &#123; loader.setEnvironment(this.environment); &#125; //org.springframework.boot.BeanDefinitionLoader把beanDefination加载进spring的BeanDefinationRegistry中的方法 loader.load();&#125; 12345678910111213private int load(Class&lt;?&gt; source) &#123; if (isGroovyPresent() &amp;&amp; GroovyBeanDefinitionSource.class.isAssignableFrom(source)) &#123; // Any GroovyLoaders added in beans&#123;&#125; DSL can contribute beans here GroovyBeanDefinitionSource loader = BeanUtils.instantiateClass(source, GroovyBeanDefinitionSource.class); load(loader); &#125; if (isComponent(source)) &#123; //通过org.springframework.context.annotation.AnnotatedBeanDefinitionReader.AnnotatedBeanDefinitionReader(BeanDefinitionRegistry registry)来注册注解扫描的类定义 this.annotatedReader.register(source); return 1; &#125; return 0;&#125; 在refreshContext进行bean的实例化(DI依赖注入)生成bean过程运用装饰器模式产生的bean都是beanWrapper（bean的增强）先自定义一个class 123456@Componentpublic class MyClass &#123; public MyClass() &#123; System.out.println(&quot;我创建了&quot;); &#125;&#125; 调试发现refresh方法里面的finishBeanFactoryInitialization(beanFactory)方法对MyClass实例化 依赖注入怎么处理bean之间的依赖关系?其实就是通过在beanDefinition载入时，如果bean有依赖关系，通过占位符来代替，在调用getbean时候，如果遇到占位符，从ioc里获取bean注入到本实例来参考1参考2参考3参考4","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://kebabshellgithub.github.io/tags/Spring/"}]},{"title":"prepareContext","slug":"了解prepareContext","date":"2020-05-01T15:29:59.000Z","updated":"2023-04-06T11:06:55.034Z","comments":true,"path":"2020/05/01/了解prepareContext/","link":"","permalink":"https://kebabshellgithub.github.io/2020/05/01/%E4%BA%86%E8%A7%A3prepareContext/","excerpt":"","text":"prepareContext 步骤: 设置environment 后置处理ApplicationContext 执行Initializers 发布contextPrepared事件 日志 注册单例bean 加载启动类 发布contextLoaded事件 1234567891011121314151617181920212223242526272829303132333435private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; //设置上下文环境 context.setEnvironment(environment); //ApplicationContext的后置处理 postProcessApplicationContext(context); //执行Initializers applyInitializers(context); //发布contextPrepared事件 listeners.contextPrepared(context); //日志 if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // Add boot specific singleton beans 注册单例bean ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); beanFactory.registerSingleton(&quot;springApplicationArguments&quot;, applicationArguments); if (printedBanner != null) &#123; beanFactory.registerSingleton(&quot;springBootBanner&quot;, printedBanner); &#125; if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory) .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; if (this.lazyInitialization) &#123; context.addBeanFactoryPostProcessor(new LazyInitializationBeanFactoryPostProcessor()); &#125; // Load the sources Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, &quot;Sources must not be empty&quot;); //初始化bean加载器,并加载bean到应用上下文 load(context, sources.toArray(new Object[0])); //发布contextLoaded事件 listeners.contextLoaded(context);&#125; 设置上下文环境,以AnnotationConfigServletWebServerApplicationContext为例 123456789@Overridepublic void setEnvironment(ConfigurableEnvironment environment) &#123; //显式调用父类AbstractApplicationContext的setEnvironment方法 super.setEnvironment(environment); //调用AnnotatedBeanDefinitionReader#setEnvironment()方法 this.reader.setEnvironment(environment); //ClassPathBeanDefinitionScanner调用父类的setEnvironment方法 this.scanner.setEnvironment(environment);&#125; 后置处理 设置ApplicationContext的beanNameGenerator 设置ApplicationContext的resourceLoader和classLoader 设置ApplicationContext的类型转换Service 12345678910111213141516171819protected void postProcessApplicationContext(ConfigurableApplicationContext context) &#123; //设置ApplicationContext的beanNameGenerator if (this.beanNameGenerator != null) &#123; context.getBeanFactory().registerSingleton(AnnotationConfigUtils.CONFIGURATION_BEAN_NAME_GENERATOR, this.beanNameGenerator); &#125; //设置ApplicationContext的resourceLoader和classLoader if (this.resourceLoader != null) &#123; if (context instanceof GenericApplicationContext) &#123; ((GenericApplicationContext) context).setResourceLoader(this.resourceLoader); &#125; if (context instanceof DefaultResourceLoader) &#123; ((DefaultResourceLoader) context).setClassLoader(this.resourceLoader.getClassLoader()); &#125; &#125; //设置ApplicationContext的类型转换Service if (this.addConversionService) &#123; context.getBeanFactory().setConversionService(ApplicationConversionService.getSharedInstance()); &#125;&#125; …prepareContext()这一步的主要作用是为下面刷新applicationContext做准备参考1","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://kebabshellgithub.github.io/tags/Spring/"}]},{"title":"createApplicationContext","slug":"了解createApplicationContext","date":"2020-05-01T14:26:43.000Z","updated":"2023-04-06T11:06:55.034Z","comments":true,"path":"2020/05/01/了解createApplicationContext/","link":"","permalink":"https://kebabshellgithub.github.io/2020/05/01/%E4%BA%86%E8%A7%A3createApplicationContext/","excerpt":"","text":"createApplicationContext 先来看看之前的run方法 123456789101112131415161718192021222324252627282930313233343536373839public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); //这是本文重点 context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; return context; &#125; createApplicationContext()源码 12345678910111213141516171819202122protected ConfigurableApplicationContext createApplicationContext() &#123; Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) &#123; try &#123; switch (this.webApplicationType) &#123; case SERVLET: contextClass = Class.forName(DEFAULT_SERVLET_WEB_CONTEXT_CLASS); break; case REACTIVE: contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS); break; default: contextClass = Class.forName(DEFAULT_CONTEXT_CLASS); &#125; &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException(&quot;Unable create a default ApplicationContext, please specify an ApplicationContextClass&quot;, ex); &#125; &#125; // 通过反射获取对应类的实例 return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass);&#125; 根据SpringApplication的webApplicationType来实例化对应的上下文；如果webApplicationType的值是SERVLET，那么实例化AnnotationConfigServletWebServerApplicationContext，如果是REACTIVE则实例化AnnotationConfigReactiveWebServerApplicationContext（响应式编程，后续再看），如果既不是SERVLET、也不是REACTIVE，那么则是默认情况（也就是我们所说的非web引用），实例化AnnotationConfigApplicationContext. webApplicationType的值就在构造SpringApplition时获取 12345public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; //... this.webApplicationType = WebApplicationType.deduceFromClasspath(); //...&#125; 虽然已经创建了应用上下文，但还只是具有一个骨架（填充了少部分内容,注解的,扫描的等等）参考1","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://kebabshellgithub.github.io/tags/Spring/"}]},{"title":"Spring Boot 的启动","slug":"SpringBoot的小复习","date":"2020-04-29T18:59:06.000Z","updated":"2023-04-06T11:06:55.026Z","comments":true,"path":"2020/04/29/SpringBoot的小复习/","link":"","permalink":"https://kebabshellgithub.github.io/2020/04/29/SpringBoot%E7%9A%84%E5%B0%8F%E5%A4%8D%E4%B9%A0/","excerpt":"","text":"新的 Spring Boot 的文章 SpringBoot 新建一个SpringBoot工程的示例 关于启动流程 SpringBoot首先会创建SpringBootApplication对象 初始化对象 12345678910111213public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; //primarySources就是当前SpringBootApplication对象 Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); //判断是否是web项目 this.webApplicationType = WebApplicationType.deduceFromClasspath(); //从类路径下找到META-INF/spring.factories配置的所有ApplicationContextInitializer，然后保存 setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); //从类路径下找到ETA-INF/spring.factories配置的所有ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass();&#125; 然后执行run方法Spring Boot应用的整个启动流程都封装在SpringApplication.run方法中，本质上其实就是在spring的基础之上做了封装，做了大量的扩张 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public ConfigurableApplicationContext run(String... args) &#123; //启动开始停止的监听 StopWatch stopWatch = new StopWatch(); stopWatch.start(); //声明IOC容器 ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); //是关于awt的 configureHeadlessProperty(); //通过SpringFactoriesLoader查找并加载所有的SpringApplicationRunListeners(从META-INF/spring.factories),通过调用starting()方法通知所有的SpringApplicationRunListeners：应用开始启动了 SpringApplicationRunListeners listeners = getRunListeners(args); //回调所有的获取SpringApplicationRunListener.starting()方法 listeners.starting(); try &#123; //封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); //准备环境 //创建环境完成后回调SpringApplicationRunListener.environmentPrepared(),表示环境准备完成 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); //打印SPRING那个大图标 Banner printedBanner = printBanner(environment); //创建IOC容器,会判断是不是web，利用反射创建容器 context = createApplicationContext(); //创建一系列FailureAnalyzer exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); //准备上下文环境 //将environment保存到IOC //还有applyInitializers(),回调之前保存的所有的ApplicationContextInitialize方法 //还要回调所有的SpringApplicationRunListener的contextPrepared() //还有什么banner什么的 prepareContext(context, environment, listeners, applicationArguments, printedBanner); //prepareContext完成后回调所有的SpringApplicationRunListener的contextLoaded() //刷新容器，IOC容器初始化的过程，扫描、创建、加载所有的组件 //如果是web,tomcat也在这里创建好 refreshContext(context); //afterRefresh:从IOC容器中获取所有的ApplicationRunner(先)和CommandLineRunner(后)进行回调 afterRefresh(context, applicationArguments); //完成 stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; //返回启动的IOC容器 return context;&#125; 1234private void configureHeadlessProperty() &#123; System.setProperty(SYSTEM_PROPERTY_JAVA_AWT_HEADLESS, System.getProperty(SYSTEM_PROPERTY_JAVA_AWT_HEADLESS, Boolean.toString(this.headless)));&#125; configureHeadlessProperty是关于awt的,给属性设值System.setProperty(),它的值来源于System.getProperty().为什么把属性从一个地方取出来,然后又设置到同一个地方?System中getProperty()有2个重载方法,但却只有一个setProperty()方法,其中getProperty()有单参和双参两方法,单参就是简单的获取属性,有就有,没有就没有,双参则聪明一点,在没有的时候会返回一个调用者指定的默认值,所以经过这样操作后,不管有没有那个属性,最终都能保证有。所以先取后设 即使没有检测到显示器,也允许其启动。对于服务器来说,是不需要显示器的,所以要这样设置 几个重要的事件回调机制 在META-INF&#x2F;spring.factories ApplicationContextInitializer SpringApplicationRunListener IOC容器中 ApplicationRunner CommandLineRunner 实现它们来观察SpringBoot启动顺序 四个实现 1234567public class MyApplicationContextInitializer implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt; &#123; //ConfigurableApplicationContext ioc @Override public void initialize(ConfigurableApplicationContext applicationContext) &#123; System.out.println(&quot;MyApplicationContextInitializer initialize: &quot; + applicationContext); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 ```java public class MySpringApplicationRunListener implements SpringApplicationRunListener &#123; public MySpringApplicationRunListener(SpringApplication application, String[] args) &#123; &#125; @Override public void starting() &#123; System.out.println(&quot;MySpringApplicationRunListener start&quot;); &#125; @Override public void environmentPrepared(ConfigurableEnvironment environment) &#123; Object o = environment.getSystemProperties().get(&quot;os.name&quot;); System.out.println(&quot;SpringApplicationRunListener的environmentPrepared... os name:&quot; + o); &#125; @Override public void contextPrepared(ConfigurableApplicationContext context) &#123; // context.getBean(&quot;xxx&quot;) System.out.println(&quot;SpringApplicationRunListener的contextPrepared (ioc)准备好&quot;); &#125; @Override public void contextLoaded(ConfigurableApplicationContext context) &#123; System.out.println(&quot;SpringApplicationRunListener的contextLoaded context加载ok&quot;); &#125; @Override public void started(ConfigurableApplicationContext context) &#123; System.out.println(&quot;MySpringApplicationRunListener started&quot;); &#125; @Override public void running(ConfigurableApplicationContext context) &#123; System.out.println(&quot;MySpringApplicationRunListener running&quot;); &#125; @Override public void failed(ConfigurableApplicationContext context, Throwable exception) &#123; System.out.println(&quot;MySpringApplicationRunListener failed&quot;); &#125; &#125; 12345678@Componentpublic class MyApplicationRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; //args命令行参数 System.out.println(&quot;MyApplicationRunner run&quot;); &#125;&#125; 1234567@Componentpublic class MyCommandLineRunner implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; System.out.println(&quot;MyCommandLineRunner run&quot;); &#125;&#125; 记得ApplicationContextInitializer和SpringApplicationRunListener要在spring.factories声明 还有其他两个要@Component，它们两个B在IOC中 12345 # Application Context Initializers org.springframework.context.ApplicationContextInitializer=\\ cn.kebabshell.springbootlearn.listener.MyApplicationContextInitializer org.springframework.boot.SpringApplicationRunListener=\\cn.kebabshell.springbootlearn.listener.MySpringApplicationRunListener 结果一目了然！！ ![结果](F:\\blog\\source\\_posts\\SpringBoot的小复习\\test3.png) 自定义starter场景启动器官方的有例如aop什么的 分为starter和autoconfigurer例如 新建空工程，创建两个模块 1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!--启动器--&gt; &lt;groupId&gt;cn.kebabshell.starter&lt;/groupId&gt; &lt;artifactId&gt;kebabshell-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;!--引入自动配置模块--&gt; &lt;dependency&gt; &lt;groupId&gt;cn.kebabshell&lt;/groupId&gt; &lt;artifactId&gt;kebabshell-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 123456789101112131415161718192021222324252627282930 ```xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;cn.kebabshell&lt;/groupId&gt; &lt;artifactId&gt;kebabshell-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;kebabshell-spring-boot-starter-autoconfigurer&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--引入spring-boot-starter,所有starter的基本配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 1 autoconfigurer 创建MyProperties 1234567891011121314151617181920212223 @ConfigurationProperties(prefix = &quot;kebabshell.test&quot;) //这里的prefix就是引入这个starter的项目在配置文件里面可以配置的前缀 public class MyProperties &#123; //自定义的一些属性 private String prefix; private String suffix; public String getPrefix() &#123; return prefix; &#125; public void setPrefix(String prefix) &#123; this.prefix = prefix; &#125; public String getSuffix() &#123; return suffix; &#125; public void setSuffix(String suffix) &#123; this.suffix = suffix; &#125;&#125; 1234567891011121314151617181920 - 创建TestService ```javapublic class TestService &#123; private MyProperties properties; public MyProperties getProperties() &#123; return properties; &#125; public void setProperties(MyProperties properties) &#123; this.properties = properties; &#125; //根据别的项目调用test方法，可以进行一些操作 public String test(String str)&#123; return &quot;im config prefix:&quot; + properties.getPrefix() + &quot; suffix:&quot; + properties.getSuffix() + &quot; args:&quot; + str; &#125;&#125; - 创建MyAutoConfiguration 12345678910111213 @Configuration @ConditionalOnWebApplication//Web才生效 @EnableConfigurationProperties(MyProperties.class) public class MyAutoConfiguration &#123; @Autowired private MyProperties properties; @Bean//加入ioc public TestService testService()&#123; TestService testService = new TestService(); testService.setProperties(properties); return testService; &#125;&#125; 1234567- 创建spring.factories![spring.factories](F:\\blog\\source\\_posts\\SpringBoot的小复习\\test6.png) ```xmlorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ cn.kebabshell.MyAutoConfiguration 依次构建包 新建web工程 引入自定义starter 123456&lt;!--自定义starter--&gt;&lt;dependency&gt; &lt;groupId&gt;cn.kebabshell.starter&lt;/groupId&gt; &lt;artifactId&gt;kebabshell-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 12345678910111213 - 创建controller就可以进行测试了 ```java @RestController public class TestController &#123; @Autowired private TestService service; @GetMapping(&quot;/test&quot;) public String test()&#123; return service.test(&quot;hello&quot;); &#125; &#125; - 结果 ![result](F:\\blog\\source\\_posts\\SpringBoot的小复习\\test8.png) 参考1参考2","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://kebabshellgithub.github.io/tags/Spring/"}]},{"title":"spring aop","slug":"spring-aop的小复习","date":"2020-04-27T21:47:51.000Z","updated":"2023-04-06T11:06:55.030Z","comments":true,"path":"2020/04/27/spring-aop的小复习/","link":"","permalink":"https://kebabshellgithub.github.io/2020/04/27/spring-aop%E7%9A%84%E5%B0%8F%E5%A4%8D%E4%B9%A0/","excerpt":"","text":"AOP看这篇里面的AOP 对AOP的理解 OOP(面向对象编程)是纵向的，而AOP(面向切面编程)是横向的 什么是切面。炒菜，锅与炉子共同来完成炒菜，锅与炉子就是切面。web层级设计中，每一层之间也是一个切面。编程中，对象与对象之间，方法与方法之间，模块与模块之间都是一个个切面 执行这个方法前，你需要干什么，执行方法后，你需要干什么，都可以用AOP的思想 以一个简单的例子来比喻一下 AOP 中 Aspect, Joint point, Pointcut 与 Advice之间的关系 让我们来假设一下, 从前有一个叫爪哇的小县城, 在一个月黑风高的晚上, 这个县城中发生了命案. 作案的凶手十分狡猾, 现场没有留下什么有价值的线索. 不过万幸的是, 刚从隔壁回来的老王恰好在这时候无意中发现了凶手行凶的过程, 但是由于天色已晚, 加上凶手蒙着面, 老王并没有看清凶手的面目, 只知道凶手是个男性, 身高约七尺五寸. 爪哇县的县令根据老王的描述, 对守门的士兵下命令说: 凡是发现有身高七尺五寸的男性, 都要抓过来审问. 士兵当然不敢违背县令的命令, 只好把进出城的所有符合条件的人都抓了起来 来让我们看一下上面的一个小故事和 AOP 到底有什么对应关系。首先我们知道, 在 Spring AOP 中 Joint point 指代的是所有方法的执行点, 而 point cut 是一个描述信息, 它修饰的是 Joint point, 通过 point cut, 我们就可以确定哪些 Joint point 可以被织入 Advice. 对应到我们在上面举的例子, 我们可以做一个简单的类比, Joint point 就相当于 爪哇的小县城里的百姓,pointcut 就相当于 老王所做的指控, 即凶手是个男性, 身高约七尺五寸, 而 Advice 则是施加在符合老王所描述的嫌疑人的动作: 抓过来审问 Joint point: 爪哇的小县城里的百姓: 因为根据定义, Joint point 是所有可能被织入 Advice 的候选的点, 在 Spring AOP中, 则可以认为所有方法执行点都是 Joint point. 而在我们上面的例子中, 命案发生在小县城中, 按理说在此县城中的所有人都有可能是嫌疑人. Pointcut：男性, 身高约七尺五寸: 我们知道, 所有的方法(joint point) 都可以织入 Advice, 但是我们并不希望在所有方法上都织入 Advice, 而 Pointcut 的作用就是提供一组规则来匹配joint point, 给满足规则的 joint point 添加 Advice. 同理, 对于县令来说, 他再昏庸, 也知道不能把县城中的所有百姓都抓起来审问, 而是根据凶手是个男性, 身高约七尺五寸, 把符合条件的人抓起来. 在这里 凶手是个男性, 身高约七尺五寸 就是一个修饰谓语, 它限定了凶手的范围, 满足此修饰规则的百姓都是嫌疑人, 都需要抓起来审问 Advice ：抓过来审问, Advice 是一个动作, 即一段 Java 代码, 这段 Java 代码是作用于 point cut 所限定的那些 Joint point 上的. 同理, 对比到我们的例子中, 抓过来审问 这个动作就是对作用于那些满足 男性, 身高约七尺五寸 的爪哇的小县城里的百姓 Aspect: Aspect 是 point cut 与 Advice 的组合, 因此在这里我们就可以类比: “根据老王的线索, 凡是发现有身高七尺五寸的男性, 都要抓过来审问” 这一整个动作可以被认为是一个 Aspect Joinpoint可以有多种类型：构造方法调用，字段的设置和获取，方法的调用，方法的执行，异常的处理执行，类的初始化。但是在Spring中却没有实现上面所有的Joinpoint，确切的说，Spring只支持方法执行类型的Joinpoint。在Spring中，通过动态代理和动态字节码技术实现AOP AOP的实现 动态代理。Java中的一个方法，这个方法可以实现动态创建一组指定的接口的实现对象 1public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) ClassLoader loader：方法需要动态生成一个类，这个类实现了A和B两个接口，然后创建这个类的对象。需要生成一个类，而且这个类也需要加载到方法区中，所以我们需要一个ClassLoader来加载该类 Class&lt;?&gt;[] interfaces：我们需要代理对象实现的数组 InvocationHandler h：调用处理器，这里就是增强的地方 1234567/*** Created by KebabShell* on 2020/4/26 下午 01:49*/public interface hello &#123; Object test();&#125; 123456789101112131415161718192021222324252627282930public void test0() &#123; /** * 三个参数 * 1、ClassLoader * 方法需要动态生成一个类，这个类实现了A和B两个接口，然后创建这个类的对象 * 需要生成一个类，这个类也需要加载到方法区中，所以我们需要一个ClassLoader来加载该类 * * 2、Class[] interfaces * 我们需要代理对象实现的数组 * * 3、InvocationHandler * 调用处理器 */ ClassLoader classLoader = this.getClass().getClassLoader(); InvocationHandler invocationHandler = new InvocationHandler() &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;handler invoke&quot;); return &quot;invoke return&quot;; &#125; &#125;; //hello是自定义接口 Object obj = Proxy.newProxyInstance(classLoader, new Class[]&#123;hello.class&#125;, invocationHandler); hello h = (hello) obj; Object test = h.test(); //System.out.println(&quot;h.toString()&quot; + h.toString()); //System.out.println(&quot;h.getClass()&quot; + h.getClass()); //System.out.println(&quot;obj.getClass()&quot; + obj.getClass()); System.out.println(&quot;test&quot; + test);&#125; 以上是残疾版的AOP。代理对象方法的返回值其实就是invoke方法的返回值，代理对象其实就是使用反射机制实现的一个运行时对象。下面是比较完整的实现 123public interface BeforeAdvice &#123; void before();&#125; 123public interface AfterAdvice &#123; void after();&#125; 1234567public class HelloImpl implements hello &#123; @Override public Object test() &#123; System.out.println(&quot;helloImpl test&quot;); return &quot;helloImpl&quot;; &#125;&#125; 12345678910111213141516171819202122232425262728293031/*** Created by KebabShell* on 2020/4/26 下午 11:18* 代理工厂*/public class ProxyFactory &#123; private Object target; //自定义的 private BeforeAdvice beforeAdvice; private AfterAdvice afterAdvice; public Object createProxy()&#123; ClassLoader classLoader = this.getClass().getClassLoader(); Class&lt;?&gt;[] interfaces = target.getClass().getInterfaces(); InvocationHandler invocationHandler = new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //执行前 beforeAdvice.before(); //实现目标需要执行的方法 Object result = method.invoke(target, args); //执行后 afterAdvice.after(); return result; &#125; &#125;; Object obj = Proxy.newProxyInstance(classLoader, interfaces, invocationHandler); return obj; &#125; //getter setter&#125; 123456789101112131415161718192021public void test1()&#123; ProxyFactory proxyFactory = new ProxyFactory(); proxyFactory.setTarget(new HelloImpl()); proxyFactory.setBeforeAdvice(new BeforeAdvice() &#123; @Override public void before() &#123; System.out.println(&quot;before&quot;); &#125; &#125;); proxyFactory.setAfterAdvice(new AfterAdvice() &#123; @Override public void after() &#123; System.out.println(&quot;after&quot;); &#125; &#125;); hello h = (hello) proxyFactory.createProxy(); Object result = h.test(); System.out.println(result);&#125; 12//这是spring的ProxyFactorypublic class ProxyFactory extends ProxyCreatorSupport 动态字节码技术 CGLIB 12345678910&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib-nodep&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt;&lt;/dependency&gt; 首先实现一个MethodInterceptor，方法调用会被转发到该类的intercept()方法。然后在需要使用目标对象的时候，通过CGLIB动态代理获取代理对象 12345678910//目标对象public class TargetTest &#123; public String doFirst()&#123; System.out.println(&quot;first&quot;); return &quot;doFirst&quot;; &#125; public void doSecond()&#123; System.out.println(&quot;second&quot;); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041/*** Created by KebabShell* on 2020/4/27 下午 09:20*/public class CglibFactory implements MethodInterceptor &#123; public TargetTest myCglibCreator()&#123; Enhancer enhancer = new Enhancer(); //将目标类设置为父类，cglib动态代理增强的原理就是子类增强父类,cglib不能增强目标类为final的类 //因为final类不能有子类 enhancer.setSuperclass(TargetTest.class); //设置回调接口,这里的MethodInterceptor实现类回调接口，而我们又实现了MethodInterceptor,其实 //这里的回调接口就是本类对象,调用的方法其实就是intercept()方法 enhancer.setCallback(this); //create()方法用于创建cglib动态代理对象 return (TargetTest) enhancer.create(); &#125; /** * @param o Object为由CGLib动态生成的代理类实例 * @param method Method为上文中实体类所调用的被代理的方法引用 * @param objects Object[]为参数值列表 * @param methodProxy MethodProxy为生成的代理类对方法的代理引用。 * @return * @throws Throwable * * 回调接口的方法 * 回调接口的方法执行的条件是：代理对象执行目标方法时会调用回调接口的方法 */ public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; //执行目标类的方法 //Object result = methodProxy.invokeSuper(o, objects); //这里实现将返回值字符串变为大写的逻辑 //if(result != null) &#123; //result = ((String) result).toUpperCase(); //result += &quot; intercept&quot;; //&#125; //return result; //调用代理类实例上的methodProxy方法的父类方法（即实体类TargetTest中对应的方法） System.out.println(&quot;intercept&quot;); return &quot;HHH&quot;; &#125;&#125; 12345678@Testpublic void test0()&#123; //TargetTest target = new TargetTest(); TargetTest creator = new CglibFactory().myCglibCreator(); String result = creator.doFirst(); System.out.println(result); creator.doSecond();&#125; CGLIB也有其缺陷，那就是必须目标类必须是可以继承的，如果目标类不可继承，那么我们就无法使用CGLIB来增强该类 Spring实现AOP的原理是JDK动态代理和cglib代理。JDK动态代理有缺陷，就是被代理对象必须实现接口才能产生代理对象，如果没有接口，就不能使用动态代理技术。我们用spring容器来实现动态代理，假如要管理的对象没有实现接口，那么就不能产生代理对象了。为了让所有的对象都能产生动态代理对象，Spring又融入了第三方代理技术CGLIB代理。CGLIB可以对任何类生成代理对象，它的原理是对目标对象进行继承代理，如果目标对象被final修饰，那么该类无法被CGLIB代理。 那么Spring到底使用的是JDK代理，还是cglib代理呢？ 答案是混合使用。如果被代理对象实现了接口，就优先使用JDK代理，如果没有实现接口，就用用cglib代理。 Spring切面可以应用5种类型的通知 前置通知（Before） 后置通知（After，在方法完成之后调用通知，无论方法执行是否成功） 后置通知（After-returning，在方法成功执行之后调用通知） 异常通知（After-throwing，在方法抛出异常后调用通知） 环绕通知(Around，在目标方法之前之后都调用)。 AOP的应用 spring的AOP事务 事务的概述 ACID。即原子性(amoticity)、一致性(consitency)、隔离性(isolation)、持久性(durability) 原子性:指事务包含的所有操作要么全部成功，要么全部失败回滚 一致性:指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性 隔离性:当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。即要达到这么一种效果：对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行 持久性:指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作 事务的隔离级别 Read uncommitted:读未提交。即一个事务可以读取另一个未提交事务的数据。这就是脏读。解决脏读方法就是Read committed 读提交 Read committed:读提交。一个事务要等另一个事务提交后才能读取数据。程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他埋单时（程序员事务开启），收费系统事先检测到他的卡里有3.6万，就在这个时候！！程序员的妻子要把钱全部转出充当家用，并提交。当收费系统准备扣款时，再检测卡里的金额，发现已经没钱了（第二次检测金额当然要等待妻子转出金额事务提交完）。程序员就会很郁闷，明明卡里是有钱的。这就是读提交，若有事务对数据进行更新（UPDATE）操作时，读操作事务要等待这个更新操作事务提交后才能读取数据，可以解决脏读问题。但在这个事例中，出现了一个事务范围内两个相同的查询却返回了不同数据，这就是不可重复读。解决不可重复读的方法就是Repeatable read重复读 Repeatable read:重复读。就是在开始读取数据（事务开启）时，不再允许修改操作。程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他埋单时（事务开启，不允许其他事务的UPDATE修改操作），收费系统事先检测到他的卡里有3.6万。这个时候他的妻子不能转出金额了。接下来收费系统就可以扣款了。不可重复读对应的是修改，即UPDATE操作。但是可能还会有幻读问题。因为幻读问题对应的是插入INSERT操作，而不是UPDATE操作。那什么是幻读？程序员某一天去消费，花了2千元，然后他的妻子去查看他今天的消费记录（全表扫描FTS，妻子事务开启），看到确实是花了2千元，就在这个时候，程序员花了1万买了一部电脑，即新增INSERT了一条消费记录，并提交。当妻子打印程序员的消费记录清单时（妻子事务提交），发现花了1.2万元，似乎出现了幻觉，这就是幻读，怎么解决幻读问题？Serializable序列化 Serializable:序列化。Serializable 是最高的事务隔离级别，在该级别下，事务串行化顺序执行，可以避免脏读、不可重复读与幻读。但是这种事务隔离级别效率低下，比较耗数据库性能，一般不使用。 大多数数据库默认的事务隔离级别是Read committed，比如Sql Server , Oracle。Mysql的默认隔离级别是Repeatable read spring中事务的分类 可以分为编程式事务控制和声明式事务控制。 自己手动控制事务，就叫做编程式事务控制。开发起来比较繁琐，每次都要开启、提交、回滚。可以对指定的方法、指定的方法的某几行添加事务控制 Spring提供了对事务的管理, 这个就叫声明式事务管理。实现了对事务控制的最大程度的解耦。核心实现就是基于AOP。只能给整个方法应用事务，不可以对方法的某几行应用事务。Spring声明式事务管理器类：Jdbc技术：DataSourceTransactionManager、Hibernate技术：HibernateTransactionManager 使用配置文件的方法略。 spring管理事务的属性介绍 (1)事务的隔离级别 (2)是否只读 (3)事务的传播行为。有7种。分别是REQUIRED、REQUIRES_NEW、SUPPORTS、NOT_SUPPORTED、MANDATORY、NESTED、NEVER。我们常用的是propagation=&quot;REQUIRED&quot;，默认的就是REQUIRED，指得是支持当前事务，如果不存在，就新建一个（默认），所以这个属性不用配置。其余6个属性几乎不用 在需要添加事务管理的方法上添加： 1@Transactional(isolation=Isolation.REPEATABLE_READ,readOnly=false,propagation=Propagation.REQUIRED) 参考文章1参考文章2参考文章3参考文章4参考文章5参考文章6","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://kebabshellgithub.github.io/tags/Spring/"}]},{"title":"异常的小复习","slug":"异常的小复习","date":"2020-04-03T15:30:48.000Z","updated":"2023-04-06T11:06:55.042Z","comments":true,"path":"2020/04/03/异常的小复习/","link":"","permalink":"https://kebabshellgithub.github.io/2020/04/03/%E5%BC%82%E5%B8%B8%E7%9A%84%E5%B0%8F%E5%A4%8D%E4%B9%A0/","excerpt":"","text":"异常 Throwable Error Exception（异常） 编译时异常(非运行时异常)(编译阶段就会报错，必须处理，否则编译不能通过(抛异常)) RuntimeException（运行时异常，运行阶段） Error与Exception Error:无法通过处理的错误，比如内存崩溃、JVM本身的崩溃… Exception:异常，需要提取处理，使程序更健壮 Java默认异常的自动处理 默认会在出现异常的代码那里自动创建一个异常对象ArithmeticException 会从方法中出现异常的那一行抛出给调用者 调用者最终抛给JVM JVM收到异常对象后，先输出异常栈信息 然后干掉程序 编译时异常处理： 一股脑的在方法后抛出 try …catch 直接printStackTrace异常栈 （建议直接catch(Exception e)） 把异常一层层抛给最外层统一处理（规范）（异常打印不一定按照顺序（会有指令优化，指令重排序）） 运行时异常处理：（10 &#x2F; 0） 外层要try catch捕获一下 自定义编译时异常: 继承Exception 重写构造 在出现异常的地方throw new 异常 来抛出 自定义运行时异常： 继承RuntimeException try、catch、finally： try只能出现一次 catch 0-n次（当有finally时可以为0次） finally 0-1次 无论代码是否异常，finally都会执行 当多异常处理时，前面catch的异常不能是后面catch异常的父类 finally 主要是为了释放资源(资源：实现了Closeable接口的) 如果try有return，要finally执行完才return 在finally中抛异常或者return，会掩盖之前的异常 如果finally有异常，如io流的关闭，try里面先if判断，不为空则关闭，catch里面不打印或者写进日志 常见的运行时异常 数组越界：ArrayIndexOutOfBoundsException 空指针：NullPointerException(直接输出没问题，调用其功能抛异常) 类型转换异常：ClassCastException 迭代器遍历没有此元素异常：NoSuchElementException 数学操作异常：ArithmeticException 数学转换异常：NumberFormatException … throw 与 throws 的区别 throw抛出实例，throws在方法后 如果throw抛出RuntimeException及其子类，则方法声明上可以没有throws，如果throw抛出Exception及其子类，则声明上必须有throws Java 异常链 异常链是指在进行一个异常处理时抛出了另外一个异常，由此产生了一个异常链条，大多用于将受检查异常（checked exception）封装成为非受检查异常（unchecked exception)或者 RuntimeException。特别注意如果你因为一个异常而决定抛出另一个新的异常时一定要包含原有的异常，这样处理程序才可以通过 getCause() 和 initCause() 方法来访问异常最终的根源。 例子 定义两个异常类 1public class MyE1 extends Exception &#123;&#125; 12345678public class MyE2 extends Exception&#123; MyE2(Throwable throwable)&#123; super(throwable); &#125; MyE2()&#123; super(); &#125;&#125; 跑一下 123456789101112131415161718192021public class test &#123; public void func() throws MyE2 &#123; try &#123; func2(); &#125; catch (MyE1 myE1) &#123; myE1.printStackTrace(); throw new MyE2(); &#125; &#125; public void func2() throws MyE1 &#123; throw new MyE1(); &#125; @Test public void test()&#123; try &#123; func(); &#125; catch (MyE2 myE2) &#123; myE2.printStackTrace(); &#125; &#125;&#125; 运行test的结果： 将func()里面的throw new MyE2()添加上MyE1的信息 -&gt; throw new MyE2(MyE1) 运行test的结果： 现在可以拿到MyE1的信息了 未完待续！ 没了 :)","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"}]},{"title":"next lastest 6+ 的安装和坑","slug":"next-6-的安装和坑","date":"2020-04-01T16:17:24.000Z","updated":"2023-04-06T11:06:55.030Z","comments":true,"path":"2020/04/01/next-6-的安装和坑/","link":"","permalink":"https://kebabshellgithub.github.io/2020/04/01/next-6-%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E5%9D%91/","excerpt":"","text":"next 安装 1、基本安装和上文类似，请移步上文及1https://github.com/theme-next/hexo-theme-next 2、估计是5.*的bug，菜单的设置不用考虑有没有空格了，例如1archives: /archives/ || archive 3、隐藏主页的内容12# auto_excerpt:# enable: false 这个最新版已经移除，直接用&lt;!-- more --&gt;截断 next更新日志 4、使用valine评论系统看这篇 没了 :)","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://kebabshellgithub.github.io/tags/Hexo/"},{"name":"博客","slug":"博客","permalink":"https://kebabshellgithub.github.io/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"Next","slug":"Next","permalink":"https://kebabshellgithub.github.io/tags/Next/"}]},{"title":"hexo 主题的安装(next)(5.1.*)","slug":"hexo-主题的安装-next","date":"2020-04-01T10:08:55.000Z","updated":"2023-04-06T11:06:55.030Z","comments":true,"path":"2020/04/01/hexo-主题的安装-next/","link":"","permalink":"https://kebabshellgithub.github.io/2020/04/01/hexo-%E4%B8%BB%E9%A2%98%E7%9A%84%E5%AE%89%E8%A3%85-next/","excerpt":"","text":"next主题安装文档 1、克隆(要在博客的根目录下)：1$ git clone https://github.com/iissnan/hexo-theme-next themes/next 2、更改_config.yml文件 theme: next 3、主题设定在主题的_config.yml中，更改Scheme 4、设置语言在默认_config.yml中修改language: zh-Hans 5、设置菜单 123456menu: home: /|| home #about: /about/ || user #tags: /tags/ || tags #categories: /categories/ || th archives: /archives/|| archive 注意：是archives: /archives/|| archive而不是archives: /archives/ || archive，/archives/后面不能有空格 6、侧栏设置12sidebar: display: post 7、设置头像1avatar: /images/hexo.jpg hexo.jpg放在所选主题(next)的source/images下 8、作者昵称和站点描述都在默认_config.yml中 9、隐藏主页的内容，即提供more按钮12auto_excerpt: enable: false 没了:)","categories":[{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://kebabshellgithub.github.io/tags/Hexo/"},{"name":"博客","slug":"博客","permalink":"https://kebabshellgithub.github.io/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"Next","slug":"Next","permalink":"https://kebabshellgithub.github.io/tags/Next/"}]}],"categories":[{"name":"总结","slug":"总结","permalink":"https://kebabshellgithub.github.io/categories/%E6%80%BB%E7%BB%93/"},{"name":"摄影","slug":"摄影","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%84%E5%BD%B1/"},{"name":"技术","slug":"技术","permalink":"https://kebabshellgithub.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"音乐","slug":"音乐","permalink":"https://kebabshellgithub.github.io/categories/%E9%9F%B3%E4%B9%90/"},{"name":"摆烂了","slug":"摆烂了","permalink":"https://kebabshellgithub.github.io/categories/%E6%91%86%E7%83%82%E4%BA%86/"}],"tags":[{"name":"半年","slug":"半年","permalink":"https://kebabshellgithub.github.io/tags/%E5%8D%8A%E5%B9%B4/"},{"name":"画册","slug":"画册","permalink":"https://kebabshellgithub.github.io/tags/%E7%94%BB%E5%86%8C/"},{"name":"原创","slug":"原创","permalink":"https://kebabshellgithub.github.io/tags/%E5%8E%9F%E5%88%9B/"},{"name":"组图","slug":"组图","permalink":"https://kebabshellgithub.github.io/tags/%E7%BB%84%E5%9B%BE/"},{"name":"历史","slug":"历史","permalink":"https://kebabshellgithub.github.io/tags/%E5%8E%86%E5%8F%B2/"},{"name":"软考","slug":"软考","permalink":"https://kebabshellgithub.github.io/tags/%E8%BD%AF%E8%80%83/"},{"name":"Kotlin","slug":"Kotlin","permalink":"https://kebabshellgithub.github.io/tags/Kotlin/"},{"name":"Jetpack","slug":"Jetpack","permalink":"https://kebabshellgithub.github.io/tags/Jetpack/"},{"name":"Android","slug":"Android","permalink":"https://kebabshellgithub.github.io/tags/Android/"},{"name":"乐理","slug":"乐理","permalink":"https://kebabshellgithub.github.io/tags/%E4%B9%90%E7%90%86/"},{"name":"和弦","slug":"和弦","permalink":"https://kebabshellgithub.github.io/tags/%E5%92%8C%E5%BC%A6/"},{"name":"Hexo","slug":"Hexo","permalink":"https://kebabshellgithub.github.io/tags/Hexo/"},{"name":"博客","slug":"博客","permalink":"https://kebabshellgithub.github.io/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"GitHub","slug":"GitHub","permalink":"https://kebabshellgithub.github.io/tags/GitHub/"},{"name":"面试","slug":"面试","permalink":"https://kebabshellgithub.github.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"Java","slug":"Java","permalink":"https://kebabshellgithub.github.io/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://kebabshellgithub.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"数据库","slug":"数据库","permalink":"https://kebabshellgithub.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"https://kebabshellgithub.github.io/tags/MySQL/"},{"name":"设计模式","slug":"设计模式","permalink":"https://kebabshellgithub.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Spring","slug":"Spring","permalink":"https://kebabshellgithub.github.io/tags/Spring/"},{"name":"JVM","slug":"JVM","permalink":"https://kebabshellgithub.github.io/tags/JVM/"},{"name":"操作系统","slug":"操作系统","permalink":"https://kebabshellgithub.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"集合","slug":"集合","permalink":"https://kebabshellgithub.github.io/tags/%E9%9B%86%E5%90%88/"},{"name":"微服务","slug":"微服务","permalink":"https://kebabshellgithub.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"置顶","slug":"置顶","permalink":"https://kebabshellgithub.github.io/tags/%E7%BD%AE%E9%A1%B6/"},{"name":"MarkDown","slug":"MarkDown","permalink":"https://kebabshellgithub.github.io/tags/MarkDown/"},{"name":"锁","slug":"锁","permalink":"https://kebabshellgithub.github.io/tags/%E9%94%81/"},{"name":"消息队列","slug":"消息队列","permalink":"https://kebabshellgithub.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"中间件","slug":"中间件","permalink":"https://kebabshellgithub.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"网络","slug":"网络","permalink":"https://kebabshellgithub.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"算法","slug":"算法","permalink":"https://kebabshellgithub.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"缓存","slug":"缓存","permalink":"https://kebabshellgithub.github.io/tags/%E7%BC%93%E5%AD%98/"},{"name":"Next","slug":"Next","permalink":"https://kebabshellgithub.github.io/tags/Next/"}]}